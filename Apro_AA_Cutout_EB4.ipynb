{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### IMPORTING NECESSARY MODULES #########\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.append('/home/ironman/abhishek/AliProducts/architectures/')\n",
    "sys.path.append('/home/ironman/abhishek/AliProducts/Helper/')\n",
    "from dataloader import mydataset, create_prime_dict \n",
    "from trainer import train, test_classify, eval_classify\n",
    "from efficientnet import *\n",
    "from Load_model import load\n",
    "from plot_curves import plot_loss, plot_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataloading Scheme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlist = '/home/ironman/abhishek/AliProducts/Newlist/NEW_train_list1.txt'\n",
    "validlist = '/home/ironman/abhishek/AliProducts/Newlist/NEW_valid_list1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes =  50030\n"
     ]
    }
   ],
   "source": [
    "prime_dict = create_prime_dict(trainlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train Dataloader #### \n",
    "train_dataset = mydataset(trainlist, prime_dict, name='train')          \n",
    "train_dataloader = data.DataLoader(train_dataset, shuffle= True, batch_size = 256, num_workers=16,pin_memory=True)\n",
    "\n",
    "\n",
    "#### Validation Dataloader #### \n",
    "validation_dataset = mydataset(validlist, prime_dict, name='valid')         \n",
    "validation_dataloader = data.DataLoader(validation_dataset, shuffle=False, batch_size = 64, num_workers=16,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): EfficientNet(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          16, 16, kernel_size=(3, 3), stride=(1, 1), groups=16, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          16, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          4, 16, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (7): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (9): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (12): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (14): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (16): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (17): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (18): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (19): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (20): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (21): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (22): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          320, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1920, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1920, 1920, kernel_size=(3, 3), stride=(1, 1), groups=1920, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1920, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1920, 80, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          80, 1920, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1920, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (_dropout): Dropout(p=0.2, inplace=False)\n",
       "    (_fc): Linear(in_features=1280, out_features=50030, bias=True)\n",
       "    (batchnorm): BatchNorm1d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_swish): MemoryEfficientSwish()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained('efficientnet-b1', num_classes = 50030)\n",
    "\n",
    "model = nn.DataParallel(model,device_ids=[2,3]).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4, momentum=0.9)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 25, gamma = 0.1)\n",
    "\n",
    "# Epochs\n",
    "num_Epochs = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'New_Data_Apro_AA_Cutout_EB4'\n",
    "modelpath = '/home/ironman/abhishek/saved_model_checkpoints/AliProducts/'+modelname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 10.875374240875244\n",
      "loss 21.40119930267334\n",
      "loss 31.474676504135132\n",
      "loss 41.018507947921755\n",
      "loss 50.027185621261594\n",
      "loss 58.48823525428772\n",
      "loss 66.39914549350739\n",
      "loss 73.79642375946045\n",
      "loss 80.7872084760666\n",
      "loss 87.35523881912232\n",
      "loss 93.59308490753173\n",
      "loss 99.5039008140564\n",
      "loss 105.11004096984863\n",
      "loss 110.46933645248413\n",
      "loss 115.67984777450562\n",
      "loss 120.69465416908264\n",
      "loss 125.53975365638733\n",
      "loss 130.29283402204513\n",
      "loss 134.84975261211395\n",
      "loss 139.39749851703644\n",
      "loss 143.81729031801223\n",
      "loss 148.1028567314148\n",
      "loss 152.28740742206574\n",
      "loss 156.43959990262985\n",
      "loss 160.50460388183595\n",
      "loss 164.53945883512498\n",
      "loss 168.50371052026748\n",
      "loss 172.45160319566727\n",
      "loss 176.30515181541443\n",
      "loss 180.11538854122162\n",
      "loss 183.85879071235658\n",
      "loss 187.52464338064195\n",
      "loss 191.20842149734497\n",
      "loss 194.86319331884386\n",
      "loss 198.44136847734453\n",
      "loss 201.98718685388565\n",
      "loss 205.53763853549958\n",
      "loss 209.0610853099823\n",
      "loss 212.5755342054367\n",
      "loss 216.05949625968933\n",
      "loss 219.5045344352722\n",
      "loss 222.9389777970314\n",
      "loss 226.2998943400383\n",
      "loss 229.66236600875854\n",
      "Epoch:  1\n",
      "training loss =  5.200399333556261\n",
      "Validation Loss: 2.2991\tTop 1 Validation Accuracy: 0.5871\t Top 5 Validation Accuracy: 0.8029\n",
      "loss 2.7755173420906067\n",
      "loss 5.509573273658752\n",
      "loss 8.251894474029541\n",
      "loss 11.027627737522126\n",
      "loss 13.80544364452362\n",
      "loss 16.585599734783173\n",
      "loss 19.40335327386856\n",
      "loss 22.21951485157013\n",
      "loss 25.042044010162353\n",
      "loss 27.873501627445222\n",
      "loss 36.486583948135376\n",
      "loss 39.32607803344727\n",
      "loss 42.1842848610878\n",
      "loss 45.05940130472183\n",
      "loss 47.91298730134964\n",
      "loss 50.74853702068329\n",
      "loss 53.62521392583847\n",
      "loss 56.49301251173019\n",
      "loss 59.39215390920639\n",
      "loss 62.275159068107605\n",
      "loss 65.17179070472717\n",
      "loss 68.02816643714905\n",
      "loss 70.88441929101944\n",
      "loss 73.78986892461776\n",
      "loss 76.66261073589325\n",
      "loss 79.4890097951889\n",
      "loss 82.3485434627533\n",
      "loss 85.21586978197098\n",
      "loss 88.09127929449082\n",
      "loss 90.93992572069168\n",
      "loss 93.85264526844024\n",
      "loss 96.71628387451172\n",
      "loss 99.59715429544448\n",
      "loss 102.45391491413116\n",
      "loss 105.32829275846481\n",
      "loss 108.23134703874588\n",
      "loss 111.11431519269944\n",
      "loss 114.04169662714004\n",
      "loss 116.88815101861954\n",
      "loss 119.76532963991166\n",
      "loss 122.6369607257843\n",
      "loss 125.48252917528153\n",
      "Epoch:  2\n",
      "training loss =  2.852787545592109\n",
      "Validation Loss: 1.8206\tTop 1 Validation Accuracy: 0.6556\t Top 5 Validation Accuracy: 0.8575\n",
      "loss 2.2903393650054933\n",
      "loss 4.5460362410545345\n",
      "loss 6.8557852780818935\n",
      "loss 9.18780619263649\n",
      "loss 11.558864644765855\n",
      "loss 13.960234056711197\n",
      "loss 16.341594284772874\n",
      "loss 18.744539748430253\n",
      "loss 21.211729863882066\n",
      "loss 23.669067978858948\n",
      "loss 26.14555276632309\n",
      "loss 28.59203716993332\n",
      "loss 31.075196180343628\n",
      "loss 33.58768809556961\n",
      "loss 36.082813613414764\n",
      "loss 38.594486668109894\n",
      "loss 41.14900351524353\n",
      "loss 43.71146654367447\n",
      "loss 46.29273763179779\n",
      "loss 48.84754363656044\n",
      "loss 51.46681475043297\n",
      "loss 54.08842275500297\n",
      "loss 56.69908964991569\n",
      "loss 59.338811510801314\n",
      "loss 62.00276744484901\n",
      "loss 64.6023363006115\n",
      "loss 67.25032995581627\n",
      "loss 69.92579835295678\n",
      "loss 72.57944751143455\n",
      "loss 75.23694606900216\n",
      "loss 77.92937964558601\n",
      "loss 80.60782507777213\n",
      "loss 83.26119077801704\n",
      "loss 85.98283975720406\n",
      "loss 88.669549254179\n",
      "loss 91.3639813220501\n",
      "loss 94.01113572239876\n",
      "loss 96.70115482211114\n",
      "loss 99.40393439412117\n",
      "loss 102.10548866152763\n",
      "loss 104.8420830976963\n",
      "loss 107.58467314124107\n",
      "loss 110.319354814291\n",
      "loss 113.02681717514992\n",
      "Epoch:  3\n",
      "training loss =  2.5702396692628136\n",
      "Validation Loss: 1.7823\tTop 1 Validation Accuracy: 0.6708\t Top 5 Validation Accuracy: 0.8670\n",
      "loss 2.1569179236888885\n",
      "loss 4.309640575647354\n",
      "loss 6.468938826322556\n",
      "loss 8.62450767159462\n",
      "loss 10.828333706855775\n",
      "loss 13.068707045316696\n",
      "loss 15.342643344402314\n",
      "loss 17.647356609106065\n",
      "loss 19.93512911081314\n",
      "loss 22.303701337575912\n",
      "loss 24.621854082345962\n",
      "loss 26.99216587662697\n",
      "loss 29.3655986726284\n",
      "loss 31.779036153554916\n",
      "loss 34.19052817225456\n",
      "loss 36.59483488559723\n",
      "loss 39.02682902932167\n",
      "loss 41.47277196407318\n",
      "loss 43.939086918830874\n",
      "loss 46.43972725629806\n",
      "loss 48.97011409401894\n",
      "loss 51.47842283129692\n",
      "loss 53.99543798804283\n",
      "loss 56.50930825829506\n",
      "loss 59.00659880042076\n",
      "loss 61.51227355957031\n",
      "loss 64.06035498857499\n",
      "loss 66.61104792118073\n",
      "loss 69.16594111442566\n",
      "loss 71.72681391477585\n",
      "loss 74.34126393795013\n",
      "loss 76.97760072946548\n",
      "loss 79.59998485088349\n",
      "loss 82.25020045042038\n",
      "loss 90.03641006231308\n",
      "loss 92.66922003269195\n",
      "loss 95.27145058393478\n",
      "loss 97.909718105793\n",
      "loss 100.52672556400299\n",
      "loss 103.19106154680252\n",
      "loss 105.83053493261338\n",
      "loss 108.45987469434738\n",
      "Epoch:  4\n",
      "training loss =  2.4670861314756833\n",
      "Validation Loss: 2.0106\tTop 1 Validation Accuracy: 0.6424\t Top 5 Validation Accuracy: 0.8394\n",
      "loss 2.0717362809181212\n",
      "loss 4.139642843008041\n",
      "loss 6.196537964344024\n",
      "loss 8.305904208421707\n",
      "loss 10.436047389507294\n",
      "loss 12.56115501999855\n",
      "loss 14.761509898900986\n",
      "loss 16.966430612802505\n",
      "loss 19.13645306825638\n",
      "loss 21.417467287778855\n",
      "loss 23.70905797600746\n",
      "loss 25.993320857286452\n",
      "loss 28.29339219212532\n",
      "loss 30.653420754671096\n",
      "loss 32.999174313545225\n",
      "loss 37.731824320554736\n",
      "loss 40.13928855419159\n",
      "loss 42.5551779448986\n",
      "loss 44.949853694438936\n",
      "loss 47.38195763707161\n",
      "loss 49.79816977500916\n",
      "loss 52.256921987533566\n",
      "loss 54.7262384057045\n",
      "loss 57.22199607729912\n",
      "loss 59.697726701498034\n",
      "loss 62.162446504831316\n",
      "loss 64.64874154806137\n",
      "loss 67.15001354694367\n",
      "loss 69.64622498750687\n",
      "loss 72.19549667358399\n",
      "loss 74.70462519049644\n",
      "loss 77.24992560505866\n",
      "loss 79.84010908722877\n",
      "loss 82.42703675389289\n",
      "loss 85.00613613009453\n",
      "loss 87.5673266685009\n",
      "loss 90.14459829688072\n",
      "loss 92.71813231825828\n",
      "loss 95.28728230118752\n",
      "loss 97.89075986504555\n",
      "loss 100.45215586781502\n",
      "loss 103.02906918168068\n",
      "loss 105.65239546895027\n",
      "Epoch:  5\n",
      "training loss =  2.4033560769220723\n",
      "Validation Loss: 1.9315\tTop 1 Validation Accuracy: 0.6503\t Top 5 Validation Accuracy: 0.8448\n",
      "loss 2.022850377559662\n",
      "loss 3.986678237915039\n",
      "loss 5.966580799818039\n",
      "loss 7.981686021089554\n",
      "loss 10.022757494449616\n",
      "loss 12.127441040277482\n",
      "loss 14.226867402791976\n",
      "loss 16.409669404029845\n",
      "loss 18.599571952819826\n",
      "loss 20.793345547914505\n",
      "loss 23.000307586193085\n",
      "loss 25.201703869104385\n",
      "loss 27.470940651893617\n",
      "loss 29.746894663572313\n",
      "loss 32.0365666949749\n",
      "loss 34.31283702850342\n",
      "loss 36.65071712136269\n",
      "loss 38.98417128562927\n",
      "loss 41.314955811500546\n",
      "loss 43.692565958499905\n",
      "loss 46.05799862742424\n",
      "loss 48.467971510887146\n",
      "loss 50.857205675840376\n",
      "loss 53.261880991458895\n",
      "loss 55.65211313843727\n",
      "loss 58.11550954699516\n",
      "loss 60.546625057458876\n",
      "loss 63.004934862852096\n",
      "loss 65.4803714454174\n",
      "loss 67.99405634045601\n",
      "loss 70.4946012032032\n",
      "loss 72.98279384613038\n",
      "loss 75.50933652997017\n",
      "loss 78.02118761897087\n",
      "loss 80.54956722855567\n",
      "loss 83.10178007245064\n",
      "loss 85.65441497683526\n",
      "loss 88.16966645359993\n",
      "loss 90.70066400408744\n",
      "loss 93.22821209073066\n",
      "loss 95.74123686909675\n",
      "loss 98.26225847721099\n",
      "loss 100.83815031290054\n",
      "loss 103.37722422599792\n",
      "Epoch:  6\n",
      "training loss =  2.3525759362627583\n",
      "Validation Loss: 1.8374\tTop 1 Validation Accuracy: 0.6765\t Top 5 Validation Accuracy: 0.8662\n",
      "loss 1.9788048195838928\n",
      "loss 3.9605911672115326\n",
      "loss 5.917921837568283\n",
      "loss 7.902492002248764\n",
      "loss 9.889254055023194\n",
      "loss 11.93006381392479\n",
      "loss 13.983914933204652\n",
      "loss 16.078178936243056\n",
      "loss 18.2437762594223\n",
      "loss 20.366911544799805\n",
      "loss 22.508075180053712\n",
      "loss 24.6914986538887\n",
      "loss 26.927984130382537\n",
      "loss 29.161476018428804\n",
      "loss 31.38596327781677\n",
      "loss 33.66043945074082\n",
      "loss 35.93666945338249\n",
      "loss 38.23944131731987\n",
      "loss 40.49663118600845\n",
      "loss 42.79815984249115\n",
      "loss 45.12477315545082\n",
      "loss 47.52097828626633\n",
      "loss 49.88320778489113\n",
      "loss 52.248954603672026\n",
      "loss 54.646961092948914\n",
      "loss 57.04620800018311\n",
      "loss 59.47625279903412\n",
      "loss 61.87344687581062\n",
      "loss 64.28473929643631\n",
      "loss 66.71986766695976\n",
      "loss 69.18202126860619\n",
      "loss 71.62872699141502\n",
      "loss 74.06696590900421\n",
      "loss 76.5430317234993\n",
      "loss 79.02765622735023\n",
      "loss 81.54445086717605\n",
      "loss 84.04187913656234\n",
      "loss 86.56892481446266\n",
      "loss 89.0962464439869\n",
      "loss 91.62103079795837\n",
      "loss 94.17528576374053\n",
      "loss 96.70502894878388\n",
      "loss 99.27278795480728\n",
      "loss 101.82275163412095\n",
      "Epoch:  7\n",
      "training loss =  2.316691776058608\n",
      "Validation Loss: 1.8551\tTop 1 Validation Accuracy: 0.6676\t Top 5 Validation Accuracy: 0.8588\n",
      "loss 1.8969014298915863\n",
      "loss 3.764711004495621\n",
      "loss 5.678177266120911\n",
      "loss 7.6373996758461\n",
      "loss 9.637708923816682\n",
      "loss 11.639552700519562\n",
      "loss 13.658457397222518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 15.702332139015198\n",
      "loss 17.763293837308883\n",
      "loss 19.88459294438362\n",
      "loss 22.002492954730986\n",
      "loss 24.132478152513503\n",
      "loss 26.304765157699585\n",
      "loss 28.491727666854857\n",
      "loss 30.704017535448074\n",
      "loss 32.93958483099937\n",
      "loss 35.1592644560337\n",
      "loss 37.37811470627785\n",
      "loss 39.62011539459228\n",
      "loss 41.89962891578674\n",
      "loss 44.20821425318718\n",
      "loss 46.51919836640358\n",
      "loss 48.89334097743034\n",
      "loss 51.21882918119431\n",
      "loss 53.576948137283324\n",
      "loss 55.93154453992844\n",
      "loss 58.29400796890259\n",
      "loss 60.67954214096069\n",
      "loss 63.07305860042572\n",
      "loss 65.4928748869896\n",
      "loss 67.92601506471634\n",
      "loss 70.3405402636528\n",
      "loss 72.7703059208393\n",
      "loss 75.2459460425377\n",
      "loss 77.70355123400688\n",
      "loss 80.14145565390587\n",
      "loss 82.62252972245216\n",
      "loss 85.07736855983734\n",
      "loss 87.55953185558319\n",
      "loss 90.04602410674096\n",
      "loss 92.59464856624604\n",
      "loss 95.09056990981102\n",
      "loss 97.58615517616272\n",
      "loss 100.05683620095253\n",
      "Epoch:  8\n",
      "training loss =  2.2760625489513497\n",
      "Validation Loss: 1.7820\tTop 1 Validation Accuracy: 0.6769\t Top 5 Validation Accuracy: 0.8638\n",
      "loss 1.8934005141258239\n",
      "loss 3.7754588878154753\n",
      "loss 5.669107124805451\n",
      "loss 7.6066868782043455\n",
      "loss 9.521913104057312\n",
      "loss 11.468963646888733\n",
      "loss 13.437959285974502\n",
      "loss 15.478374218940735\n",
      "loss 17.527934205532073\n",
      "loss 19.633285912275316\n",
      "loss 21.690291615724565\n",
      "loss 23.774763823747634\n",
      "loss 25.928779327869414\n",
      "loss 28.06081426382065\n",
      "loss 30.20427626132965\n",
      "loss 32.400015723705295\n",
      "loss 34.64067546367645\n",
      "loss 36.85658390045166\n",
      "loss 39.08774697303772\n",
      "loss 41.35925642609596\n",
      "loss 43.64069636940956\n",
      "loss 45.9336915397644\n",
      "loss 48.22025030374527\n",
      "loss 50.513872126340864\n",
      "loss 52.77868367195129\n",
      "loss 55.09973428606987\n",
      "loss 57.44378130435943\n",
      "loss 59.78114742398262\n",
      "loss 62.16002827882767\n",
      "loss 64.5682433283329\n",
      "loss 66.95060109972954\n",
      "loss 69.36229343414307\n",
      "loss 71.78617259263993\n",
      "loss 74.22099300861359\n",
      "loss 76.63534773230553\n",
      "loss 79.02507558584213\n",
      "loss 81.47189308285714\n",
      "loss 83.95373279213905\n",
      "loss 86.45090249180794\n",
      "loss 88.95422686457634\n",
      "loss 91.42607989668846\n",
      "loss 93.9270554292202\n",
      "loss 96.43079888820648\n",
      "loss 98.94507958173752\n",
      "Epoch:  9\n",
      "training loss =  2.2512180849169248\n",
      "Validation Loss: 1.7406\tTop 1 Validation Accuracy: 0.6861\t Top 5 Validation Accuracy: 0.8732\n",
      "loss 1.8599343383312226\n",
      "loss 3.6934449207782745\n",
      "loss 5.50591339468956\n",
      "loss 7.392070108652115\n",
      "loss 9.328855127096176\n",
      "loss 11.261564828157425\n",
      "loss 13.21924373626709\n",
      "loss 15.229187477827072\n",
      "loss 17.21661967635155\n",
      "loss 19.21919591784477\n",
      "loss 21.254625413417816\n",
      "loss 23.343693770170212\n",
      "loss 25.415955682992934\n",
      "loss 27.56744567155838\n",
      "loss 29.72093785405159\n",
      "loss 31.907238487005234\n",
      "loss 34.0819109916687\n",
      "loss 36.31828841924667\n",
      "loss 38.496230301857\n",
      "loss 40.721285084486006\n",
      "loss 42.95021682858467\n",
      "loss 45.21831439971924\n",
      "loss 47.49075170636177\n",
      "loss 49.776296045780185\n",
      "loss 52.080438709259035\n",
      "loss 54.39545637607574\n",
      "loss 56.709590654373166\n",
      "loss 59.0216066467762\n",
      "loss 61.409889910221096\n",
      "loss 63.77797531247139\n",
      "loss 66.16726029276847\n",
      "loss 68.56876914620399\n",
      "loss 70.95413932561874\n",
      "loss 73.36957753658295\n",
      "loss 75.78398336529732\n",
      "loss 78.19956921339035\n",
      "loss 80.6080780994892\n",
      "loss 83.05257463693619\n",
      "loss 85.46904940724373\n",
      "loss 87.92788367390632\n",
      "loss 90.390083912611\n",
      "loss 92.86811855435371\n",
      "loss 95.33381224751473\n",
      "loss 97.7968438899517\n",
      "Epoch:  10\n",
      "training loss =  2.2252189960001507\n",
      "Validation Loss: 1.7702\tTop 1 Validation Accuracy: 0.6807\t Top 5 Validation Accuracy: 0.8676\n",
      "loss 1.8043381774425507\n",
      "loss 3.56955340385437\n",
      "loss 5.391085749864578\n",
      "loss 7.2319538569450375\n",
      "loss 9.098956159353257\n",
      "loss 10.969166892766953\n",
      "loss 12.88161418914795\n",
      "loss 14.86120740532875\n",
      "loss 16.83424993276596\n",
      "loss 18.83951155900955\n",
      "loss 20.888352930545807\n",
      "loss 22.96539347410202\n",
      "loss 25.025351887941362\n",
      "loss 27.136362043619155\n",
      "loss 29.249504207372667\n",
      "loss 31.392733577489853\n",
      "loss 33.55115178346634\n",
      "loss 35.76514547705651\n",
      "loss 37.960222519636154\n",
      "loss 40.16797077298165\n",
      "loss 42.40498764753342\n",
      "loss 44.71156987905502\n",
      "loss 47.03346445202828\n",
      "loss 49.27957668185234\n",
      "loss 51.57780928969383\n",
      "loss 53.909708194732666\n",
      "loss 56.24134421706199\n",
      "loss 58.5472897028923\n",
      "loss 60.891477233171464\n",
      "loss 63.220052715539936\n",
      "loss 65.59663663387299\n",
      "loss 67.99605507373809\n",
      "loss 70.36275128126144\n",
      "loss 72.75062943816185\n",
      "loss 75.11640198230744\n",
      "loss 77.53632064461708\n",
      "loss 79.90717722415924\n",
      "loss 82.34486833810806\n",
      "loss 84.75829429745674\n",
      "loss 87.20901720643043\n",
      "loss 89.6460921061039\n",
      "loss 92.08560422420501\n",
      "loss 94.57127898454667\n",
      "loss 97.02319582939148\n",
      "Epoch:  11\n",
      "training loss =  2.207415946499803\n",
      "Validation Loss: 1.7861\tTop 1 Validation Accuracy: 0.6828\t Top 5 Validation Accuracy: 0.8681\n",
      "loss 1.8065552628040313\n",
      "loss 3.5919676852226257\n",
      "loss 5.395625207424164\n",
      "loss 7.253454395532608\n",
      "loss 9.091091244220733\n",
      "loss 10.971302759647369\n",
      "loss 12.909922853708267\n",
      "loss 14.861370441913605\n",
      "loss 16.84125162601471\n",
      "loss 18.832996555566787\n",
      "loss 20.851126894950866\n",
      "loss 22.89349529385567\n",
      "loss 24.958939337730406\n",
      "loss 27.032815953493117\n",
      "loss 29.13827815413475\n",
      "loss 31.299555331468582\n",
      "loss 33.42357234239578\n",
      "loss 35.60867243528366\n",
      "loss 37.79738213419914\n",
      "loss 39.99668234109878\n",
      "loss 42.22983526587486\n",
      "loss 44.436979112625124\n",
      "loss 46.68268518924713\n",
      "loss 48.92833724141121\n",
      "loss 51.20846578478813\n",
      "loss 53.46039859175682\n",
      "loss 55.74047050714493\n",
      "loss 58.01379712820053\n",
      "loss 60.34827053666115\n",
      "loss 62.67104071855545\n",
      "loss 64.98319088220596\n",
      "loss 67.36272395849228\n",
      "loss 69.7339038324356\n",
      "loss 72.12246117830277\n",
      "loss 74.544382199049\n",
      "loss 76.937289737463\n",
      "loss 79.30741221547127\n",
      "loss 81.72287867426873\n",
      "loss 84.12470311641692\n",
      "loss 86.5610026061535\n",
      "loss 89.03445655107498\n",
      "loss 91.45472104549408\n",
      "loss 93.87340966820717\n",
      "loss 96.29690402269364\n",
      "Epoch:  12\n",
      "training loss =  2.1913070931229828\n",
      "Validation Loss: 1.9326\tTop 1 Validation Accuracy: 0.6652\t Top 5 Validation Accuracy: 0.8502\n",
      "loss 1.7965473449230194\n",
      "loss 3.5763775980472565\n",
      "loss 5.366297590732574\n",
      "loss 7.194256339073181\n",
      "loss 9.060905575752258\n",
      "loss 10.935785789489746\n",
      "loss 12.833900096416473\n",
      "loss 14.741120573282242\n",
      "loss 16.69207042813301\n",
      "loss 18.667810446023942\n",
      "loss 20.637072874307634\n",
      "loss 22.655790470838546\n",
      "loss 24.741202350854874\n",
      "loss 26.80995968580246\n",
      "loss 28.872625827789307\n",
      "loss 30.949584007263184\n",
      "loss 33.096891293525694\n",
      "loss 35.260066536664965\n",
      "loss 37.45293834090233\n",
      "loss 39.617452274560925\n",
      "loss 41.81291657924652\n",
      "loss 44.00183892011643\n",
      "loss 46.24021192908287\n",
      "loss 48.48279054999352\n",
      "loss 50.73818970799446\n",
      "loss 53.02257740259171\n",
      "loss 55.319860402345654\n",
      "loss 57.618542433977126\n",
      "loss 59.932669689655306\n",
      "loss 62.29834443807602\n",
      "loss 64.63130397677422\n",
      "loss 66.99190828442573\n",
      "loss 69.30897381663323\n",
      "loss 71.67634946465492\n",
      "loss 74.0630610871315\n",
      "loss 76.42335594773293\n",
      "loss 78.77831451773643\n",
      "loss 81.14747757196426\n",
      "loss 83.5131663954258\n",
      "loss 85.94512650966644\n",
      "loss 88.34905533313751\n",
      "loss 90.78014029741287\n",
      "loss 93.23294288158417\n",
      "loss 95.67622422337531\n",
      "Epoch:  13\n",
      "training loss =  2.177544030039826\n",
      "Validation Loss: 1.8486\tTop 1 Validation Accuracy: 0.6788\t Top 5 Validation Accuracy: 0.8634\n",
      "loss 1.798008943796158\n",
      "loss 3.5960370397567747\n",
      "loss 5.3639254009723665\n",
      "loss 7.142068461179734\n",
      "loss 8.920037124156952\n",
      "loss 10.809762711524963\n",
      "loss 12.69817454457283\n",
      "loss 14.587284837961198\n",
      "loss 16.49236779332161\n",
      "loss 18.449615783691407\n",
      "loss 20.44464015007019\n",
      "loss 22.478463748693468\n",
      "loss 24.51382931113243\n",
      "loss 26.533799196481706\n",
      "loss 28.614855679273607\n",
      "loss 30.713604044914245\n",
      "loss 32.86798034191131\n",
      "loss 34.98067050099373\n",
      "loss 37.120478912591935\n",
      "loss 39.2993935072422\n",
      "loss 41.4874915766716\n",
      "loss 43.70039901018143\n",
      "loss 45.94076660752297\n",
      "loss 48.165884817838666\n",
      "loss 50.38111711025238\n",
      "loss 52.611784608364104\n",
      "loss 54.889802691936495\n",
      "loss 57.14752104043961\n",
      "loss 59.44884841322899\n",
      "loss 61.73740345597267\n",
      "loss 64.05915628790855\n",
      "loss 66.39552374839782\n",
      "loss 68.76875241279602\n",
      "loss 71.14171931028366\n",
      "loss 73.46541660189628\n",
      "loss 75.86708177208901\n",
      "loss 78.23385703206063\n",
      "loss 80.62237677454948\n",
      "loss 83.03007078409195\n",
      "loss 85.45133005857468\n",
      "loss 87.86909775018692\n",
      "loss 90.28732455730439\n",
      "loss 92.74754039168357\n",
      "loss 95.18626091122627\n",
      "Epoch:  14\n",
      "training loss =  2.166477283762363\n",
      "Validation Loss: 1.9207\tTop 1 Validation Accuracy: 0.6612\t Top 5 Validation Accuracy: 0.8477\n",
      "loss 1.7447675669193268\n",
      "loss 3.4878734946250916\n",
      "loss 5.250191245079041\n",
      "loss 7.047378767728805\n",
      "loss 8.854966425895691\n",
      "loss 10.683028192520142\n",
      "loss 12.523631302118302\n",
      "loss 14.450691915750504\n",
      "loss 16.354344577789306\n",
      "loss 18.306327189207078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 20.26808477163315\n",
      "loss 22.259661625623703\n",
      "loss 24.25773979783058\n",
      "loss 26.298776738643646\n",
      "loss 28.364266715049745\n",
      "loss 30.449648215770722\n",
      "loss 32.578835223913195\n",
      "loss 34.718184152841566\n",
      "loss 36.84542257547378\n",
      "loss 39.00305196881294\n",
      "loss 41.14963093996048\n",
      "loss 43.317818942070005\n",
      "loss 45.53989016294479\n",
      "loss 47.73351854085922\n",
      "loss 50.00366534233093\n",
      "loss 52.24552729725838\n",
      "loss 54.47360140562058\n",
      "loss 56.742977454662324\n",
      "loss 59.0404035782814\n",
      "loss 61.35142465591431\n",
      "loss 63.720186239480974\n",
      "loss 66.01763167023658\n",
      "loss 68.32724645018578\n",
      "loss 70.67073402285575\n",
      "loss 73.02767296433449\n",
      "loss 75.39003465294837\n",
      "loss 77.73962005376816\n",
      "loss 80.09700637221336\n",
      "loss 82.4993152475357\n",
      "loss 84.89311079263688\n",
      "loss 87.3371852338314\n",
      "loss 89.77523282766342\n",
      "loss 92.1911624455452\n",
      "loss 94.61389221191406\n",
      "Epoch:  15\n",
      "training loss =  2.1534393120541155\n",
      "Validation Loss: 1.7436\tTop 1 Validation Accuracy: 0.6896\t Top 5 Validation Accuracy: 0.8717\n",
      "loss 1.7964167165756226\n",
      "loss 3.5295990884304045\n",
      "loss 5.312365013360977\n",
      "loss 7.088975363969803\n",
      "loss 8.90792073726654\n",
      "loss 10.732909315824509\n",
      "loss 12.562344037294388\n",
      "loss 14.46972240805626\n",
      "loss 16.357430263757706\n",
      "loss 18.305358512401583\n",
      "loss 20.235752354860306\n",
      "loss 22.22249577522278\n",
      "loss 24.25073746800423\n",
      "loss 26.332728933095932\n",
      "loss 28.382151200771332\n",
      "loss 30.479121619462965\n",
      "loss 32.601579794883726\n",
      "loss 34.69955174088478\n",
      "loss 36.84181564331055\n",
      "loss 38.98063856959343\n",
      "loss 41.142281826734546\n",
      "loss 43.30542523860932\n",
      "loss 45.514753452539445\n",
      "loss 47.73860127210617\n",
      "loss 49.94930575370788\n",
      "loss 52.16812524676323\n",
      "loss 54.38536410808563\n",
      "loss 56.65172819972038\n",
      "loss 58.935308876037595\n",
      "loss 61.231287460327145\n",
      "loss 63.51309198260307\n",
      "loss 65.81423522949218\n",
      "loss 68.08577152490616\n",
      "loss 70.41086342692375\n",
      "loss 72.73396667003631\n",
      "loss 75.11825546264649\n",
      "loss 77.48829150438308\n",
      "loss 79.84618240475655\n",
      "loss 82.22435580849647\n",
      "loss 84.63215351223946\n",
      "loss 87.01061874985695\n",
      "loss 89.44186880588532\n",
      "loss 91.90268630981446\n",
      "loss 94.33175998330117\n",
      "Epoch:  16\n",
      "training loss =  2.146871572294636\n",
      "Validation Loss: 2.2288\tTop 1 Validation Accuracy: 0.6236\t Top 5 Validation Accuracy: 0.8098\n",
      "loss 1.7614156436920165\n",
      "loss 3.4948622691631317\n",
      "loss 5.248893104791641\n",
      "loss 6.9679353559017185\n",
      "loss 8.767870439291\n",
      "loss 10.580063483715058\n",
      "loss 12.434291166067123\n",
      "loss 14.338308000564576\n",
      "loss 16.240299669504164\n",
      "loss 18.159113359451293\n",
      "loss 20.10605421066284\n",
      "loss 22.104035897254946\n",
      "loss 24.094545212984084\n",
      "loss 26.096440155506134\n",
      "loss 28.169052486419677\n",
      "loss 30.253988844156265\n",
      "loss 32.331840953826905\n",
      "loss 34.46940535545349\n",
      "loss 36.59209053754807\n",
      "loss 38.68002527832985\n",
      "loss 40.83433916926384\n",
      "loss 43.01938195228577\n",
      "loss 45.17463172078133\n",
      "loss 47.38753834247589\n",
      "loss 49.58832793831825\n",
      "loss 51.786033834218976\n",
      "loss 54.02700244069099\n",
      "loss 56.294573869705204\n",
      "loss 58.564667669534686\n",
      "loss 60.83708501577377\n",
      "loss 63.148237863779066\n",
      "loss 65.47419775128364\n",
      "loss 67.79264637947082\n",
      "loss 70.10868026971816\n",
      "loss 72.49519238948822\n",
      "loss 74.83561116218567\n",
      "loss 77.17818886995316\n",
      "loss 79.55154724359512\n",
      "loss 81.91519169330597\n",
      "loss 84.29788479566574\n",
      "loss 86.6747707426548\n",
      "loss 89.08484479308129\n",
      "loss 91.48770486474037\n",
      "loss 93.86537432789802\n",
      "Epoch:  17\n",
      "training loss =  2.1361961047623113\n",
      "Validation Loss: 1.9894\tTop 1 Validation Accuracy: 0.6613\t Top 5 Validation Accuracy: 0.8471\n",
      "loss 1.7438879787921906\n",
      "loss 3.4761714446544647\n",
      "loss 5.22015983581543\n",
      "loss 6.978919357061386\n",
      "loss 8.75990014910698\n",
      "loss 10.580616766214371\n",
      "loss 12.434315701723099\n",
      "loss 14.31828140616417\n",
      "loss 16.217029571533203\n",
      "loss 18.101448702812196\n",
      "loss 19.999322292804717\n",
      "loss 21.972105211019517\n",
      "loss 23.975297561883927\n",
      "loss 26.005543723106385\n",
      "loss 28.050337033271788\n",
      "loss 30.08613893032074\n",
      "loss 32.16201903820038\n",
      "loss 34.22526586174965\n",
      "loss 36.37717979073525\n",
      "loss 38.53294953584671\n",
      "loss 40.67798655152321\n",
      "loss 42.78854302287102\n",
      "loss 44.97529071092605\n",
      "loss 47.16807162284851\n",
      "loss 49.370234158039096\n",
      "loss 51.57433798313141\n",
      "loss 53.77748951792717\n",
      "loss 60.55846076607704\n",
      "loss 62.87040174841881\n",
      "loss 65.17937959194184\n",
      "loss 67.48260965585709\n",
      "loss 69.77743708968163\n",
      "loss 72.09103906154633\n",
      "loss 74.42715112805367\n",
      "loss 76.83245108366013\n",
      "loss 79.20246720075608\n",
      "loss 81.55550686359406\n",
      "loss 83.95299908995628\n",
      "loss 86.33770210385323\n",
      "loss 88.79191242337227\n",
      "loss 91.2132611656189\n",
      "loss 93.62170561313629\n",
      "Epoch:  18\n",
      "training loss =  2.1310619577172365\n",
      "Validation Loss: 2.0220\tTop 1 Validation Accuracy: 0.6611\t Top 5 Validation Accuracy: 0.8460\n",
      "loss 1.7689245319366456\n",
      "loss 3.4712395703792573\n",
      "loss 5.203423712253571\n",
      "loss 6.943206279277802\n",
      "loss 8.738612051010131\n",
      "loss 10.563771104812622\n",
      "loss 12.408124190568923\n",
      "loss 14.296463735103607\n",
      "loss 16.147790067195892\n",
      "loss 18.06511113166809\n",
      "loss 20.019547562599183\n",
      "loss 22.002760019302368\n",
      "loss 23.949361977577208\n",
      "loss 25.973550152778625\n",
      "loss 27.993578437566757\n",
      "loss 30.02890776991844\n",
      "loss 32.099671298265456\n",
      "loss 34.20741695046425\n",
      "loss 36.32799037098884\n",
      "loss 38.44022764801979\n",
      "loss 40.55843019962311\n",
      "loss 42.69742438316345\n",
      "loss 44.872071908712385\n",
      "loss 47.04373650789261\n",
      "loss 49.214238057136534\n",
      "loss 51.430765186548236\n",
      "loss 53.662556307315825\n",
      "loss 55.887155312299726\n",
      "loss 58.16088828921318\n",
      "loss 60.406021341085435\n",
      "loss 62.721951043605806\n",
      "loss 65.02152182102203\n",
      "loss 67.32750319838524\n",
      "loss 69.64859704494476\n",
      "loss 71.97070481061935\n",
      "loss 74.33137747168541\n",
      "loss 76.66933786034583\n",
      "loss 79.06085840940476\n",
      "loss 81.40883992791176\n",
      "loss 83.80046343445778\n",
      "loss 86.16451407194137\n",
      "loss 88.51796659708023\n",
      "loss 90.91808185338974\n",
      "loss 93.3257237482071\n",
      "Epoch:  19\n",
      "training loss =  2.124511238588814\n",
      "Validation Loss: 1.9195\tTop 1 Validation Accuracy: 0.6685\t Top 5 Validation Accuracy: 0.8509\n",
      "loss 1.7662308382987977\n",
      "loss 3.471060538291931\n",
      "loss 5.161354751586914\n",
      "loss 6.931419625282287\n",
      "loss 8.706242281198502\n",
      "loss 10.485197989940643\n",
      "loss 12.32036861538887\n",
      "loss 14.180799815654755\n",
      "loss 16.04142901659012\n",
      "loss 17.958019382953644\n",
      "loss 19.910790036916733\n",
      "loss 21.837216341495512\n",
      "loss 23.782414741516114\n",
      "loss 25.79088212609291\n",
      "loss 27.811332451105116\n",
      "loss 29.836093854904174\n",
      "loss 31.946693198680876\n",
      "loss 34.04026290416718\n",
      "loss 36.13458826065064\n",
      "loss 38.289493017196655\n",
      "loss 40.39578734278679\n",
      "loss 42.588603074550626\n",
      "loss 44.755623272657395\n",
      "loss 46.977398593425754\n",
      "loss 49.14081741571427\n",
      "loss 51.34153770804405\n",
      "loss 53.54431061029434\n",
      "loss 55.78505250453949\n",
      "loss 57.99902670383453\n",
      "loss 60.226974769830704\n",
      "loss 62.508986196517945\n",
      "loss 64.78174110889435\n",
      "loss 67.0615508544445\n",
      "loss 69.37485967040062\n",
      "loss 71.69545745015144\n",
      "loss 74.0070456290245\n",
      "loss 76.37917135357857\n",
      "loss 78.72027077436447\n",
      "loss 81.06272959470749\n",
      "loss 83.41640975356103\n",
      "loss 85.78969476222991\n",
      "loss 88.17573355913163\n",
      "loss 90.57768808364868\n",
      "loss 92.98743860721588\n",
      "Epoch:  20\n",
      "training loss =  2.1167109688132\n",
      "Validation Loss: 1.8211\tTop 1 Validation Accuracy: 0.6760\t Top 5 Validation Accuracy: 0.8583\n",
      "loss 1.7223964726924896\n",
      "loss 3.3903591513633726\n",
      "loss 5.096560163497925\n",
      "loss 6.831006430387497\n",
      "loss 8.625260887145997\n",
      "loss 10.404465702772141\n",
      "loss 12.249536046981811\n",
      "loss 14.092006176710129\n",
      "loss 15.968722956180573\n",
      "loss 17.865588552951813\n",
      "loss 19.747463287115096\n",
      "loss 21.695631328821182\n",
      "loss 23.669930355548857\n",
      "loss 25.688978193998338\n",
      "loss 27.677519013881682\n",
      "loss 29.720297548770905\n",
      "loss 31.786364151239397\n",
      "loss 33.86308991909027\n",
      "loss 35.926157891750336\n",
      "loss 38.04250871062279\n",
      "loss 40.15728114843368\n",
      "loss 42.30328422784805\n",
      "loss 44.43842839002609\n",
      "loss 46.58544997096062\n",
      "loss 48.81492092370987\n",
      "loss 51.049590219259265\n",
      "loss 53.21780990600586\n",
      "loss 55.445403988361356\n",
      "loss 57.71185203313828\n",
      "loss 59.99726482033729\n",
      "loss 62.279239901304244\n",
      "loss 64.5405429804325\n",
      "loss 66.88070266246795\n",
      "loss 69.19097060918808\n",
      "loss 71.47814974188805\n",
      "loss 73.76411821603774\n",
      "loss 76.10106245875359\n",
      "loss 78.45740139245987\n",
      "loss 80.7886866223812\n",
      "loss 83.17084125638009\n",
      "loss 85.53601759076119\n",
      "loss 87.8746971654892\n",
      "loss 90.2647298169136\n",
      "loss 92.65664910078048\n",
      "Epoch:  21\n",
      "training loss =  2.108680914299178\n",
      "Validation Loss: 1.9545\tTop 1 Validation Accuracy: 0.6595\t Top 5 Validation Accuracy: 0.8455\n",
      "loss 1.7224915647506713\n",
      "loss 3.4456370842456816\n",
      "loss 5.1352842390537266\n",
      "loss 6.856042867898941\n",
      "loss 8.644252088069916\n",
      "loss 10.445723022222518\n",
      "loss 15.892836655378341\n",
      "loss 17.75162542939186\n",
      "loss 19.68519420146942\n",
      "loss 21.62291130065918\n",
      "loss 23.578873633146287\n",
      "loss 25.57862053513527\n",
      "loss 27.577741936445236\n",
      "loss 29.5825113260746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 31.63060555934906\n",
      "loss 33.71944102168083\n",
      "loss 35.810155124664306\n",
      "loss 37.89219779729843\n",
      "loss 40.041401578187944\n",
      "loss 42.14710013628006\n",
      "loss 44.292159821987156\n",
      "loss 46.48642778992653\n",
      "loss 48.66945001125336\n",
      "loss 50.847321937084196\n",
      "loss 53.0591305243969\n",
      "loss 55.34207416892052\n",
      "loss 57.59782230138779\n",
      "loss 59.83480796098709\n",
      "loss 62.124793112277985\n",
      "loss 64.41624012351036\n",
      "loss 66.74943262815475\n",
      "loss 69.0486149930954\n",
      "loss 71.35802935004234\n",
      "loss 73.68935399532319\n",
      "loss 76.00702236056328\n",
      "loss 78.29294698238373\n",
      "loss 80.61603753924369\n",
      "loss 82.93476153969765\n",
      "loss 85.26970875382423\n",
      "loss 87.65628899216652\n",
      "loss 90.03774617910385\n",
      "loss 92.43906639695167\n",
      "Epoch:  22\n",
      "training loss =  2.104485863778252\n",
      "Validation Loss: 1.8866\tTop 1 Validation Accuracy: 0.6695\t Top 5 Validation Accuracy: 0.8518\n",
      "loss 1.7312345933914184\n",
      "loss 3.409169718027115\n",
      "loss 5.075835098028183\n",
      "loss 6.76614074587822\n",
      "loss 8.550625054836273\n",
      "loss 10.335579771995544\n",
      "loss 12.147730456590653\n",
      "loss 13.949264795780183\n",
      "loss 15.797476999759674\n",
      "loss 17.672659285068512\n",
      "loss 19.58627469778061\n",
      "loss 21.53316512465477\n",
      "loss 23.455636755228042\n",
      "loss 25.39691886663437\n",
      "loss 27.37218584060669\n",
      "loss 29.399264456033706\n",
      "loss 31.480121426582336\n",
      "loss 33.530653990507126\n",
      "loss 35.62525558948517\n",
      "loss 37.72599999666214\n",
      "loss 39.84661790847778\n",
      "loss 41.97270293354988\n",
      "loss 44.10940732836723\n",
      "loss 46.26965961456299\n",
      "loss 48.46499773025513\n",
      "loss 50.688152426481246\n",
      "loss 52.877122975587845\n",
      "loss 55.09021867156029\n",
      "loss 57.34259399652481\n",
      "loss 59.56618407607078\n",
      "loss 61.83669940471649\n",
      "loss 64.1462139236927\n",
      "loss 66.42810570001602\n",
      "loss 68.72563866972924\n",
      "loss 71.0167672431469\n",
      "loss 73.299226385355\n",
      "loss 77.9953828239441\n",
      "loss 80.33786951303482\n",
      "loss 82.71665795564651\n",
      "loss 85.08691515803338\n",
      "loss 87.40833000779152\n",
      "loss 89.79317903876304\n",
      "loss 92.21987176775933\n",
      "Epoch:  23\n",
      "training loss =  2.099943398491088\n",
      "Validation Loss: 2.1288\tTop 1 Validation Accuracy: 0.6404\t Top 5 Validation Accuracy: 0.8237\n",
      "loss 1.6982453966140747\n",
      "loss 3.3501919746398925\n",
      "loss 5.072118512392044\n",
      "loss 6.802282692193985\n",
      "loss 8.55329253435135\n",
      "loss 10.312410712242126\n",
      "loss 12.132183079719544\n",
      "loss 13.961852077245712\n",
      "loss 15.809880766868591\n",
      "loss 17.68946818828583\n",
      "loss 19.618511157035826\n",
      "loss 21.52722722530365\n",
      "loss 23.45649015903473\n",
      "loss 25.434594451189042\n",
      "loss 27.399712923765183\n",
      "loss 29.41118111848831\n",
      "loss 31.462763979434968\n",
      "loss 33.54296928405762\n",
      "loss 35.60570647597313\n",
      "loss 37.69126682639122\n",
      "loss 39.805825833082196\n",
      "loss 41.95510190010071\n",
      "loss 44.11787635564804\n",
      "loss 46.31679725289345\n",
      "loss 48.50675536632538\n",
      "loss 50.68865894317627\n",
      "loss 52.92366156339645\n",
      "loss 55.15433353543281\n",
      "loss 57.36172052502632\n",
      "loss 59.60426934719086\n",
      "loss 61.8783322262764\n",
      "loss 64.12104248523713\n",
      "loss 66.40509858965873\n",
      "loss 68.68573355197907\n",
      "loss 70.96648815631866\n",
      "loss 73.32103469848633\n",
      "loss 75.63091143965721\n",
      "loss 77.93247715353965\n",
      "loss 80.2717512011528\n",
      "loss 82.63274622321129\n",
      "loss 84.99610451102257\n",
      "loss 87.3218228495121\n",
      "loss 89.71881592273712\n",
      "loss 92.12058219790458\n",
      "Epoch:  24\n",
      "training loss =  2.0970210987770455\n",
      "Validation Loss: 2.0499\tTop 1 Validation Accuracy: 0.6464\t Top 5 Validation Accuracy: 0.8304\n",
      "loss 1.6700721383094788\n",
      "loss 3.33995775103569\n",
      "loss 5.028943145275116\n",
      "loss 6.719221369028092\n",
      "loss 8.485111141204834\n",
      "loss 10.266310883760452\n",
      "loss 12.0453992497921\n",
      "loss 13.842386747598647\n",
      "loss 15.689408943653106\n",
      "loss 17.54989920258522\n",
      "loss 19.47731047153473\n",
      "loss 21.435412136316298\n",
      "loss 23.38282069683075\n",
      "loss 25.308102478981017\n",
      "loss 27.292302268743516\n",
      "loss 29.291807494163514\n",
      "loss 31.33066263437271\n",
      "loss 33.40043344140053\n",
      "loss 35.5059595477581\n",
      "loss 37.60710210800171\n",
      "loss 39.70017816781998\n",
      "loss 41.804070454835895\n",
      "loss 43.94020870089531\n",
      "loss 46.118718039989474\n",
      "loss 48.28443031311035\n",
      "loss 50.485753729343415\n",
      "loss 52.71100784659386\n",
      "loss 54.89929017901421\n",
      "loss 57.13212386846542\n",
      "loss 59.36716679811477\n",
      "loss 61.60954612255097\n",
      "loss 63.86120157003403\n",
      "loss 66.16696026325226\n",
      "loss 68.50002126574516\n",
      "loss 70.82770111680031\n",
      "loss 73.15519853472709\n",
      "loss 75.48333489179612\n",
      "loss 77.81988506436348\n",
      "loss 80.1451231789589\n",
      "loss 82.4587762606144\n",
      "loss 84.81279567718506\n",
      "loss 87.1466994547844\n",
      "loss 89.47767651915551\n",
      "loss 91.89135637402535\n",
      "Epoch:  25\n",
      "training loss =  2.091382221127993\n",
      "Validation Loss: 2.0547\tTop 1 Validation Accuracy: 0.6479\t Top 5 Validation Accuracy: 0.8308\n",
      "loss 1.5958932054042816\n",
      "loss 5.734547029733658\n",
      "loss 7.03706410586834\n",
      "loss 8.305533905029296\n",
      "loss 9.60263886153698\n",
      "loss 10.840442596077919\n",
      "loss 12.05137472510338\n",
      "loss 13.246608573794365\n",
      "loss 14.44683137178421\n",
      "loss 15.643092330694198\n",
      "loss 16.81331901013851\n",
      "loss 17.992625694274903\n",
      "loss 19.13247481763363\n",
      "loss 20.262270948886872\n",
      "loss 21.418391771912574\n",
      "loss 22.544082410931587\n",
      "loss 23.663449692726136\n",
      "loss 24.776806874871255\n",
      "loss 25.895049104094504\n",
      "loss 26.990088644623757\n",
      "loss 28.085269576311113\n",
      "loss 29.166608929634094\n",
      "loss 30.259533999562265\n",
      "loss 31.349303351044654\n",
      "loss 32.44759876549244\n",
      "loss 33.51220221102238\n",
      "loss 34.590296783447265\n",
      "loss 35.64887713611126\n",
      "loss 36.746514980196956\n",
      "loss 37.83439234137535\n",
      "loss 38.908537388443946\n",
      "loss 39.992217209339145\n",
      "loss 41.0658228212595\n",
      "loss 42.116324576735494\n",
      "loss 43.16083323538303\n",
      "loss 44.183967708945275\n",
      "loss 45.220085300803184\n",
      "loss 46.24118272006512\n",
      "loss 47.302305151820185\n",
      "loss 48.322232060432434\n",
      "loss 49.374829320907594\n",
      "loss 50.412194092273715\n",
      "Epoch:  26\n",
      "training loss =  1.1446571137922814\n",
      "Validation Loss: 1.0303\tTop 1 Validation Accuracy: 0.7936\t Top 5 Validation Accuracy: 0.9392\n",
      "loss 0.8914635092020035\n",
      "loss 1.7939617675542832\n",
      "loss 2.682672708630562\n",
      "loss 3.6052681297063827\n",
      "loss 4.535041633248329\n",
      "loss 5.436929441690445\n",
      "loss 6.35372871696949\n",
      "loss 7.253164623975754\n",
      "loss 8.176701660752297\n",
      "loss 9.060996861457825\n",
      "loss 9.986474264860153\n",
      "loss 10.903506917953491\n",
      "loss 11.809845706224442\n",
      "loss 12.733047075867653\n",
      "loss 13.646509313583374\n",
      "loss 14.574812648296357\n",
      "loss 15.461657434105874\n",
      "loss 16.369593242406847\n",
      "loss 18.17414966702461\n",
      "loss 19.105988383293152\n",
      "loss 20.02547251522541\n",
      "loss 20.929690485596655\n",
      "loss 21.85858605504036\n",
      "loss 22.784575521945953\n",
      "loss 23.7094056981802\n",
      "loss 24.62803175806999\n",
      "loss 25.555215843319893\n",
      "loss 26.464057791233063\n",
      "loss 27.38100736796856\n",
      "loss 28.29307711482048\n",
      "loss 29.2124647128582\n",
      "loss 30.121876502037047\n",
      "loss 31.050135179162027\n",
      "loss 31.962172545790672\n",
      "loss 32.876526965498925\n",
      "loss 33.779961350560185\n",
      "loss 34.70669958293438\n",
      "loss 35.61359434306622\n",
      "loss 36.53892354667187\n",
      "loss 37.444214362502095\n",
      "loss 38.346142607331274\n",
      "loss 39.25901178956032\n",
      "loss 40.169456335306165\n",
      "Epoch:  27\n",
      "training loss =  0.9129931487499904\n",
      "Validation Loss: 1.0020\tTop 1 Validation Accuracy: 0.7994\t Top 5 Validation Accuracy: 0.9434\n",
      "loss 0.8097028595209121\n",
      "loss 1.5977326399087906\n",
      "loss 2.3938801062107085\n",
      "loss 3.207832815051079\n",
      "loss 4.014805995821953\n",
      "loss 4.816040493845939\n",
      "loss 5.633959946632385\n",
      "loss 6.435626517534256\n",
      "loss 7.256525350809097\n",
      "loss 8.051344435811043\n",
      "loss 8.864904032945633\n",
      "loss 9.674342721700668\n",
      "loss 10.495011444687844\n",
      "loss 11.316147813796997\n",
      "loss 12.147123072743415\n",
      "loss 12.986167170405388\n",
      "loss 13.805595827698708\n",
      "loss 14.607624199986457\n",
      "loss 15.438720855116845\n",
      "loss 16.263302326202393\n",
      "loss 17.086898600459097\n",
      "loss 17.926516638994215\n",
      "loss 18.759514080882074\n",
      "loss 19.56910435140133\n",
      "loss 20.387694766521452\n",
      "loss 21.205179602503776\n",
      "loss 22.012929655313492\n",
      "loss 22.835311007499694\n",
      "loss 23.656886753439903\n",
      "loss 24.47647605776787\n",
      "loss 25.309450121521948\n",
      "loss 26.156829226017\n",
      "loss 26.982977755069733\n",
      "loss 27.81248429775238\n",
      "loss 28.66186839938164\n",
      "loss 29.492600619196892\n",
      "loss 30.3427588647604\n",
      "loss 31.169720112085344\n",
      "loss 32.02249244749546\n",
      "loss 32.878836050629616\n",
      "loss 33.7277316904068\n",
      "loss 34.54941795885563\n",
      "loss 35.3898155605793\n",
      "loss 36.22343914151192\n",
      "Epoch:  28\n",
      "training loss =  0.8233929663286709\n",
      "Validation Loss: 0.9721\tTop 1 Validation Accuracy: 0.8019\t Top 5 Validation Accuracy: 0.9448\n",
      "loss 0.7299736812710762\n",
      "loss 1.4550953486561775\n",
      "loss 2.200293565392494\n",
      "loss 2.9401643204689027\n",
      "loss 3.6798305636644364\n",
      "loss 4.425560007095337\n",
      "loss 5.1785174161195755\n",
      "loss 5.924329753518105\n",
      "loss 6.673101179003716\n",
      "loss 7.419665884971619\n",
      "loss 8.146028581857681\n",
      "loss 8.895433738827705\n",
      "loss 9.64065834224224\n",
      "loss 10.421102015972137\n",
      "loss 11.181374838352204\n",
      "loss 11.955189280509948\n",
      "loss 12.712620837688446\n",
      "loss 13.469119067192077\n",
      "loss 14.21727358698845\n",
      "loss 14.982735142707824\n",
      "loss 15.729438126683235\n",
      "loss 16.4920977050066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 17.25132340967655\n",
      "loss 18.017472996115686\n",
      "loss 18.77618090212345\n",
      "loss 19.558118115067483\n",
      "loss 20.323514173030855\n",
      "loss 21.091282893419265\n",
      "loss 21.855398855507374\n",
      "loss 22.627952509224414\n",
      "loss 23.40402360767126\n",
      "loss 24.18343478292227\n",
      "loss 24.948855155706404\n",
      "loss 25.721387891173364\n",
      "loss 26.49979249179363\n",
      "loss 27.289563154578207\n",
      "loss 28.071989691853524\n",
      "loss 28.862769967615606\n",
      "loss 29.652802599966527\n",
      "loss 30.43570271641016\n",
      "loss 31.227389580905438\n",
      "loss 32.0110476449132\n",
      "loss 32.79194813340902\n",
      "loss 33.60332978636026\n",
      "Epoch:  29\n",
      "training loss =  0.764216388608194\n",
      "Validation Loss: 0.9698\tTop 1 Validation Accuracy: 0.8043\t Top 5 Validation Accuracy: 0.9470\n",
      "loss 0.6668948403000832\n",
      "loss 1.3435235899686813\n",
      "loss 2.041165782213211\n",
      "loss 2.709504510164261\n",
      "loss 3.397061396241188\n",
      "loss 4.094471094012261\n",
      "loss 4.77429977029562\n",
      "loss 5.452934154868126\n",
      "loss 6.151745945811272\n",
      "loss 6.8476156482100485\n",
      "loss 7.549411516189576\n",
      "loss 8.255317469835282\n",
      "loss 8.971371530294418\n",
      "loss 9.658212115764618\n",
      "loss 10.342692517638206\n",
      "loss 11.05601467192173\n",
      "loss 11.766736053824424\n",
      "loss 12.477531201541424\n",
      "loss 13.200914799273015\n",
      "loss 13.912927998006344\n",
      "loss 14.645223152339458\n",
      "loss 15.36367321819067\n",
      "loss 16.077735914886\n",
      "loss 16.789230878949166\n",
      "loss 17.522503450512886\n",
      "loss 18.23628051519394\n",
      "loss 18.968117722272872\n",
      "loss 19.699277504086496\n",
      "loss 20.440630028247835\n",
      "loss 21.17663204371929\n",
      "loss 21.895892038941383\n",
      "loss 22.61483155578375\n",
      "loss 23.341293931305408\n",
      "loss 24.079570640027523\n",
      "loss 24.80715500921011\n",
      "loss 25.555996758043765\n",
      "loss 27.036153925657274\n",
      "loss 27.766324166059494\n",
      "loss 28.484880592226983\n",
      "loss 29.218446984887123\n",
      "loss 29.949110203981398\n",
      "loss 30.691289666295052\n",
      "loss 31.450065712332727\n",
      "Epoch:  30\n",
      "training loss =  0.7152869332257565\n",
      "Validation Loss: 0.9988\tTop 1 Validation Accuracy: 0.8022\t Top 5 Validation Accuracy: 0.9461\n",
      "loss 0.6328416174650192\n",
      "loss 1.258964846432209\n",
      "loss 1.8893014243245125\n",
      "loss 2.54257260799408\n",
      "loss 3.186602231860161\n",
      "loss 3.8542068070173263\n",
      "loss 4.510519490838051\n",
      "loss 5.167756293416023\n",
      "loss 5.8227035629749295\n",
      "loss 6.486924639940262\n",
      "loss 7.144214544594288\n",
      "loss 7.804787333905697\n",
      "loss 8.460445645451546\n",
      "loss 9.114722877442837\n",
      "loss 9.781477468311786\n",
      "loss 10.44617815196514\n",
      "loss 11.117687473595142\n",
      "loss 11.79727941840887\n",
      "loss 12.47917862534523\n",
      "loss 13.164450703561306\n",
      "loss 13.850041945874692\n",
      "loss 14.525656409263611\n",
      "loss 15.206485110223293\n",
      "loss 15.886888668239116\n",
      "loss 16.582744007408618\n",
      "loss 17.26476991057396\n",
      "loss 17.959638269543646\n",
      "loss 18.64238512724638\n",
      "loss 19.32936408340931\n",
      "loss 20.02228063285351\n",
      "loss 20.712842557132245\n",
      "loss 21.40091078132391\n",
      "loss 22.107506734132766\n",
      "loss 22.794162804782392\n",
      "loss 23.511740139424802\n",
      "loss 24.218470501601697\n",
      "loss 24.917685478627682\n",
      "loss 25.61879789918661\n",
      "loss 26.31695888131857\n",
      "loss 27.029080134928225\n",
      "loss 27.738498478233815\n",
      "loss 28.460304177701474\n",
      "loss 29.183204702436925\n",
      "loss 29.884988992214204\n",
      "Epoch:  31\n",
      "training loss =  0.6794439594290459\n",
      "Validation Loss: 1.0033\tTop 1 Validation Accuracy: 0.8015\t Top 5 Validation Accuracy: 0.9451\n",
      "loss 0.6078688892722129\n",
      "loss 1.2304909813404084\n",
      "loss 1.8308570843935013\n",
      "loss 2.4414182835817337\n",
      "loss 3.05560991615057\n",
      "loss 3.6845062246918676\n",
      "loss 4.308506865799427\n",
      "loss 4.926776487529278\n",
      "loss 5.548868758082389\n",
      "loss 6.186339915990829\n",
      "loss 6.817763800919056\n",
      "loss 7.440788324177265\n",
      "loss 8.076623835265636\n",
      "loss 8.715945255458355\n",
      "loss 9.362579887211323\n",
      "loss 10.00083396166563\n",
      "loss 10.637268175184726\n",
      "loss 11.282395330071449\n",
      "loss 11.946221405267716\n",
      "loss 12.5956565746665\n",
      "loss 13.246810422539712\n",
      "loss 13.894402174949645\n",
      "loss 14.543900018930435\n",
      "loss 15.187203002870083\n",
      "loss 15.830997578501702\n",
      "loss 16.491089619994163\n",
      "loss 17.157802377939223\n",
      "loss 17.807248841822148\n",
      "loss 18.47588415503502\n",
      "loss 19.141648876070978\n",
      "loss 19.806030826568602\n",
      "loss 20.46834312915802\n",
      "loss 21.133758580684663\n",
      "loss 21.78827936351299\n",
      "loss 22.45461770683527\n",
      "loss 23.123540815114975\n",
      "loss 23.791628196239472\n",
      "loss 24.45735850840807\n",
      "loss 25.12385310024023\n",
      "loss 25.80932040274143\n",
      "loss 26.490002721250058\n",
      "loss 27.156930823028087\n",
      "loss 27.832131546139717\n",
      "loss 28.506746922135353\n",
      "Epoch:  32\n",
      "training loss =  0.6482834256188585\n",
      "Validation Loss: 0.9730\tTop 1 Validation Accuracy: 0.8029\t Top 5 Validation Accuracy: 0.9471\n",
      "loss 0.5792689582705498\n",
      "loss 1.1596338921785354\n",
      "loss 1.73765921741724\n",
      "loss 2.3142810437083243\n",
      "loss 2.9018376368284224\n",
      "loss 3.4904328346252442\n",
      "loss 4.099633710086346\n",
      "loss 4.687763223946095\n",
      "loss 5.276211737990379\n",
      "loss 5.873093871772289\n",
      "loss 6.479543687701225\n",
      "loss 7.079742043316364\n",
      "loss 7.665732798576355\n",
      "loss 8.258742874264717\n",
      "loss 8.85374199539423\n",
      "loss 9.468082057535648\n",
      "loss 10.083927845060826\n",
      "loss 10.70394171923399\n",
      "loss 11.32288156658411\n",
      "loss 11.936542661190034\n",
      "loss 12.544447606503963\n",
      "loss 13.173639634549618\n",
      "loss 13.789198841750622\n",
      "loss 14.42037436902523\n",
      "loss 15.048684077858924\n",
      "loss 15.668769477307796\n",
      "loss 16.312774540185927\n",
      "loss 16.948674149215222\n",
      "loss 17.591415628790855\n",
      "loss 18.23460997104645\n",
      "loss 18.87338872760534\n",
      "loss 19.499187322556974\n",
      "loss 20.13494210958481\n",
      "loss 20.76602620065212\n",
      "loss 21.415973981022834\n",
      "loss 22.060601714849472\n",
      "loss 22.723891464471816\n",
      "loss 23.37652233302593\n",
      "loss 24.043387505412102\n",
      "loss 24.704676537811757\n",
      "loss 25.362702760100365\n",
      "loss 26.00117957442999\n",
      "loss 26.66825637549162\n",
      "loss 27.33758144080639\n",
      "Epoch:  33\n",
      "training loss =  0.6216708013441473\n",
      "Validation Loss: 0.9882\tTop 1 Validation Accuracy: 0.8038\t Top 5 Validation Accuracy: 0.9467\n",
      "loss 0.5564631456136704\n",
      "loss 1.1119519212841988\n",
      "loss 1.6807034426927567\n",
      "loss 2.2651206919550897\n",
      "loss 2.827241660356522\n",
      "loss 3.3912815806269645\n",
      "loss 3.9618418169021608\n",
      "loss 4.518667423427105\n",
      "loss 5.0957442197203635\n",
      "loss 5.681593372225762\n",
      "loss 6.262192554473877\n",
      "loss 6.841133170425892\n",
      "loss 7.423041111826897\n",
      "loss 8.001081505417824\n",
      "loss 8.58137625604868\n",
      "loss 9.168136475086213\n",
      "loss 9.763230102956294\n",
      "loss 10.35928750038147\n",
      "loss 10.965266138911247\n",
      "loss 11.559532369673253\n",
      "loss 12.155882196724415\n",
      "loss 12.761232632398606\n",
      "loss 13.363697502315045\n",
      "loss 13.986245664060116\n",
      "loss 14.587056710124015\n",
      "loss 15.197057353854179\n",
      "loss 15.793916026353836\n",
      "loss 16.407022100389003\n",
      "loss 17.018741221129893\n",
      "loss 17.650373624861242\n",
      "loss 18.275260215997697\n",
      "loss 18.891742731630803\n",
      "loss 19.522468805909156\n",
      "loss 20.158786586523057\n",
      "loss 20.789291496276856\n",
      "loss 21.419423878490925\n",
      "loss 22.05233085036278\n",
      "loss 22.69239404410124\n",
      "loss 23.320345737040043\n",
      "loss 23.949029755592345\n",
      "loss 24.582352622747422\n",
      "loss 25.22926004588604\n",
      "loss 25.863931680321695\n",
      "loss 26.517803956866263\n",
      "Epoch:  34\n",
      "training loss =  0.6031168174992955\n",
      "Validation Loss: 0.9810\tTop 1 Validation Accuracy: 0.8060\t Top 5 Validation Accuracy: 0.9488\n",
      "loss 0.5440631264448166\n",
      "loss 1.0753524309396745\n",
      "loss 1.6013032120466233\n",
      "loss 2.1537365543842317\n",
      "loss 2.7178596287965773\n",
      "loss 3.2637638252973558\n",
      "loss 3.826048178970814\n",
      "loss 4.387714114785195\n",
      "loss 4.937412113845348\n",
      "loss 5.486363823413849\n",
      "loss 6.047344522774219\n",
      "loss 6.595627889931202\n",
      "loss 7.175923410654068\n",
      "loss 7.755494525432587\n",
      "loss 8.310615304708481\n",
      "loss 8.8899100959301\n",
      "loss 9.459609486758708\n",
      "loss 10.02656740784645\n",
      "loss 10.607704272270203\n",
      "loss 11.188974063396454\n",
      "loss 11.764001232385635\n",
      "loss 12.354599142670631\n",
      "loss 12.941975970566272\n",
      "loss 13.535662252604961\n",
      "loss 14.129527451694011\n",
      "loss 14.728864363729954\n",
      "loss 15.323781843781472\n",
      "loss 15.925704824030399\n",
      "loss 16.52047484278679\n",
      "loss 17.12400224775076\n",
      "loss 17.718349469602106\n",
      "loss 18.32141389787197\n",
      "loss 18.921354109048842\n",
      "loss 19.52722578048706\n",
      "loss 20.141248193085193\n",
      "loss 20.75224985420704\n",
      "loss 21.37612726718187\n",
      "loss 21.98173276811838\n",
      "loss 22.59478862673044\n",
      "loss 23.213792335391044\n",
      "loss 23.824606285989283\n",
      "loss 24.43677045673132\n",
      "loss 25.07054434508085\n",
      "loss 25.709722757041455\n",
      "Epoch:  35\n",
      "training loss =  0.584856456609316\n",
      "Validation Loss: 0.9971\tTop 1 Validation Accuracy: 0.8052\t Top 5 Validation Accuracy: 0.9481\n",
      "loss 0.523726127743721\n",
      "loss 1.0488083127141\n",
      "loss 1.573647395670414\n",
      "loss 2.1021147346496583\n",
      "loss 2.622748121321201\n",
      "loss 3.1596203941106795\n",
      "loss 3.7061686527729036\n",
      "loss 4.253633248209954\n",
      "loss 4.793047989606857\n",
      "loss 5.331675034165382\n",
      "loss 5.880058251023293\n",
      "loss 6.4337979277968405\n",
      "loss 6.985530240237713\n",
      "loss 7.542038674354553\n",
      "loss 8.095481073856353\n",
      "loss 8.660551735460759\n",
      "loss 9.220681479275227\n",
      "loss 9.802367888092995\n",
      "loss 10.366644982695579\n",
      "loss 10.945474038422107\n",
      "loss 11.520440310835838\n",
      "loss 12.09068595558405\n",
      "loss 12.655171281695367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 13.222921629846097\n",
      "loss 13.787799716591834\n",
      "loss 14.370193922519684\n",
      "loss 14.94114553272724\n",
      "loss 15.527637027204037\n",
      "loss 16.12811576485634\n",
      "loss 16.72051582068205\n",
      "loss 17.319390126764773\n",
      "loss 17.9089672639966\n",
      "loss 18.50238800019026\n",
      "loss 19.099943423271178\n",
      "loss 19.696308417022227\n",
      "loss 20.292447155416014\n",
      "loss 20.90373951792717\n",
      "loss 21.502294678092003\n",
      "loss 22.09537074714899\n",
      "loss 22.708315377533435\n",
      "loss 23.33069517225027\n",
      "loss 23.959388059973715\n",
      "loss 24.581276488006115\n",
      "loss 25.19579944342375\n",
      "Epoch:  36\n",
      "training loss =  0.5731725627541784\n",
      "Validation Loss: 0.9765\tTop 1 Validation Accuracy: 0.8042\t Top 5 Validation Accuracy: 0.9477\n",
      "loss 0.5146600958704949\n",
      "loss 1.0242059740424156\n",
      "loss 1.5500974324345589\n",
      "loss 2.0754282158613204\n",
      "loss 2.587599947154522\n",
      "loss 3.112829033434391\n",
      "loss 3.6272482293844224\n",
      "loss 4.157472320795059\n",
      "loss 4.692126289606095\n",
      "loss 5.226095394194126\n",
      "loss 5.769787258505821\n",
      "loss 6.321131386458874\n",
      "loss 6.868125704526901\n",
      "loss 7.40477543503046\n",
      "loss 7.9471746039390565\n",
      "loss 8.492546265721321\n",
      "loss 9.040059407055377\n",
      "loss 9.597627265751361\n",
      "loss 10.157359430193901\n",
      "loss 10.72344586789608\n",
      "loss 11.287033423185349\n",
      "loss 11.83650963485241\n",
      "loss 12.395811513364315\n",
      "loss 12.968420687019824\n",
      "loss 13.536367988288402\n",
      "loss 14.111524274349213\n",
      "loss 14.676645711362362\n",
      "loss 15.261780200898647\n",
      "loss 15.844059554934502\n",
      "loss 16.416626228392126\n",
      "loss 17.00233388453722\n",
      "loss 17.57706897497177\n",
      "loss 18.16920052587986\n",
      "loss 18.73547487974167\n",
      "loss 19.33488214880228\n",
      "loss 19.91390640705824\n",
      "loss 20.49663728415966\n",
      "loss 21.090933180451394\n",
      "loss 21.690613439083098\n",
      "loss 22.28392149657011\n",
      "loss 22.899171564280987\n",
      "loss 23.484102922677994\n",
      "loss 24.091239076256752\n",
      "loss 24.692859233021736\n",
      "Epoch:  37\n",
      "training loss =  0.5617022605418944\n",
      "Validation Loss: 1.0044\tTop 1 Validation Accuracy: 0.8048\t Top 5 Validation Accuracy: 0.9479\n",
      "loss 0.5090282496809959\n",
      "loss 1.00868979036808\n",
      "loss 1.5148549875617028\n",
      "loss 2.0183660611510277\n",
      "loss 2.5253611320257185\n",
      "loss 3.032449407875538\n",
      "loss 3.5514648535847666\n",
      "loss 4.076875087320804\n",
      "loss 4.59078963547945\n",
      "loss 5.133305366933346\n",
      "loss 5.658629455864429\n",
      "loss 6.187271638810635\n",
      "loss 6.724846020936966\n",
      "loss 7.268711045384407\n",
      "loss 7.802600939571858\n",
      "loss 8.331708745658398\n",
      "loss 8.874883227348327\n",
      "loss 9.422419348657131\n",
      "loss 9.971321099996567\n",
      "loss 10.524762473404408\n",
      "loss 11.073413895666599\n",
      "loss 11.614024409353734\n",
      "loss 12.145755478739739\n",
      "loss 12.71164639800787\n",
      "loss 13.253744149804115\n",
      "loss 13.816897243857383\n",
      "loss 14.394803813397884\n",
      "loss 14.964147983193397\n",
      "loss 15.521539498865604\n",
      "loss 16.087433446347713\n",
      "loss 16.64806919038296\n",
      "loss 17.226071357131005\n",
      "loss 17.813912965357304\n",
      "loss 18.394856916368006\n",
      "loss 18.960516056716443\n",
      "loss 19.544643994271755\n",
      "loss 20.143448687791825\n",
      "loss 20.716613871753214\n",
      "loss 21.313318879008293\n",
      "loss 21.905782098770143\n",
      "loss 22.509225184619428\n",
      "loss 23.10591763794422\n",
      "loss 23.700330978929998\n",
      "loss 24.29428725004196\n",
      "Epoch:  38\n",
      "training loss =  0.5525816084964907\n",
      "Validation Loss: 0.9999\tTop 1 Validation Accuracy: 0.8029\t Top 5 Validation Accuracy: 0.9473\n",
      "loss 0.490845542550087\n",
      "loss 0.9825076347589493\n",
      "loss 1.4697530329227448\n",
      "loss 1.978047717511654\n",
      "loss 2.4750808757543563\n",
      "loss 2.9848911693692206\n",
      "loss 3.486913565993309\n",
      "loss 3.984174299240112\n",
      "loss 4.493952233791351\n",
      "loss 5.014543251395225\n",
      "loss 5.5369697952270505\n",
      "loss 6.068077958524227\n",
      "loss 6.589585005640983\n",
      "loss 7.120878478884697\n",
      "loss 7.647690731585026\n",
      "loss 8.19507100969553\n",
      "loss 8.734420054852963\n",
      "loss 9.25874135673046\n",
      "loss 9.776975551843643\n",
      "loss 10.312554512619972\n",
      "loss 10.858322132825851\n",
      "loss 11.406593747437\n",
      "loss 11.950472899079323\n",
      "loss 12.499753267168998\n",
      "loss 13.042351404428482\n",
      "loss 13.602106198370457\n",
      "loss 14.155286817550659\n",
      "loss 14.71238746523857\n",
      "loss 15.258068479895591\n",
      "loss 15.818424332141877\n",
      "loss 16.38138986825943\n",
      "loss 16.954771030247212\n",
      "loss 17.528075603246688\n",
      "loss 18.092594851851462\n",
      "loss 18.668710834085942\n",
      "loss 19.236450760364534\n",
      "loss 19.804896313548088\n",
      "loss 20.37241038888693\n",
      "loss 20.944443204700946\n",
      "loss 21.52729490697384\n",
      "loss 22.111672723591326\n",
      "loss 22.691803109049797\n",
      "loss 23.280934965014456\n",
      "loss 23.876182766556738\n",
      "Epoch:  39\n",
      "training loss =  0.5431495207144701\n",
      "Validation Loss: 1.0120\tTop 1 Validation Accuracy: 0.8022\t Top 5 Validation Accuracy: 0.9462\n",
      "loss 0.47064942568540574\n",
      "loss 0.9498302912712098\n",
      "loss 1.4394628751277923\n",
      "loss 1.937993541955948\n",
      "loss 2.425130331814289\n",
      "loss 2.9229743084311486\n",
      "loss 3.419872288107872\n",
      "loss 3.922068505883217\n",
      "loss 4.433149822354316\n",
      "loss 4.928828902542591\n",
      "loss 5.432746568918228\n",
      "loss 5.938291808068752\n",
      "loss 6.45655768096447\n",
      "loss 6.972152630090713\n",
      "loss 7.49428368806839\n",
      "loss 8.011731715202332\n",
      "loss 8.547876322567463\n",
      "loss 9.079484922289849\n",
      "loss 9.624925065338612\n",
      "loss 10.169420731067657\n",
      "loss 10.702999089360237\n",
      "loss 11.234227144122123\n",
      "loss 11.777302060127258\n",
      "loss 12.326048784852027\n",
      "loss 12.859558478593826\n",
      "loss 13.409153800010682\n",
      "loss 13.958714961707592\n",
      "loss 14.509850546121598\n",
      "loss 15.056374162137509\n",
      "loss 15.596033097803593\n",
      "loss 16.153245041370393\n",
      "loss 16.703002536892892\n",
      "loss 17.25004860728979\n",
      "loss 17.802336501181127\n",
      "loss 18.361418595016\n",
      "loss 18.93914600431919\n",
      "loss 19.4975487190485\n",
      "loss 20.07030515640974\n",
      "loss 20.660194515287877\n",
      "loss 21.230873010754586\n",
      "loss 21.81555917084217\n",
      "loss 22.389420113265516\n",
      "loss 22.97758951038122\n",
      "loss 23.559601998627187\n",
      "Epoch:  40\n",
      "training loss =  0.5358525852969933\n",
      "Validation Loss: 1.0089\tTop 1 Validation Accuracy: 0.8020\t Top 5 Validation Accuracy: 0.9461\n",
      "loss 0.4810509902238846\n",
      "loss 0.9652856945991516\n",
      "loss 1.4530404832959176\n",
      "loss 1.9343834808468818\n",
      "loss 2.4151471102237703\n",
      "loss 2.920042032599449\n",
      "loss 3.4163480538129805\n",
      "loss 3.9087287718057633\n",
      "loss 4.398140550255776\n",
      "loss 4.899467030465603\n",
      "loss 5.3929528221488\n",
      "loss 5.904537226259708\n",
      "loss 6.411120866835117\n",
      "loss 6.925629158616066\n",
      "loss 7.455749840438366\n",
      "loss 7.975059431493282\n",
      "loss 8.496447596549988\n",
      "loss 9.019407586455346\n",
      "loss 9.544712526202202\n",
      "loss 10.073724437355995\n",
      "loss 10.596958431899548\n",
      "loss 11.125814749598502\n",
      "loss 11.648689345419406\n",
      "loss 12.187022177278996\n",
      "loss 12.735170484483241\n",
      "loss 13.266708062887192\n",
      "loss 13.801829891204834\n",
      "loss 14.345239661633968\n",
      "loss 14.892263077795505\n",
      "loss 15.443781796395779\n",
      "loss 15.987252649366855\n",
      "loss 16.54356291204691\n",
      "loss 17.105980809032918\n",
      "loss 17.662445148825647\n",
      "loss 18.226793401241302\n",
      "loss 18.784142891764642\n",
      "loss 19.35404004216194\n",
      "loss 19.911079301536084\n",
      "loss 20.4694108530879\n",
      "loss 21.056797173023224\n",
      "loss 21.636697821617126\n",
      "loss 22.206778915822508\n",
      "loss 22.788667278289793\n",
      "loss 23.36763051748276\n",
      "Epoch:  41\n",
      "training loss =  0.5315399239887301\n",
      "Validation Loss: 0.9871\tTop 1 Validation Accuracy: 0.8040\t Top 5 Validation Accuracy: 0.9485\n",
      "loss 0.47371585011482237\n",
      "loss 0.9493396806716919\n",
      "loss 1.4367400047183037\n",
      "loss 1.9232979220151902\n",
      "loss 2.416376409828663\n",
      "loss 2.896452395915985\n",
      "loss 3.388453545868397\n",
      "loss 3.878890672922134\n",
      "loss 4.368998610675335\n",
      "loss 4.8751713594794275\n",
      "loss 5.367028550207615\n",
      "loss 5.865453045964241\n",
      "loss 6.377189337909222\n",
      "loss 6.88903946518898\n",
      "loss 7.398529841005802\n",
      "loss 7.913947359621525\n",
      "loss 8.432403793632984\n",
      "loss 8.946885229945183\n",
      "loss 9.473950356245041\n",
      "loss 9.983120207488536\n",
      "loss 10.50582325309515\n",
      "loss 11.020877672433853\n",
      "loss 11.552688460946083\n",
      "loss 12.094968178868294\n",
      "loss 12.614220239520073\n",
      "loss 13.148117423057556\n",
      "loss 13.691241219639778\n",
      "loss 14.227331271767616\n",
      "loss 14.758167263269424\n",
      "loss 15.309433817863464\n",
      "loss 15.851929875612258\n",
      "loss 17.483438046872617\n",
      "loss 18.049090415239334\n",
      "loss 18.601420516073702\n",
      "loss 19.15935487449169\n",
      "loss 19.716925885379315\n",
      "loss 20.285829200148584\n",
      "loss 20.86535602092743\n",
      "loss 21.41840866744518\n",
      "loss 21.982004891633988\n",
      "loss 22.54155473858118\n",
      "loss 23.1266094404459\n",
      "Epoch:  42\n",
      "training loss =  0.5261582839025227\n",
      "Validation Loss: 1.0035\tTop 1 Validation Accuracy: 0.8025\t Top 5 Validation Accuracy: 0.9463\n",
      "loss 0.4683948424458504\n",
      "loss 0.95013357847929\n",
      "loss 1.4279503318667413\n",
      "loss 1.892887347638607\n",
      "loss 2.3672583895921706\n",
      "loss 2.8388384142518044\n",
      "loss 3.3245390319824217\n",
      "loss 3.8099627631902693\n",
      "loss 4.297176427841187\n",
      "loss 4.770606915056706\n",
      "loss 5.269136418998241\n",
      "loss 5.757829889953136\n",
      "loss 6.247085938155651\n",
      "loss 6.757417047917843\n",
      "loss 7.274435235857964\n",
      "loss 7.778825799822807\n",
      "loss 8.285925854742526\n",
      "loss 8.797178402245045\n",
      "loss 9.322469829916955\n",
      "loss 9.846713961660862\n",
      "loss 10.363816553354264\n",
      "loss 10.868035709261894\n",
      "loss 11.395194082260131\n",
      "loss 11.913100299835206\n",
      "loss 12.429314255416394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 12.96856595814228\n",
      "loss 13.502764807343484\n",
      "loss 14.03342140197754\n",
      "loss 14.576700930297374\n",
      "loss 15.103470245301724\n",
      "loss 15.641306881606578\n",
      "loss 16.19576963573694\n",
      "loss 16.749878614246846\n",
      "loss 17.303910370469094\n",
      "loss 17.859984980821608\n",
      "loss 18.40901926547289\n",
      "loss 18.95921140640974\n",
      "loss 19.51164209663868\n",
      "loss 20.059511937499046\n",
      "loss 20.627392826974393\n",
      "loss 21.193562412559984\n",
      "loss 21.766646702885627\n",
      "loss 22.330784825980665\n",
      "loss 22.90411852389574\n",
      "Epoch:  43\n",
      "training loss =  0.5210421128449398\n",
      "Validation Loss: 1.0098\tTop 1 Validation Accuracy: 0.7999\t Top 5 Validation Accuracy: 0.9458\n",
      "loss 0.4680595675110817\n",
      "loss 0.9317349517345428\n",
      "loss 1.40240732640028\n",
      "loss 1.8702544045448304\n",
      "loss 2.3448218619823455\n",
      "loss 2.8109668895602224\n",
      "loss 3.286072380542755\n",
      "loss 3.7521166905760763\n",
      "loss 4.241350918114185\n",
      "loss 4.721282683312893\n",
      "loss 5.209665921628475\n",
      "loss 5.696294907033444\n",
      "loss 6.183943541347981\n",
      "loss 6.689575497210026\n",
      "loss 7.194012448191643\n",
      "loss 7.698284486532211\n",
      "loss 8.199379979372024\n",
      "loss 8.721120643317699\n",
      "loss 9.218877461850644\n",
      "loss 9.72532466262579\n",
      "loss 10.236433466672898\n",
      "loss 10.765197724997996\n",
      "loss 11.292564097940922\n",
      "loss 11.823434939682484\n",
      "loss 12.332378568053246\n",
      "loss 12.86396283209324\n",
      "loss 13.397544217705727\n",
      "loss 13.92584546416998\n",
      "loss 14.458252952992916\n",
      "loss 15.000123880803585\n",
      "loss 15.540786884129048\n",
      "loss 16.087354535758497\n",
      "loss 16.62372005045414\n",
      "loss 17.178864259719848\n",
      "loss 17.733688308000566\n",
      "loss 18.293258805274963\n",
      "loss 18.853467028439045\n",
      "loss 19.407416283488274\n",
      "loss 19.95354190081358\n",
      "loss 20.492892068326473\n",
      "loss 21.054895083904267\n",
      "loss 21.627353811860086\n",
      "loss 22.19017375200987\n",
      "loss 22.757821483612062\n",
      "Epoch:  44\n",
      "training loss =  0.5178409147415372\n",
      "Validation Loss: 1.0104\tTop 1 Validation Accuracy: 0.8004\t Top 5 Validation Accuracy: 0.9462\n",
      "loss 0.4586948052048683\n",
      "loss 0.9135233893990516\n",
      "loss 1.376190499663353\n",
      "loss 1.8391121977567673\n",
      "loss 2.312137818336487\n",
      "loss 2.7846487948298453\n",
      "loss 3.247973363101482\n",
      "loss 3.724900566637516\n",
      "loss 4.2192618492245675\n",
      "loss 4.698095385432243\n",
      "loss 5.187366341650486\n",
      "loss 5.675272610783577\n",
      "loss 6.169841847717762\n",
      "loss 6.67659377604723\n",
      "loss 7.164392096698284\n",
      "loss 8.157672663927078\n",
      "loss 8.667880158126355\n",
      "loss 9.172281958162785\n",
      "loss 9.68427168160677\n",
      "loss 10.202599566280842\n",
      "loss 10.731594571471215\n",
      "loss 11.255150117278099\n",
      "loss 11.77339636862278\n",
      "loss 12.297581965923309\n",
      "loss 12.818875765800476\n",
      "loss 13.348245995342731\n",
      "loss 13.883813244998455\n",
      "loss 14.408147757649422\n",
      "loss 14.949592719376087\n",
      "loss 15.482125780284404\n",
      "loss 16.021012166142462\n",
      "loss 16.557768341600895\n",
      "loss 17.119209520220757\n",
      "loss 17.660452224314213\n",
      "loss 18.208123525679113\n",
      "loss 18.753943453133108\n",
      "loss 19.31413519948721\n",
      "loss 19.86576077669859\n",
      "loss 20.421886426210403\n",
      "loss 20.974057452380656\n",
      "loss 21.516243922114374\n",
      "loss 22.075365477204322\n",
      "loss 22.644050925970078\n",
      "Epoch:  45\n",
      "training loss =  0.5156035395868982\n",
      "Validation Loss: 1.0043\tTop 1 Validation Accuracy: 0.8025\t Top 5 Validation Accuracy: 0.9465\n",
      "loss 0.4590145215392113\n",
      "loss 0.912244901061058\n",
      "loss 1.362426568865776\n",
      "loss 1.8279705640673638\n",
      "loss 2.3005049028992652\n",
      "loss 2.77338448792696\n",
      "loss 3.2390605732798576\n",
      "loss 3.7059840208292005\n",
      "loss 4.18251159965992\n",
      "loss 4.664882344901562\n",
      "loss 5.151197097599506\n",
      "loss 5.636544020175934\n",
      "loss 6.130379005074501\n",
      "loss 6.618452490866185\n",
      "loss 7.113293633759022\n",
      "loss 7.614623016119003\n",
      "loss 8.101080648899078\n",
      "loss 8.586360304653645\n",
      "loss 9.09499327480793\n",
      "loss 9.593679466247558\n",
      "loss 10.085279226899146\n",
      "loss 10.608033304214478\n",
      "loss 11.123951575160026\n",
      "loss 11.650281918644906\n",
      "loss 12.16869045138359\n",
      "loss 12.689754025936127\n",
      "loss 13.196626372933387\n",
      "loss 13.732506133317948\n",
      "loss 14.259997692406177\n",
      "loss 14.801182288229466\n",
      "loss 15.339361227154733\n",
      "loss 15.87793981820345\n",
      "loss 16.42781406581402\n",
      "loss 16.971421633064747\n",
      "loss 17.527123662233354\n",
      "loss 18.075308275222778\n",
      "loss 18.616537811756135\n",
      "loss 19.17264598697424\n",
      "loss 19.72785822659731\n",
      "loss 20.268606502115727\n",
      "loss 20.8171154153347\n",
      "loss 21.37579653561115\n",
      "loss 21.942056496739387\n",
      "loss 22.504661275148393\n",
      "Epoch:  46\n",
      "training loss =  0.5118987526227737\n",
      "Validation Loss: 1.0573\tTop 1 Validation Accuracy: 0.8005\t Top 5 Validation Accuracy: 0.9461\n",
      "loss 0.4566661602258682\n",
      "loss 0.9087701803445816\n",
      "loss 1.3624877494573593\n",
      "loss 1.8290944069623947\n",
      "loss 2.282030622959137\n",
      "loss 2.763137414753437\n",
      "loss 3.224163748025894\n",
      "loss 3.696025470495224\n",
      "loss 4.171600584983826\n",
      "loss 4.65106534987688\n",
      "loss 5.127118682265282\n",
      "loss 5.6021553137898445\n",
      "loss 6.0829810291528705\n",
      "loss 6.570056414604187\n",
      "loss 7.057103795111179\n",
      "loss 7.553566342294216\n",
      "loss 8.051198669672011\n",
      "loss 8.542058035433293\n",
      "loss 9.031702455580234\n",
      "loss 9.530902290046216\n",
      "loss 10.051614413261413\n",
      "loss 10.57060644030571\n",
      "loss 11.078137765228748\n",
      "loss 11.594045452475548\n",
      "loss 12.118725771009922\n",
      "loss 12.6313686978817\n",
      "loss 13.149509696662426\n",
      "loss 13.66887847661972\n",
      "loss 14.186715425252915\n",
      "loss 14.714621980786324\n",
      "loss 15.246405020952224\n",
      "loss 15.782738526761532\n",
      "loss 16.331006598770617\n",
      "loss 16.87429425984621\n",
      "loss 17.41186015665531\n",
      "loss 17.9583370244503\n",
      "loss 18.51036791354418\n",
      "loss 19.071335946917532\n",
      "loss 19.630167139172553\n",
      "loss 20.176119915246964\n",
      "loss 20.732019195258616\n",
      "loss 21.29246981292963\n",
      "loss 21.851957676708697\n",
      "loss 22.425349761247634\n",
      "Epoch:  47\n",
      "training loss =  0.5103178151891772\n",
      "Validation Loss: 0.9930\tTop 1 Validation Accuracy: 0.8040\t Top 5 Validation Accuracy: 0.9493\n",
      "loss 0.45504360377788544\n",
      "loss 0.909036318063736\n",
      "loss 1.3595656007528305\n",
      "loss 1.8187632688879967\n",
      "loss 2.2827593526244163\n",
      "loss 2.7524657440185547\n",
      "loss 3.2175244349241257\n",
      "loss 3.6851209661364557\n",
      "loss 4.15561784029007\n",
      "loss 4.623523733317852\n",
      "loss 5.103904976248741\n",
      "loss 5.5749058017134665\n",
      "loss 6.04283857524395\n",
      "loss 6.518466272056103\n",
      "loss 7.013151940703392\n",
      "loss 7.503507342338562\n",
      "loss 7.998987242877483\n",
      "loss 8.504328072071075\n",
      "loss 9.007045899629594\n",
      "loss 9.499964919984341\n",
      "loss 9.98968067407608\n",
      "loss 11.526908480525016\n",
      "loss 12.035379871428013\n",
      "loss 12.561350811719894\n",
      "loss 13.079881122410297\n",
      "loss 13.613548281490802\n",
      "loss 14.134566974937917\n",
      "loss 14.664819332659244\n",
      "loss 15.192170541882515\n",
      "loss 15.72918307542801\n",
      "loss 16.26027687162161\n",
      "loss 16.799287196695804\n",
      "loss 17.330961333811285\n",
      "loss 17.86258930772543\n",
      "loss 18.40841959476471\n",
      "loss 18.96516283810139\n",
      "loss 19.529177055358886\n",
      "loss 20.08937068194151\n",
      "loss 20.641665499210358\n",
      "loss 21.20448481798172\n",
      "loss 21.771533265411854\n",
      "loss 22.319694618582727\n",
      "Epoch:  48\n",
      "training loss =  0.5080269960330958\n",
      "Validation Loss: 1.0284\tTop 1 Validation Accuracy: 0.8035\t Top 5 Validation Accuracy: 0.9482\n",
      "loss 0.4517409393191338\n",
      "loss 0.8951480734348297\n",
      "loss 1.3483567529916762\n",
      "loss 1.8034627324342727\n",
      "loss 2.25661181807518\n",
      "loss 2.7274460899829864\n",
      "loss 3.196933746635914\n",
      "loss 3.654130107462406\n",
      "loss 4.127922700941562\n",
      "loss 4.597208541035652\n",
      "loss 5.074081095159054\n",
      "loss 5.5639608517289165\n",
      "loss 6.038969483077526\n",
      "loss 6.52396297365427\n",
      "loss 6.998556881546974\n",
      "loss 7.48881875872612\n",
      "loss 7.975911118090153\n",
      "loss 8.455002108216286\n",
      "loss 8.958988639116287\n",
      "loss 9.468631216585637\n",
      "loss 9.970925643742085\n",
      "loss 10.470245718359948\n",
      "loss 10.961711639463902\n",
      "loss 11.483900223970414\n",
      "loss 12.003997264504433\n",
      "loss 12.517707854509354\n",
      "loss 13.034101628661155\n",
      "loss 13.537739980220795\n",
      "loss 14.06059563100338\n",
      "loss 14.58117290198803\n",
      "loss 15.112243844270706\n",
      "loss 15.652959835529327\n",
      "loss 16.187526683807373\n",
      "loss 16.721616685688495\n",
      "loss 17.268969050347806\n",
      "loss 17.815724011957645\n",
      "loss 18.351963168978692\n",
      "loss 18.899921043515207\n",
      "loss 19.462692863345147\n",
      "loss 20.007936879694462\n",
      "loss 20.569358730018138\n",
      "loss 21.126368380188943\n",
      "loss 21.67558144390583\n",
      "loss 22.246594960689546\n",
      "Epoch:  49\n",
      "training loss =  0.5062216751986148\n",
      "Validation Loss: 1.0020\tTop 1 Validation Accuracy: 0.8006\t Top 5 Validation Accuracy: 0.9459\n",
      "loss 0.44028797894716265\n",
      "loss 0.8921505042910576\n",
      "loss 1.3326482751965523\n",
      "loss 1.7789698562026024\n",
      "loss 2.2148564577102663\n",
      "loss 2.6785989198088647\n",
      "loss 3.1295025238394736\n",
      "loss 3.572529295682907\n",
      "loss 4.036811655163765\n",
      "loss 4.514096083641053\n",
      "loss 4.990970795452594\n",
      "loss 5.46048661082983\n",
      "loss 5.9398023998737335\n",
      "loss 6.413503444194793\n",
      "loss 6.894259185492992\n",
      "loss 7.389942292273044\n",
      "loss 7.888927671909332\n",
      "loss 8.373425889313221\n",
      "loss 8.860255315601826\n",
      "loss 9.358346004486084\n",
      "loss 9.859325354397297\n",
      "loss 10.356083369255066\n",
      "loss 10.865787506997584\n",
      "loss 11.376981483697891\n",
      "loss 11.880605148077011\n",
      "loss 12.401615429520607\n",
      "loss 12.92069573521614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 13.442787477076054\n",
      "loss 13.961836277842522\n",
      "loss 14.49891935378313\n",
      "loss 15.020613265633584\n",
      "loss 15.556680866777898\n",
      "loss 16.098276619017124\n",
      "loss 16.6425755161047\n",
      "loss 17.181098186075687\n",
      "loss 17.728088488280772\n",
      "loss 18.257546909749507\n",
      "loss 18.794610227942467\n",
      "loss 19.33372141510248\n",
      "loss 19.87910535424948\n",
      "loss 20.431598965227604\n",
      "loss 20.99210347533226\n",
      "loss 21.55100520312786\n",
      "loss 22.105797338187696\n",
      "Epoch:  50\n",
      "training loss =  0.5031458547417169\n",
      "Validation Loss: 1.0718\tTop 1 Validation Accuracy: 0.7974\t Top 5 Validation Accuracy: 0.9438\n",
      "loss 0.4237370103597641\n",
      "loss 0.8249332673847676\n",
      "loss 1.2223854149878024\n",
      "loss 1.614367929250002\n",
      "loss 2.010290262550116\n",
      "loss 2.406660322993994\n",
      "loss 2.791627639681101\n",
      "loss 3.1718933399021627\n",
      "loss 3.5443002851307392\n",
      "loss 3.9275000897049903\n",
      "loss 4.306921772956848\n",
      "loss 4.683691252171993\n",
      "loss 5.055668685436249\n",
      "loss 5.429601860493421\n",
      "loss 5.80297678783536\n",
      "loss 6.183383448272943\n",
      "loss 6.557593736946583\n",
      "loss 6.923599415719509\n",
      "loss 7.286100924164057\n",
      "loss 7.658141557723284\n",
      "loss 8.02496717080474\n",
      "loss 8.392045766413212\n",
      "loss 8.760804022848607\n",
      "loss 9.124047839641571\n",
      "loss 9.487747324109078\n",
      "loss 9.857469976842403\n",
      "loss 10.217405879050494\n",
      "loss 10.585976045876741\n",
      "loss 10.962169438451529\n",
      "loss 11.330221039205789\n",
      "loss 11.699673193246126\n",
      "loss 12.064550842642785\n",
      "loss 12.432378468066453\n",
      "loss 12.784984272569417\n",
      "loss 13.153318627923728\n",
      "loss 13.520000167042017\n",
      "loss 13.88892447307706\n",
      "loss 14.25130072966218\n",
      "loss 14.613079541474582\n",
      "loss 14.971059889495372\n",
      "loss 15.343129869401455\n",
      "loss 15.700018300116062\n",
      "loss 16.05407967016101\n",
      "loss 16.41380953267217\n",
      "Epoch:  51\n",
      "training loss =  0.37310951532997494\n",
      "Validation Loss: 0.9127\tTop 1 Validation Accuracy: 0.8168\t Top 5 Validation Accuracy: 0.9544\n",
      "loss 0.3448458456993103\n",
      "loss 0.7075039401650429\n",
      "loss 1.0613687607645987\n",
      "loss 1.406837341338396\n",
      "loss 1.7560479445755481\n",
      "loss 2.0996320383250713\n",
      "loss 2.454566590040922\n",
      "loss 2.7943749491870404\n",
      "loss 3.145851895660162\n",
      "loss 3.5069804216921328\n",
      "loss 3.8586396902799605\n",
      "loss 4.214295759797096\n",
      "loss 4.562858728766441\n",
      "loss 4.907680014073849\n",
      "loss 5.271313949227333\n",
      "loss 5.616032830029726\n",
      "loss 5.96169574663043\n",
      "loss 6.3166578628122805\n",
      "loss 6.663295314759016\n",
      "loss 7.014396508783102\n",
      "loss 7.364421013891697\n",
      "loss 7.723086462020874\n",
      "loss 8.078078512251377\n",
      "loss 8.432044816315175\n",
      "loss 8.780312657356262\n",
      "loss 9.134833306521177\n",
      "loss 9.489247157126664\n",
      "loss 9.84039677783847\n",
      "loss 10.207256666123866\n",
      "loss 10.554320625364781\n",
      "loss 10.916740696430207\n",
      "loss 11.26867272913456\n",
      "loss 11.62684931114316\n",
      "loss 11.976941232085228\n",
      "loss 12.336891234517097\n",
      "loss 12.687050195932388\n",
      "loss 13.027397207915783\n",
      "loss 13.385746909976005\n",
      "loss 13.736727536767722\n",
      "loss 14.09300632789731\n",
      "loss 14.452721458822488\n",
      "loss 14.80550795570016\n",
      "loss 15.156740854233503\n",
      "loss 15.49959530606866\n",
      "Epoch:  52\n",
      "training loss =  0.3524029794699266\n",
      "Validation Loss: 0.9031\tTop 1 Validation Accuracy: 0.8187\t Top 5 Validation Accuracy: 0.9555\n",
      "loss 0.3348162806034088\n",
      "loss 0.6778389912843704\n",
      "loss 1.0240066365897655\n",
      "loss 1.3596598751842977\n",
      "loss 1.6999645483493806\n",
      "loss 2.0485696683824064\n",
      "loss 2.3905309891700743\n",
      "loss 2.7359800150990488\n",
      "loss 3.0836676263809206\n",
      "loss 3.427672483175993\n",
      "loss 3.7776121367514133\n",
      "loss 4.118733554333448\n",
      "loss 4.468859982043504\n",
      "loss 4.808210958838463\n",
      "loss 5.154550957977772\n",
      "loss 5.4979593232274055\n",
      "loss 5.847109636962414\n",
      "loss 6.190651929378509\n",
      "loss 6.535185112655163\n",
      "loss 6.878256765007973\n",
      "loss 7.224806013405323\n",
      "loss 7.568994932174682\n",
      "loss 7.9181716208159925\n",
      "loss 8.26988571152091\n",
      "loss 8.616472216546535\n",
      "loss 8.953058140873908\n",
      "loss 9.297024346739054\n",
      "loss 9.633295134156942\n",
      "loss 9.97466489315033\n",
      "loss 10.31595863878727\n",
      "loss 10.66973055690527\n",
      "loss 11.021476480811835\n",
      "loss 11.376820022165775\n",
      "loss 11.71023992344737\n",
      "loss 12.051296262592077\n",
      "loss 12.39453566774726\n",
      "loss 12.73792280331254\n",
      "loss 13.080754311382771\n",
      "loss 13.432888383716344\n",
      "loss 13.77428714647889\n",
      "loss 14.109348741322755\n",
      "loss 14.4644613994658\n",
      "loss 14.818113712966442\n",
      "loss 15.15182845711708\n",
      "Epoch:  53\n",
      "training loss =  0.3443834778832027\n",
      "Validation Loss: 0.8977\tTop 1 Validation Accuracy: 0.8186\t Top 5 Validation Accuracy: 0.9553\n",
      "loss 0.3370169070363045\n",
      "loss 0.6779668340086937\n",
      "loss 1.0182371088862419\n",
      "loss 1.355531850606203\n",
      "loss 1.6872954979538917\n",
      "loss 2.015825601965189\n",
      "loss 2.3486864767968654\n",
      "loss 2.688478257507086\n",
      "loss 3.0269505047798155\n",
      "loss 3.3624711011350157\n",
      "loss 3.7045382077991964\n",
      "loss 4.037302554696798\n",
      "loss 4.3783897562325\n",
      "loss 4.719553255885839\n",
      "loss 5.054244091510773\n",
      "loss 5.3981102722883225\n",
      "loss 5.74208012163639\n",
      "loss 6.079660855084658\n",
      "loss 6.423797673732042\n",
      "loss 6.762914076596498\n",
      "loss 7.100895008295774\n",
      "loss 7.44483765348792\n",
      "loss 7.7932940337061885\n",
      "loss 8.1299005651474\n",
      "loss 8.468010345101357\n",
      "loss 8.814358370304108\n",
      "loss 9.149041741490365\n",
      "loss 9.499451213181018\n",
      "loss 9.843324088603259\n",
      "loss 10.175723195672035\n",
      "loss 10.50820125028491\n",
      "loss 10.847355482131242\n",
      "loss 11.188449072688819\n",
      "loss 11.535658847391606\n",
      "loss 11.882607876062393\n",
      "loss 12.215001856982708\n",
      "loss 12.559038747400045\n",
      "loss 12.908592573851347\n",
      "loss 13.246228527873754\n",
      "loss 13.590982256382704\n",
      "loss 13.928800185918808\n",
      "loss 14.27574974656105\n",
      "loss 14.621771460324526\n",
      "loss 14.967315567284823\n",
      "Epoch:  54\n",
      "training loss =  0.3403524944882514\n",
      "Validation Loss: 0.8905\tTop 1 Validation Accuracy: 0.8201\t Top 5 Validation Accuracy: 0.9563\n",
      "loss 0.338942841142416\n",
      "loss 0.6688341347873211\n",
      "loss 0.9984881685674191\n",
      "loss 1.3275540693104266\n",
      "loss 1.6660139819979667\n",
      "loss 1.9877533265948295\n",
      "loss 2.3302749472856523\n",
      "loss 2.662291117310524\n",
      "loss 3.0091419926285745\n",
      "loss 3.3479670342803\n",
      "loss 3.6860225862264633\n",
      "loss 4.0143441639840605\n",
      "loss 4.349090913236141\n",
      "loss 4.681715754270553\n",
      "loss 5.014720585048199\n",
      "loss 5.35072168841958\n",
      "loss 5.690657024234533\n",
      "loss 6.023851088285446\n",
      "loss 6.353776551187038\n",
      "loss 6.693261107504368\n",
      "loss 7.035809651315212\n",
      "loss 7.379273943156004\n",
      "loss 7.71298274949193\n",
      "loss 8.051477740705014\n",
      "loss 8.390472343415022\n",
      "loss 8.740037771314382\n",
      "loss 9.086842349022627\n",
      "loss 9.415162139981986\n",
      "loss 9.759212404042483\n",
      "loss 10.099319844543935\n",
      "loss 10.429080768227577\n",
      "loss 10.760928546637297\n",
      "loss 11.101617998927832\n",
      "loss 11.44830571487546\n",
      "loss 11.788618727326392\n",
      "loss 12.137295653522015\n",
      "loss 12.47940837353468\n",
      "loss 12.821502991616725\n",
      "loss 13.164075145870447\n",
      "loss 13.507246744930745\n",
      "loss 13.85658840969205\n",
      "loss 14.197637950032949\n",
      "loss 14.54619558379054\n",
      "loss 14.881924667060375\n",
      "Epoch:  55\n",
      "training loss =  0.3384186001421227\n",
      "Validation Loss: 0.8946\tTop 1 Validation Accuracy: 0.8196\t Top 5 Validation Accuracy: 0.9559\n",
      "loss 0.3241168388724327\n",
      "loss 0.6466315297782421\n",
      "loss 0.9743825793266296\n",
      "loss 1.3039112536609172\n",
      "loss 1.6393955475091935\n",
      "loss 1.9735759358108043\n",
      "loss 2.310524082034826\n",
      "loss 2.646451811045408\n",
      "loss 2.9770306812226774\n",
      "loss 3.3063503287732603\n",
      "loss 3.641668490469456\n",
      "loss 3.97656378865242\n",
      "loss 4.311086449474097\n",
      "loss 4.64499096646905\n",
      "loss 4.9779931476712225\n",
      "loss 5.311255573630333\n",
      "loss 5.651976674944162\n",
      "loss 5.987993770390749\n",
      "loss 6.326896774470806\n",
      "loss 6.661018791645765\n",
      "loss 7.000440028309822\n",
      "loss 7.3350781384110455\n",
      "loss 7.6642695021629335\n",
      "loss 8.009422418624162\n",
      "loss 8.339926466047764\n",
      "loss 8.680979778319598\n",
      "loss 9.020912765413522\n",
      "loss 9.361385492533445\n",
      "loss 9.703221416324377\n",
      "loss 10.039298315644265\n",
      "loss 10.369929179698229\n",
      "loss 10.698129315674304\n",
      "loss 11.045066671669483\n",
      "loss 11.378385177999736\n",
      "loss 11.714551263004541\n",
      "loss 12.045338778942824\n",
      "loss 12.396805007904767\n",
      "loss 12.731965124458075\n",
      "loss 13.071162825524807\n",
      "loss 13.411530708521605\n",
      "loss 13.74105983376503\n",
      "loss 14.08733328267932\n",
      "loss 14.430771680921316\n",
      "loss 14.777768236845732\n",
      "Epoch:  56\n",
      "training loss =  0.3359000378910118\n",
      "Validation Loss: 0.8956\tTop 1 Validation Accuracy: 0.8204\t Top 5 Validation Accuracy: 0.9564\n",
      "loss 0.32188806891441346\n",
      "loss 0.6464033983647823\n",
      "loss 0.9800142456591129\n",
      "loss 1.3172381849586963\n",
      "loss 1.6497380703687667\n",
      "loss 1.98229936003685\n",
      "loss 2.3040012474358083\n",
      "loss 2.6334352657198905\n",
      "loss 2.968880711644888\n",
      "loss 3.300088559836149\n",
      "loss 3.640178615450859\n",
      "loss 3.964677072316408\n",
      "loss 4.298893204927444\n",
      "loss 4.622309605181218\n",
      "loss 4.953306969255209\n",
      "loss 5.298720511347056\n",
      "loss 5.63482808560133\n",
      "loss 5.969096373319626\n",
      "loss 6.3133582963049415\n",
      "loss 6.646429248154163\n",
      "loss 6.98656103849411\n",
      "loss 7.327496243864298\n",
      "loss 7.660706523507834\n",
      "loss 7.9958296830952165\n",
      "loss 8.330005139261484\n",
      "loss 8.674975617229938\n",
      "loss 9.00695701494813\n",
      "loss 9.346036927700043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 9.677412516027688\n",
      "loss 10.015420989096164\n",
      "loss 10.349331036657095\n",
      "loss 10.688004787266255\n",
      "loss 11.016556103527545\n",
      "loss 11.357689398825169\n",
      "loss 11.69140193492174\n",
      "loss 12.028760516047477\n",
      "loss 12.361927673667669\n",
      "loss 12.71184699356556\n",
      "loss 13.04963277578354\n",
      "loss 13.381636505424977\n",
      "loss 13.72752753123641\n",
      "loss 14.062985262274742\n",
      "loss 14.399030638039113\n",
      "loss 14.73541238039732\n",
      "Epoch:  57\n",
      "training loss =  0.33503689331930087\n",
      "Validation Loss: 0.8995\tTop 1 Validation Accuracy: 0.8195\t Top 5 Validation Accuracy: 0.9557\n",
      "loss 0.3300574226677418\n",
      "loss 0.6565181508660316\n",
      "loss 0.9903267700970173\n",
      "loss 1.3187013903260232\n",
      "loss 1.6526342469453812\n",
      "loss 1.982948307543993\n",
      "loss 2.312123523503542\n",
      "loss 2.6447066748142243\n",
      "loss 2.9704812191426755\n",
      "loss 3.305407686084509\n",
      "loss 3.6304995664954185\n",
      "loss 3.9671218571066857\n",
      "loss 4.2961364825069905\n",
      "loss 4.627268723398447\n",
      "loss 4.956630871444941\n",
      "loss 5.285664870291948\n",
      "loss 5.618885183930397\n",
      "loss 5.963361793160439\n",
      "loss 6.2869034041464325\n",
      "loss 6.619538692831993\n",
      "loss 6.949214469194413\n",
      "loss 7.276622110456228\n",
      "loss 7.612252343893051\n",
      "loss 7.948792875558138\n",
      "loss 8.949843489974738\n",
      "loss 9.28398043334484\n",
      "loss 9.62555133163929\n",
      "loss 9.965084314495325\n",
      "loss 10.298571710139512\n",
      "loss 10.634449213594198\n",
      "loss 10.961546214073897\n",
      "loss 11.302508702427149\n",
      "loss 11.646020584702491\n",
      "loss 11.980997654050588\n",
      "loss 12.315656303316354\n",
      "loss 12.652210303246974\n",
      "loss 12.989453188925982\n",
      "loss 13.33156083881855\n",
      "loss 13.668223048746587\n",
      "loss 14.014918814599515\n",
      "loss 14.346517445743084\n",
      "loss 14.69329991787672\n",
      "Epoch:  58\n",
      "training loss =  0.33399447060540094\n",
      "Validation Loss: 0.8999\tTop 1 Validation Accuracy: 0.8211\t Top 5 Validation Accuracy: 0.9565\n",
      "loss 0.32225939974188805\n",
      "loss 0.6472157987952233\n",
      "loss 0.9752397355437279\n",
      "loss 1.3009491136670113\n",
      "loss 1.634513957798481\n",
      "loss 1.9589857649803162\n",
      "loss 2.2915286706387996\n",
      "loss 2.625125670880079\n",
      "loss 2.9507845982909204\n",
      "loss 3.2849302658438684\n",
      "loss 3.617624864727259\n",
      "loss 3.946139111369848\n",
      "loss 4.271388780921698\n",
      "loss 4.608738394081593\n",
      "loss 4.946339674443006\n",
      "loss 5.278036451339721\n",
      "loss 5.612067341804504\n",
      "loss 5.941453206539154\n",
      "loss 6.277877261638642\n",
      "loss 6.611508504748344\n",
      "loss 6.949382925182581\n",
      "loss 7.291424703896046\n",
      "loss 7.626103775948286\n",
      "loss 7.954797603338957\n",
      "loss 8.291360630989075\n",
      "loss 8.628678857088088\n",
      "loss 8.966572852730751\n",
      "loss 9.29973901450634\n",
      "loss 9.634834537059069\n",
      "loss 9.970346440821887\n",
      "loss 10.314311214387416\n",
      "loss 10.660758771598339\n",
      "loss 10.9892885042727\n",
      "loss 11.322776559144259\n",
      "loss 11.672992868125439\n",
      "loss 12.001916877627373\n",
      "loss 12.346548266410828\n",
      "loss 12.68826400950551\n",
      "loss 13.027921197861433\n",
      "loss 13.361659288704395\n",
      "loss 13.703797948211431\n",
      "loss 14.039828349500894\n",
      "loss 14.375211698263884\n",
      "loss 14.718536249995232\n",
      "Epoch:  59\n",
      "training loss =  0.3346048267417901\n",
      "Validation Loss: 0.9029\tTop 1 Validation Accuracy: 0.8201\t Top 5 Validation Accuracy: 0.9562\n",
      "loss 0.32726752072572707\n",
      "loss 0.6562547533214093\n",
      "loss 0.9819062043726444\n",
      "loss 1.3117864449322223\n",
      "loss 1.6398852588236332\n",
      "loss 1.9690414099395275\n",
      "loss 2.300881123691797\n",
      "loss 2.6376633466780186\n",
      "loss 2.9639559116959573\n",
      "loss 3.2906861728429795\n",
      "loss 3.618284483551979\n",
      "loss 3.948417808264494\n",
      "loss 4.281789295971394\n",
      "loss 4.6050012724101546\n",
      "loss 4.942133119851351\n",
      "loss 5.279033039063215\n",
      "loss 5.611752029955387\n",
      "loss 5.935654456168413\n",
      "loss 6.272442557811737\n",
      "loss 6.596646839529276\n",
      "loss 6.9266663852334025\n",
      "loss 7.253785304874182\n",
      "loss 7.59014640763402\n",
      "loss 7.922022223472595\n",
      "loss 8.261792353987694\n",
      "loss 8.591141913831233\n",
      "loss 8.922985822707414\n",
      "loss 9.255336941033601\n",
      "loss 9.59819926455617\n",
      "loss 9.929416543841363\n",
      "loss 10.26936020642519\n",
      "loss 10.609240555614234\n",
      "loss 10.940190801024437\n",
      "loss 11.277078302651644\n",
      "loss 11.612647522687912\n",
      "loss 11.950533096343278\n",
      "loss 12.291077303737403\n",
      "loss 12.641112127155065\n",
      "loss 12.983599516004324\n",
      "loss 13.322434485554695\n",
      "loss 13.668668825179338\n",
      "loss 13.9990250441432\n",
      "loss 14.344488843381406\n",
      "loss 14.671808632314205\n",
      "Epoch:  60\n",
      "training loss =  0.3335439635510656\n",
      "Validation Loss: 0.9107\tTop 1 Validation Accuracy: 0.8200\t Top 5 Validation Accuracy: 0.9562\n",
      "loss 0.3250326704978943\n",
      "loss 0.6554321905970574\n",
      "loss 0.9792467185854912\n",
      "loss 1.2961908251047134\n",
      "loss 1.621104340404272\n",
      "loss 1.9555790129303932\n",
      "loss 2.289873120486736\n",
      "loss 2.61560814678669\n",
      "loss 2.9501011505723\n",
      "loss 3.280164255350828\n",
      "loss 3.6128026799857618\n",
      "loss 3.945860503613949\n",
      "loss 4.274673235267401\n",
      "loss 4.599862332046032\n",
      "loss 4.932800304889679\n",
      "loss 5.262668097019196\n",
      "loss 5.603551957756281\n",
      "loss 5.938977999836206\n",
      "loss 6.27107062086463\n",
      "loss 6.60878866493702\n",
      "loss 6.949637725800276\n",
      "loss 7.625901716500521\n",
      "loss 7.957678886353969\n",
      "loss 8.283352932482957\n",
      "loss 8.616524136662484\n",
      "loss 8.951195723861456\n",
      "loss 9.282304308712483\n",
      "loss 9.628343559354544\n",
      "loss 9.967619058191776\n",
      "loss 10.298476485908031\n",
      "loss 10.633464107960462\n",
      "loss 10.972606691718102\n",
      "loss 11.30082861751318\n",
      "loss 11.640116827189923\n",
      "loss 11.980064025074244\n",
      "loss 12.312959728837013\n",
      "loss 12.651550851911306\n",
      "loss 12.993367327600717\n",
      "loss 13.333939528614282\n",
      "loss 13.668762073814868\n",
      "loss 14.00027206644416\n",
      "loss 14.340081772059202\n",
      "loss 14.680796032696962\n",
      "Epoch:  61\n",
      "training loss =  0.33372401473748436\n",
      "loss 0.6490360593795776\n",
      "loss 0.9807258892059326\n",
      "loss 1.3076662684977054\n",
      "loss 1.631797716319561\n",
      "loss 1.9646829642355441\n",
      "loss 2.298897128403187\n",
      "loss 2.6241838423907757\n",
      "loss 2.9532021106779576\n",
      "loss 3.283473784029484\n",
      "loss 3.6209685154259206\n",
      "loss 3.9493899527192116\n",
      "loss 4.291774028539658\n",
      "loss 4.6304998841881755\n",
      "loss 4.950314284861088\n",
      "loss 5.285360298007727\n",
      "loss 5.619656655937433\n",
      "loss 5.946508475393057\n",
      "loss 6.271484533846379\n",
      "loss 6.603561361432075\n",
      "loss 6.937571036368609\n",
      "loss 7.267591360360384\n",
      "loss 7.598129993081093\n",
      "loss 7.931342193633318\n",
      "loss 8.26269290342927\n",
      "loss 8.595176618993282\n",
      "loss 8.928016315102576\n",
      "loss 9.26669763326645\n",
      "loss 9.920494500696659\n",
      "loss 10.258981159180403\n",
      "loss 10.59974436417222\n",
      "loss 10.938650119751692\n",
      "loss 11.267756828516722\n",
      "loss 11.606027768403292\n",
      "loss 11.943397395312786\n",
      "loss 12.280981901735068\n",
      "loss 12.613018120229244\n",
      "loss 12.960422520339488\n",
      "loss 13.303861804902553\n",
      "loss 13.646223352998495\n",
      "loss 13.992883774042129\n",
      "loss 14.323960747271776\n",
      "loss 14.658384879529477\n",
      "Epoch:  62\n",
      "training loss =  0.3333272121047502\n",
      "Validation Loss: 0.8987\tTop 1 Validation Accuracy: 0.8198\t Top 5 Validation Accuracy: 0.9562\n",
      "loss 0.31890917763113974\n",
      "loss 0.6538074827194214\n",
      "loss 0.9801745195686817\n",
      "loss 1.3184241761267186\n",
      "loss 1.6412404762208461\n",
      "loss 1.9761693760752679\n",
      "loss 2.309979400783777\n",
      "loss 2.6427503587305545\n",
      "loss 2.972768144160509\n",
      "loss 3.2978327049314977\n",
      "loss 3.629483495652676\n",
      "loss 3.9522087402641772\n",
      "loss 4.2732024267315865\n",
      "loss 4.612459709644318\n",
      "loss 4.954608077257872\n",
      "loss 5.285507788211107\n",
      "loss 5.617778066396713\n",
      "loss 5.955532254725695\n",
      "loss 6.291375081241131\n",
      "loss 6.622418744117022\n",
      "loss 6.957588504254818\n",
      "loss 7.2960602585971355\n",
      "loss 7.629338513910771\n",
      "loss 7.9564485885202885\n",
      "loss 8.295067608505487\n",
      "loss 8.636988637894392\n",
      "loss 8.97676518663764\n",
      "loss 9.31214395299554\n",
      "loss 9.64862883836031\n",
      "loss 9.983390287160873\n",
      "loss 10.316957813352346\n",
      "loss 10.654662732332945\n",
      "loss 10.987780329436063\n",
      "loss 11.323226653188467\n",
      "loss 11.6625645506382\n",
      "loss 12.002366177588701\n",
      "loss 12.333992908596992\n",
      "loss 12.663741300553083\n",
      "loss 13.012902165949345\n",
      "loss 13.351783169060946\n",
      "loss 13.697677666544914\n",
      "loss 14.032789221853017\n",
      "loss 14.366608169674873\n",
      "loss 14.705826195329427\n",
      "Epoch:  63\n",
      "training loss =  0.33442269506241623\n",
      "Validation Loss: 0.8961\tTop 1 Validation Accuracy: 0.8219\t Top 5 Validation Accuracy: 0.9572\n",
      "loss 0.32291356652975084\n",
      "loss 0.6534781295061112\n",
      "loss 0.9738577650487423\n",
      "loss 1.300435548722744\n",
      "loss 1.6245281609892845\n",
      "loss 1.952915650755167\n",
      "loss 2.28500749245286\n",
      "loss 2.6121905298531054\n",
      "loss 2.9439657908678054\n",
      "loss 3.269970423579216\n",
      "loss 3.597312117666006\n",
      "loss 3.9239478585124017\n",
      "loss 4.251821012496948\n",
      "loss 4.58167231798172\n",
      "loss 4.912234955132008\n",
      "loss 5.23757252112031\n",
      "loss 5.570005837976932\n",
      "loss 5.902677674740553\n",
      "loss 6.234479168951512\n",
      "loss 6.5607834969460965\n",
      "loss 6.897436194270849\n",
      "loss 7.2347445979714395\n",
      "loss 7.577773295193911\n",
      "loss 7.917162227034569\n",
      "loss 8.242736724466086\n",
      "loss 8.579977461993694\n",
      "loss 8.920595161169768\n",
      "loss 9.25802936464548\n",
      "loss 9.586313295811415\n",
      "loss 9.918410876393319\n",
      "loss 10.244381997138262\n",
      "loss 10.574999485611915\n",
      "loss 10.90931878760457\n",
      "loss 11.248899781405926\n",
      "loss 11.578595820218325\n",
      "loss 11.912540854662657\n",
      "loss 12.25050777927041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 12.59126596853137\n",
      "loss 12.9366948287189\n",
      "loss 13.271713809370995\n",
      "loss 13.616084069758653\n",
      "loss 13.953323653042316\n",
      "loss 14.290149700641631\n",
      "loss 14.623927621990441\n",
      "Epoch:  64\n",
      "training loss =  0.33248506076273715\n",
      "Validation Loss: 0.9117\tTop 1 Validation Accuracy: 0.8199\t Top 5 Validation Accuracy: 0.9561\n",
      "loss 0.32780040338635447\n",
      "loss 0.6554232269525528\n",
      "loss 0.9872631420195103\n",
      "loss 1.3082494960725308\n",
      "loss 1.6416870698332786\n",
      "loss 1.968280574977398\n",
      "loss 2.305222492963076\n",
      "loss 2.636807836443186\n",
      "loss 2.9600506748259066\n",
      "loss 3.2875244195759294\n",
      "loss 3.616559128165245\n",
      "loss 3.9526037050783636\n",
      "loss 4.276094987243414\n",
      "loss 4.605911467075348\n",
      "loss 4.936535401046276\n",
      "loss 5.264427506476641\n",
      "loss 5.58341616526246\n",
      "loss 5.91234770283103\n",
      "loss 6.243160739094019\n",
      "loss 6.58088613525033\n",
      "loss 6.915633104294539\n",
      "loss 7.251119567900896\n",
      "loss 7.582171540409327\n",
      "loss 7.924927639365197\n",
      "loss 8.257879970520735\n",
      "loss 8.59217056825757\n",
      "loss 8.93174665004015\n",
      "loss 9.266494608521462\n",
      "loss 9.602015093415975\n",
      "loss 9.939859960526228\n",
      "loss 10.277146409898997\n",
      "loss 10.61087883517146\n",
      "loss 10.959764727950096\n",
      "loss 11.299828590452671\n",
      "loss 11.634040395766498\n",
      "loss 11.972418924421072\n",
      "loss 12.308618272691966\n",
      "loss 12.630841376781463\n",
      "loss 12.963128978908061\n",
      "loss 13.29168796762824\n",
      "loss 13.633575832396746\n",
      "loss 13.959262702167035\n",
      "loss 14.289922599196434\n",
      "loss 14.627613016366958\n",
      "Epoch:  65\n",
      "training loss =  0.33251310219476804\n",
      "Validation Loss: 0.9009\tTop 1 Validation Accuracy: 0.8214\t Top 5 Validation Accuracy: 0.9571\n",
      "loss 0.32443088218569754\n",
      "loss 0.6602487023174762\n",
      "loss 0.9842908790707589\n",
      "loss 1.3105008161067964\n",
      "loss 1.6469119803607464\n",
      "loss 1.978136734366417\n",
      "loss 2.2999083365499975\n",
      "loss 2.625961894392967\n",
      "loss 2.948794229477644\n",
      "loss 3.2735921600461007\n",
      "loss 3.5980171339213847\n",
      "loss 3.9261069031059743\n",
      "loss 4.257817846387625\n",
      "loss 4.5939490121603015\n",
      "loss 4.926226049959659\n",
      "loss 5.251345280855894\n",
      "loss 5.5858554145693775\n",
      "loss 5.915339908003807\n",
      "loss 6.254961777031422\n",
      "loss 6.585794481337071\n",
      "loss 6.918794773072005\n",
      "loss 7.251430939286947\n",
      "loss 7.587180569469929\n",
      "loss 7.914422543495894\n",
      "loss 8.252192486226559\n",
      "loss 8.582339517474175\n",
      "loss 8.914309808313847\n",
      "loss 9.24623868048191\n",
      "loss 9.583775233626366\n",
      "loss 9.918640723973512\n",
      "loss 10.248642472475767\n",
      "loss 10.586614840626716\n",
      "loss 10.92245492979884\n",
      "loss 11.25918300241232\n",
      "loss 11.591830045580863\n",
      "loss 11.934000386595725\n",
      "loss 12.26587577700615\n",
      "loss 12.600414821505547\n",
      "loss 12.936077245175838\n",
      "loss 13.274575657099485\n",
      "loss 13.610863609761\n",
      "loss 13.951985651701689\n",
      "loss 14.286342954188585\n",
      "loss 14.614540842920542\n",
      "Epoch:  66\n",
      "training loss =  0.3324238995380393\n",
      "Validation Loss: 0.9091\tTop 1 Validation Accuracy: 0.8215\t Top 5 Validation Accuracy: 0.9570\n",
      "loss 0.31766793206334115\n",
      "loss 0.6494861368834972\n",
      "loss 0.977166088372469\n",
      "loss 1.3001799055933951\n",
      "loss 1.6320888890326024\n",
      "loss 1.9581897397339345\n",
      "loss 2.2765764288604258\n",
      "loss 2.6088591872155664\n",
      "loss 2.9317684617638586\n",
      "loss 3.2685190162062643\n",
      "loss 3.5984763702750207\n",
      "loss 3.9252457831799985\n",
      "loss 4.25456891849637\n",
      "loss 4.57795691639185\n",
      "loss 4.897698462605477\n",
      "loss 5.228428167104721\n",
      "loss 5.557695667296648\n",
      "loss 5.881988181620836\n",
      "loss 6.215516543835402\n",
      "loss 6.544403405189514\n",
      "loss 6.8713131445646285\n",
      "loss 7.209802874028683\n",
      "loss 7.541498493999243\n",
      "loss 7.878780705779791\n",
      "loss 8.214986054748296\n",
      "loss 8.559925858229398\n",
      "loss 8.894134420454503\n",
      "loss 9.231680831164121\n",
      "loss 9.559352779090405\n",
      "loss 9.895050106048584\n",
      "loss 10.232988633215427\n",
      "loss 10.575621806681156\n",
      "loss 10.919456053674221\n",
      "loss 11.255529076009989\n",
      "loss 11.580713566988706\n",
      "loss 11.913505866378546\n",
      "loss 12.249386636167765\n",
      "loss 12.588802677243947\n",
      "loss 12.92145946830511\n",
      "loss 13.262984954714774\n",
      "loss 13.606759706884622\n",
      "loss 13.943233309090138\n",
      "loss 14.285581797510385\n",
      "loss 14.626869635879993\n",
      "Epoch:  67\n",
      "training loss =  0.332569041311379\n",
      "Validation Loss: 0.9054\tTop 1 Validation Accuracy: 0.8204\t Top 5 Validation Accuracy: 0.9566\n",
      "loss 0.3213722924888134\n",
      "loss 0.6403836734592915\n",
      "loss 0.9695127977430821\n",
      "loss 1.2937985421717166\n",
      "loss 1.618134443759918\n",
      "loss 1.9436047299206256\n",
      "loss 2.2731323289871215\n",
      "loss 2.5965112909674644\n",
      "loss 2.923643092662096\n",
      "loss 3.2561879950761794\n",
      "loss 3.5896400406956674\n",
      "loss 3.9109382605552674\n",
      "loss 4.251708986163139\n",
      "loss 4.583972266763449\n",
      "loss 4.9097274798154835\n",
      "loss 5.240462694317102\n",
      "loss 5.573320120722055\n",
      "loss 5.912294927388429\n",
      "loss 6.254155566245317\n",
      "loss 6.585730693489313\n",
      "loss 6.919019840061664\n",
      "loss 7.245192667990923\n",
      "loss 7.576191037595272\n",
      "loss 7.90640316426754\n",
      "loss 8.23124695211649\n",
      "loss 8.567925529181958\n",
      "loss 8.9023403249681\n",
      "loss 9.233181639164686\n",
      "loss 9.569759366363288\n",
      "loss 9.896704985052347\n",
      "loss 10.230624713748693\n",
      "loss 10.572205739170313\n",
      "loss 10.909175173640252\n",
      "loss 11.246197354346513\n",
      "loss 11.591715554445981\n",
      "loss 11.928401590436698\n",
      "loss 12.260502994954585\n",
      "loss 12.59503030344844\n",
      "loss 12.928340350091457\n",
      "loss 13.26636524900794\n",
      "loss 13.608363249748946\n",
      "loss 13.93864623606205\n",
      "loss 14.272052071094514\n",
      "loss 14.61319154471159\n",
      "Epoch:  68\n",
      "training loss =  0.3323499199236702\n",
      "Validation Loss: 0.9051\tTop 1 Validation Accuracy: 0.8216\t Top 5 Validation Accuracy: 0.9573\n",
      "loss 0.32561908677220347\n",
      "loss 0.6515792433917522\n",
      "loss 0.979425294995308\n",
      "loss 1.3113690680265426\n",
      "loss 1.6433757889270781\n",
      "loss 1.9677624799311162\n",
      "loss 2.302414989620447\n",
      "loss 2.6319246444106104\n",
      "loss 2.9564662250876426\n",
      "loss 3.29257324591279\n",
      "loss 3.627019949555397\n",
      "loss 3.955239614546299\n",
      "loss 4.2792003552615645\n",
      "loss 4.61114156126976\n",
      "loss 4.944129121899604\n",
      "loss 5.268254104107618\n",
      "loss 5.601031941473484\n",
      "loss 5.935174538493157\n",
      "loss 6.270395166426897\n",
      "loss 6.601466284841299\n",
      "loss 6.934556020349264\n",
      "loss 7.266672183126211\n",
      "loss 7.5953430591523645\n",
      "loss 7.92566859126091\n",
      "loss 8.25062164977193\n",
      "loss 8.5746214812994\n",
      "loss 8.918321128338576\n",
      "loss 9.255157545953988\n",
      "loss 9.589220497608185\n",
      "loss 9.926813907772303\n",
      "loss 10.26350709527731\n",
      "loss 10.588908673673869\n",
      "loss 10.931445439904929\n",
      "loss 11.279166864007712\n",
      "loss 11.623677817285062\n",
      "loss 11.95825498700142\n",
      "loss 12.286847420334816\n",
      "loss 12.622638307362795\n",
      "loss 12.95447957187891\n",
      "loss 13.295901794731616\n",
      "loss 13.624641336798668\n",
      "loss 13.9672602891922\n",
      "loss 14.305215056091548\n",
      "loss 14.641420383304357\n",
      "Epoch:  69\n",
      "training loss =  0.33284826072074064\n",
      "Validation Loss: 0.9060\tTop 1 Validation Accuracy: 0.8217\t Top 5 Validation Accuracy: 0.9572\n",
      "loss 0.32507849499583247\n",
      "loss 0.6572546398639679\n",
      "loss 0.9824637684226036\n",
      "loss 1.306887286156416\n",
      "loss 1.6346203790605067\n",
      "loss 1.9595762784779072\n",
      "loss 2.283518590182066\n",
      "loss 2.613251918703318\n",
      "loss 2.939501589983702\n",
      "loss 3.2659442315995695\n",
      "loss 3.601811178177595\n",
      "loss 3.933978235423565\n",
      "loss 4.264829301536083\n",
      "loss 4.598295709490776\n",
      "loss 4.924452664554119\n",
      "loss 5.259979584366083\n",
      "loss 5.5914542970061305\n",
      "loss 5.9222297412157054\n",
      "loss 6.244392971694469\n",
      "loss 6.579664475470781\n",
      "loss 6.916840302497149\n",
      "loss 7.256561696380377\n",
      "loss 7.592814994305372\n",
      "loss 7.922218744456768\n",
      "loss 8.257706291079522\n",
      "loss 8.591984098255635\n",
      "loss 8.927286962419748\n",
      "loss 9.26436074256897\n",
      "loss 9.59692180261016\n",
      "loss 9.936700758188962\n",
      "loss 10.271152618676425\n",
      "loss 10.610014201402665\n",
      "loss 10.942428606152534\n",
      "loss 11.277885041981936\n",
      "loss 11.609853086769581\n",
      "loss 11.955362598001956\n",
      "loss 12.295679773390294\n",
      "loss 12.631612154096365\n",
      "loss 12.972155011743308\n",
      "loss 13.304923916906118\n",
      "loss 13.644845494031905\n",
      "loss 13.97184055402875\n",
      "loss 14.307928400188684\n",
      "loss 14.638539031893014\n",
      "Epoch:  70\n",
      "training loss =  0.33269462375083825\n",
      "Validation Loss: 0.8876\tTop 1 Validation Accuracy: 0.8221\t Top 5 Validation Accuracy: 0.9576\n",
      "loss 0.3185171663761139\n",
      "loss 0.6446631462872028\n",
      "loss 0.9665868245065212\n",
      "loss 1.2859405936300754\n",
      "loss 1.6177910313010215\n",
      "loss 1.9425289556384087\n",
      "loss 2.276820277273655\n",
      "loss 2.601805486679077\n",
      "loss 2.923951781690121\n",
      "loss 3.245503267943859\n",
      "loss 3.5678110067546367\n",
      "loss 3.9000571523606777\n",
      "loss 4.226096943765879\n",
      "loss 4.55418698579073\n",
      "loss 4.884230960607528\n",
      "loss 5.2162269158661365\n",
      "loss 5.544726716428995\n",
      "loss 5.882239064872265\n",
      "loss 6.216175080686807\n",
      "loss 6.546589407473802\n",
      "loss 6.874234889149665\n",
      "loss 7.206064939945936\n",
      "loss 7.534485606998206\n",
      "loss 7.869344844073058\n",
      "loss 8.196694681942462\n",
      "loss 8.535191107988357\n",
      "loss 8.875272294431925\n",
      "loss 9.207012452483177\n",
      "loss 9.548868638575078\n",
      "loss 9.881998486220837\n",
      "loss 10.212282426804304\n",
      "loss 10.547531841248274\n",
      "loss 10.875298539847135\n",
      "loss 11.204230129271746\n",
      "loss 11.538667688071728\n",
      "loss 11.874769091755152\n",
      "loss 12.212219556868076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 12.558726343363524\n",
      "loss 12.898511531800033\n",
      "loss 13.234275955408812\n",
      "loss 13.573274976313114\n",
      "loss 13.912609938681125\n",
      "loss 14.244505036473274\n",
      "loss 14.577328796684743\n",
      "Epoch:  71\n",
      "training loss =  0.33163482408483885\n",
      "Validation Loss: 0.9033\tTop 1 Validation Accuracy: 0.8231\t Top 5 Validation Accuracy: 0.9582\n",
      "loss 0.32398226514458656\n",
      "loss 0.6557990294694901\n",
      "loss 0.9881741121411324\n",
      "loss 1.3150949549674988\n",
      "loss 1.6402190493047237\n",
      "loss 1.9670733581483364\n",
      "loss 2.288389318138361\n",
      "loss 2.6135155816376208\n",
      "loss 2.9428420688211916\n",
      "loss 3.278908061534166\n",
      "loss 3.6039172583818435\n",
      "loss 3.9344006818532944\n",
      "loss 4.2594656655192376\n",
      "loss 4.592534171193838\n",
      "loss 4.919256379008293\n",
      "loss 5.255955699682236\n",
      "loss 5.590996273010969\n",
      "loss 5.92897095784545\n",
      "loss 6.25263951331377\n",
      "loss 6.580635722577572\n",
      "loss 6.913354768007994\n",
      "loss 7.237152707129717\n",
      "loss 7.578132889419794\n",
      "loss 7.909863882511854\n",
      "loss 8.251770640760661\n",
      "loss 8.574466993808747\n",
      "loss 8.908848050683737\n",
      "loss 9.234271872639656\n",
      "loss 9.562738206237555\n",
      "loss 9.89212042093277\n",
      "loss 10.228642710149288\n",
      "loss 10.564680552929639\n",
      "loss 10.899226318448783\n",
      "loss 11.238810173720122\n",
      "loss 11.572665844112635\n",
      "loss 11.908826011121272\n",
      "loss 12.240350331664086\n",
      "loss 12.57971027135849\n",
      "loss 12.920116193890571\n",
      "loss 13.2609904140234\n",
      "loss 13.59781921684742\n",
      "loss 13.946009194999933\n",
      "loss 14.291786450892687\n",
      "loss 14.636630131751298\n",
      "Epoch:  72\n",
      "training loss =  0.3326998863370064\n",
      "Validation Loss: 0.9085\tTop 1 Validation Accuracy: 0.8231\t Top 5 Validation Accuracy: 0.9583\n",
      "loss 0.32332305014133456\n",
      "loss 0.6412326140701771\n",
      "loss 0.9746981777250767\n",
      "loss 1.296057630777359\n",
      "loss 1.6222227042913437\n",
      "loss 1.9497742174565793\n",
      "loss 2.2704840748012067\n",
      "loss 2.5998544776439667\n",
      "loss 2.9337696322798728\n",
      "loss 3.26472979798913\n",
      "loss 3.588721130043268\n",
      "loss 3.924897101968527\n",
      "loss 4.253983096778393\n",
      "loss 4.580799823254347\n",
      "loss 4.910556843727827\n",
      "loss 5.241131058782339\n",
      "loss 5.572737638652325\n",
      "loss 5.9132074201107026\n",
      "loss 6.2482103654742245\n",
      "loss 6.591950105726719\n",
      "loss 6.923950661122799\n",
      "loss 7.256653373092413\n",
      "loss 7.603174760639668\n",
      "loss 7.942238224744797\n",
      "loss 8.280385102182628\n",
      "loss 8.612515946626663\n",
      "loss 8.948848436921836\n",
      "loss 9.285482209324837\n",
      "loss 9.616253578215838\n",
      "loss 9.953515284359455\n",
      "loss 10.286811846643687\n",
      "loss 10.627397641539574\n",
      "loss 10.965966456979514\n",
      "loss 11.3036328291893\n",
      "loss 11.639152954220771\n",
      "loss 11.97600132778287\n",
      "loss 12.314637492150068\n",
      "loss 12.644629957675933\n",
      "loss 12.97290458008647\n",
      "loss 13.310472962856293\n",
      "loss 13.6425930775702\n",
      "loss 13.983089278489352\n",
      "loss 14.319261359125376\n",
      "loss 14.657240887582303\n",
      "Epoch:  73\n",
      "training loss =  0.3331386013455356\n",
      "Validation Loss: 0.9113\tTop 1 Validation Accuracy: 0.8216\t Top 5 Validation Accuracy: 0.9570\n",
      "loss 0.32063091188669207\n",
      "loss 0.6559317596256733\n",
      "loss 0.9903938199579716\n",
      "loss 1.3027503293752671\n",
      "loss 1.6231005117297173\n",
      "loss 1.9575464862585068\n",
      "loss 2.2816853706538676\n",
      "loss 3.2704411885142326\n",
      "loss 3.5960146740078924\n",
      "loss 3.9302702136337757\n",
      "loss 4.262477728873491\n",
      "loss 4.58804332152009\n",
      "loss 4.91875926271081\n",
      "loss 5.251038185805083\n",
      "loss 5.58406598046422\n",
      "loss 5.919492616206408\n",
      "loss 6.2483000332117085\n",
      "loss 6.579098143279553\n",
      "loss 6.913151292353868\n",
      "loss 7.235595145523548\n",
      "loss 7.570411889106035\n",
      "loss 7.9013754872977735\n",
      "loss 8.23749174579978\n",
      "loss 8.568925580978394\n",
      "loss 8.904825427681208\n",
      "loss 9.237151315361261\n",
      "loss 9.588331546932459\n",
      "loss 9.92874736905098\n",
      "loss 10.256877589821816\n",
      "loss 10.596191317886115\n",
      "loss 10.930222838222981\n",
      "loss 11.2664967687428\n",
      "loss 11.594089158177376\n",
      "loss 11.932027876526117\n",
      "loss 12.268615855872632\n",
      "loss 12.609954262673854\n",
      "loss 12.949497704952956\n",
      "loss 13.282538196742534\n",
      "loss 13.625706707537175\n",
      "loss 13.961809691637754\n",
      "loss 14.306192199289798\n",
      "loss 14.643865130394698\n",
      "Epoch:  74\n",
      "training loss =  0.33291203421248405\n",
      "Validation Loss: 0.8985\tTop 1 Validation Accuracy: 0.8221\t Top 5 Validation Accuracy: 0.9573\n",
      "loss 0.31734377950429915\n",
      "loss 0.6489587432146072\n",
      "loss 0.9698435933887959\n",
      "loss 1.294812865704298\n",
      "loss 1.6173901851475239\n",
      "loss 1.9484967206418515\n",
      "loss 2.2754076670110224\n",
      "loss 2.60708759188652\n",
      "loss 2.9347025690972806\n",
      "loss 3.267512935400009\n",
      "loss 3.595711285918951\n",
      "loss 3.9312137082219123\n",
      "loss 4.2512629808485505\n",
      "loss 4.584546262174845\n",
      "loss 4.9111033627390865\n",
      "loss 5.247133360654115\n",
      "loss 5.581038875877857\n",
      "loss 5.9077661976218225\n",
      "loss 6.238583537489176\n",
      "loss 6.576150380671025\n",
      "loss 6.915771910697222\n",
      "loss 7.246772435754537\n",
      "loss 7.5873063558340075\n",
      "loss 7.915803833156824\n",
      "loss 8.248322962373495\n",
      "loss 8.575459544062614\n",
      "loss 8.899971699416637\n",
      "loss 9.23617027580738\n",
      "loss 9.568448358476163\n",
      "loss 9.897711139917373\n",
      "loss 10.229641553461551\n",
      "loss 10.565851718187332\n",
      "loss 10.906786242574453\n",
      "loss 11.247673254311085\n",
      "loss 11.574190793931484\n",
      "loss 11.912523261457682\n",
      "loss 12.240561183840036\n",
      "loss 12.578117579966783\n",
      "loss 12.91868679508567\n",
      "loss 13.261589692682028\n",
      "loss 13.599950173795223\n",
      "loss 13.935157611817122\n",
      "loss 14.269224839806556\n",
      "loss 14.614783572554588\n",
      "Epoch:  75\n",
      "training loss =  0.3323046172136989\n",
      "Validation Loss: 0.9166\tTop 1 Validation Accuracy: 0.8230\t Top 5 Validation Accuracy: 0.9582\n",
      "loss 0.3267429818212986\n",
      "loss 0.6522396124899388\n",
      "loss 0.9736898215115071\n",
      "loss 1.2906170934438705\n",
      "loss 1.6156988340616225\n",
      "loss 1.9349930848181247\n",
      "loss 2.256314181238413\n",
      "loss 2.560586538463831\n",
      "loss 2.8861682903766632\n",
      "loss 3.2078562895953655\n",
      "loss 3.528419940918684\n",
      "loss 3.85452430665493\n",
      "loss 4.17245988368988\n",
      "loss 4.497454218417406\n",
      "loss 4.815033080875874\n",
      "loss 5.136253093183041\n",
      "loss 5.451212510019541\n",
      "loss 5.773023688346147\n",
      "loss 6.09476920902729\n",
      "loss 6.413297616094351\n",
      "loss 6.736583232879639\n",
      "loss 7.063461513519287\n",
      "loss 7.389937420636415\n",
      "loss 7.711707011461258\n",
      "loss 8.036583043932914\n",
      "loss 8.345951588004828\n",
      "loss 8.667959789484739\n",
      "loss 8.980100889205932\n",
      "loss 9.298801463544368\n",
      "loss 9.62757178634405\n",
      "loss 9.951277164667845\n",
      "loss 10.271005130410195\n",
      "loss 10.59389136403799\n",
      "loss 10.907548843324184\n",
      "loss 11.216173902750015\n",
      "loss 11.529848396629095\n",
      "loss 11.853254918456077\n",
      "loss 12.17013810902834\n",
      "loss 12.486524037122727\n",
      "loss 12.809823179543018\n",
      "loss 13.128360844999552\n",
      "loss 13.444709635227918\n",
      "loss 13.772293334305287\n",
      "loss 14.092961600124836\n",
      "Epoch:  76\n",
      "training loss =  0.32033400666467093\n",
      "Validation Loss: 0.8995\tTop 1 Validation Accuracy: 0.8231\t Top 5 Validation Accuracy: 0.9581\n",
      "loss 0.322191297262907\n",
      "loss 0.6409913252294064\n",
      "loss 0.9565361452102661\n",
      "loss 1.2736106184124947\n",
      "loss 1.5847794964909554\n",
      "loss 1.8904722183942795\n",
      "loss 2.204904327392578\n",
      "loss 2.52169034704566\n",
      "loss 2.8399013386666776\n",
      "loss 3.1569127286970615\n",
      "loss 3.4803934407234194\n",
      "loss 3.801141817867756\n",
      "loss 4.117192261517048\n",
      "loss 4.432741491049528\n",
      "loss 4.751482456177473\n",
      "loss 5.069541239440441\n",
      "loss 5.393100530654192\n",
      "loss 5.718428146541118\n",
      "loss 6.039564255028963\n",
      "loss 6.3637769381701945\n",
      "loss 6.678446308076381\n",
      "loss 7.001680946946144\n",
      "loss 7.325097809880972\n",
      "loss 7.643324794173241\n",
      "loss 7.959650153815747\n",
      "loss 8.276325304806232\n",
      "loss 8.598079844415189\n",
      "loss 8.908466434776782\n",
      "loss 9.224057692736388\n",
      "loss 9.54146093904972\n",
      "loss 9.855040603876114\n",
      "loss 10.17329150095582\n",
      "loss 10.494279627650975\n",
      "loss 10.80840936228633\n",
      "loss 11.140497749894857\n",
      "loss 11.463694238364697\n",
      "loss 11.79529539912939\n",
      "loss 12.116263378411531\n",
      "loss 12.433775371015072\n",
      "loss 12.761333499252796\n",
      "loss 13.087051480412484\n",
      "loss 13.406188804805279\n",
      "loss 13.731638357192278\n",
      "loss 14.05010815963149\n",
      "Epoch:  77\n",
      "training loss =  0.31955029925175243\n",
      "Validation Loss: 0.8976\tTop 1 Validation Accuracy: 0.8233\t Top 5 Validation Accuracy: 0.9582\n",
      "loss 0.3119510355591774\n",
      "loss 0.6281332932412624\n",
      "loss 0.9359672638773918\n",
      "loss 1.2531904768943787\n",
      "loss 1.5634492906928061\n",
      "loss 1.8759905815124511\n",
      "loss 2.189227095544338\n",
      "loss 2.5048135587573053\n",
      "loss 2.8199536561965943\n",
      "loss 3.1424440814554693\n",
      "loss 3.456463912278414\n",
      "loss 3.777385164499283\n",
      "loss 4.095952132791281\n",
      "loss 4.421032727360726\n",
      "loss 4.744102992564439\n",
      "loss 5.064522926658392\n",
      "loss 5.378036313652992\n",
      "loss 5.695280532389879\n",
      "loss 6.020354515016079\n",
      "loss 6.342489046156406\n",
      "loss 6.666757965534925\n",
      "loss 6.978512700647116\n",
      "loss 7.301380629390478\n",
      "loss 7.626925827115774\n",
      "loss 7.946983772963286\n",
      "loss 8.254536371380091\n",
      "loss 8.574878326803447\n",
      "loss 8.897204163223504\n",
      "loss 9.218251809477806\n",
      "loss 9.5404852001369\n",
      "loss 9.85978043243289\n",
      "loss 10.165512572079898\n",
      "loss 10.486743439286947\n",
      "loss 10.81268391802907\n",
      "loss 11.13407416537404\n",
      "loss 11.45179617136717\n",
      "loss 11.775873444229365\n",
      "loss 12.094971510022878\n",
      "loss 12.41470148921013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 12.732632557600736\n",
      "loss 13.054179078191519\n",
      "loss 13.371873470395803\n",
      "loss 13.68742412686348\n",
      "loss 14.01145370349288\n",
      "Epoch:  78\n",
      "training loss =  0.31845143555334937\n",
      "Validation Loss: 0.8969\tTop 1 Validation Accuracy: 0.8237\t Top 5 Validation Accuracy: 0.9583\n",
      "loss 0.3135009084641933\n",
      "loss 0.6320323421061039\n",
      "loss 0.9495444528758525\n",
      "loss 1.2736628486216068\n",
      "loss 1.5927687054872512\n",
      "loss 1.9070937265455723\n",
      "loss 2.219465205669403\n",
      "loss 2.538351401090622\n",
      "loss 2.8530726607143877\n",
      "loss 3.172382372021675\n",
      "loss 3.495971954315901\n",
      "loss 3.8204168942570687\n",
      "loss 4.13265199393034\n",
      "loss 4.454981852769851\n",
      "loss 4.7733298934996125\n",
      "loss 5.088432271778584\n",
      "loss 5.411049844026565\n",
      "loss 5.731211291402579\n",
      "loss 6.054289466589689\n",
      "loss 6.694584627747536\n",
      "loss 7.006336531341076\n",
      "loss 7.332576033174991\n",
      "loss 7.6490926994383335\n",
      "loss 7.9691055731475355\n",
      "loss 8.287759324908256\n",
      "loss 8.608819451928138\n",
      "loss 8.918386643379927\n",
      "loss 9.240820073783398\n",
      "loss 9.562381033748387\n",
      "loss 9.887508530467748\n",
      "loss 10.20499246969819\n",
      "loss 10.526764994561672\n",
      "loss 10.847001152187586\n",
      "loss 11.169149454981088\n",
      "loss 11.484879977405072\n",
      "loss 11.800354384928943\n",
      "loss 12.112126693278551\n",
      "loss 12.435129319727421\n",
      "loss 12.744267752766609\n",
      "loss 13.071093078702688\n",
      "loss 13.379521220326424\n",
      "loss 13.701825911551714\n",
      "loss 14.014364026337862\n",
      "Epoch:  79\n",
      "training loss =  0.3186420398011003\n",
      "Validation Loss: 0.8977\tTop 1 Validation Accuracy: 0.8236\t Top 5 Validation Accuracy: 0.9583\n",
      "loss 0.9550021295249462\n",
      "loss 1.2734913685917855\n",
      "loss 1.5876456548273563\n",
      "loss 1.9073403449356556\n",
      "loss 2.2260217641294004\n",
      "loss 2.534278286546469\n",
      "loss 2.8433297729492186\n",
      "loss 3.162193283736706\n",
      "loss 3.4814826580882072\n",
      "loss 3.797042580395937\n",
      "loss 4.1196210452914235\n",
      "loss 4.444989735782147\n",
      "loss 4.76223899692297\n",
      "loss 5.077977121174335\n",
      "loss 5.398579496741295\n",
      "loss 5.721434200406074\n",
      "loss 6.041959863603115\n",
      "loss 6.36302900031209\n",
      "loss 6.677111455351114\n",
      "loss 6.999017561227083\n",
      "loss 7.327204150408506\n",
      "loss 7.643653606027365\n",
      "loss 7.9602145470678805\n",
      "loss 8.276668917834758\n",
      "loss 8.591865090876817\n",
      "loss 8.907949118614196\n",
      "loss 9.226357797384262\n",
      "loss 9.533870186209679\n",
      "loss 9.846196399331093\n",
      "loss 10.162615375369787\n",
      "loss 10.480621662735938\n",
      "loss 10.794720326513051\n",
      "loss 11.110853735953569\n",
      "loss 11.420067915469408\n",
      "loss 11.73097833544016\n",
      "loss 12.047193661034107\n",
      "loss 12.363859171569347\n",
      "loss 12.672675371170044\n",
      "loss 12.990876906365155\n",
      "loss 13.307290461808442\n",
      "loss 13.616101837009191\n",
      "loss 13.927598041445016\n",
      "Epoch:  80\n",
      "training loss =  0.31669266316189454\n",
      "Validation Loss: 0.8974\tTop 1 Validation Accuracy: 0.8235\t Top 5 Validation Accuracy: 0.9584\n",
      "loss 0.3118733225762844\n",
      "loss 0.6185936787724495\n",
      "loss 0.9356066234409809\n",
      "loss 1.2474883867800235\n",
      "loss 1.559991929680109\n",
      "loss 1.8740393190085889\n",
      "loss 2.1872009459137915\n",
      "loss 2.501782160997391\n",
      "loss 2.8181246727705003\n",
      "loss 3.1358148390054703\n",
      "loss 3.441704871058464\n",
      "loss 3.756710517257452\n",
      "loss 4.072521168291569\n",
      "loss 4.390948552638292\n",
      "loss 4.701724086999893\n",
      "loss 5.01591386795044\n",
      "loss 5.329188547581435\n",
      "loss 5.640268800705671\n",
      "loss 5.9577868065238\n",
      "loss 6.279143581241369\n",
      "loss 6.594351333081722\n",
      "loss 6.903618089705706\n",
      "loss 7.217263709455729\n",
      "loss 7.543876113593578\n",
      "loss 7.866376240551472\n",
      "loss 8.18047526985407\n",
      "loss 8.49995626628399\n",
      "loss 8.812992759793996\n",
      "loss 9.121989512443543\n",
      "loss 9.44343575462699\n",
      "loss 9.760540706813336\n",
      "loss 10.069608606994152\n",
      "loss 10.39482551664114\n",
      "loss 10.709350409805774\n",
      "loss 11.017290676683187\n",
      "loss 11.334997515678406\n",
      "loss 11.654800114780665\n",
      "loss 11.967061508446932\n",
      "loss 12.286131937503814\n",
      "loss 12.60124364450574\n",
      "loss 12.915024936944246\n",
      "loss 13.231329525858165\n",
      "loss 13.55483411744237\n",
      "loss 13.869871263056993\n",
      "Epoch:  81\n",
      "training loss =  0.31534792457386596\n",
      "Validation Loss: 0.8937\tTop 1 Validation Accuracy: 0.8238\t Top 5 Validation Accuracy: 0.9584\n",
      "loss 0.3151262165606022\n",
      "loss 0.6348850063979625\n",
      "loss 0.9502339307963849\n",
      "loss 1.2685934057831765\n",
      "loss 1.5829491721093654\n",
      "loss 1.8982343873381615\n",
      "loss 2.218254795074463\n",
      "loss 2.5416076138615606\n",
      "loss 2.8578502359986304\n",
      "loss 3.1711900171637537\n",
      "loss 3.4924795632064343\n",
      "loss 3.810036359876394\n",
      "loss 4.127009021937847\n",
      "loss 4.437557734251023\n",
      "loss 5.065471852719784\n",
      "loss 5.3830908785760405\n",
      "loss 5.705605663210154\n",
      "loss 6.024337948709726\n",
      "loss 6.647207327485084\n",
      "loss 6.959728328585625\n",
      "loss 7.273906032294035\n",
      "loss 7.59030236274004\n",
      "loss 7.907581403106451\n",
      "loss 8.22439223587513\n",
      "loss 8.532656634747982\n",
      "loss 8.850667997300626\n",
      "loss 9.171632426977158\n",
      "loss 9.483792408555747\n",
      "loss 9.801270092278719\n",
      "loss 10.118801913708449\n",
      "loss 10.426220037192106\n",
      "loss 10.738833626061679\n",
      "loss 11.05614808216691\n",
      "loss 11.37455461770296\n",
      "loss 11.691562009304763\n",
      "loss 12.004965276867152\n",
      "loss 12.318683422803879\n",
      "loss 12.636412384212017\n",
      "loss 12.951185506731271\n",
      "loss 13.267776113599538\n",
      "loss 13.580170668512583\n",
      "loss 13.895057767033578\n",
      "Epoch:  82\n",
      "training loss =  0.31583554370566275\n",
      "Validation Loss: 0.8965\tTop 1 Validation Accuracy: 0.8236\t Top 5 Validation Accuracy: 0.9582\n",
      "loss 0.31315159633755685\n",
      "loss 0.6248136973381042\n",
      "loss 0.9388478070497512\n",
      "loss 1.2545543929934502\n",
      "loss 1.5744728535413741\n",
      "loss 1.900217002183199\n",
      "loss 2.2150949107110502\n",
      "loss 2.5342853908240794\n",
      "loss 2.8503906828165055\n",
      "loss 3.169207414388657\n",
      "loss 3.489029174298048\n",
      "loss 3.8025952477753164\n",
      "loss 4.116067708432674\n",
      "loss 4.431525093168021\n",
      "loss 4.75128102183342\n",
      "loss 5.068526247888803\n",
      "loss 5.381690135002136\n",
      "loss 5.70624011605978\n",
      "loss 6.019876602441072\n",
      "loss 6.333678846806288\n",
      "loss 6.644061742126942\n",
      "loss 6.96505137398839\n",
      "loss 7.284045947194099\n",
      "loss 7.60832861945033\n",
      "loss 7.9257544323802\n",
      "loss 8.244877195358276\n",
      "loss 8.56754102870822\n",
      "loss 8.88299643561244\n",
      "loss 9.196002433151007\n",
      "loss 9.524670051932334\n",
      "loss 9.846557872146368\n",
      "loss 10.164047669321299\n",
      "loss 10.472213661670684\n",
      "loss 11.40658130556345\n",
      "loss 11.718100867569447\n",
      "loss 12.035426228046417\n",
      "loss 12.351604674756526\n",
      "loss 12.665231847912073\n",
      "loss 12.983734253644943\n",
      "loss 13.301365491449832\n",
      "loss 13.618643659055232\n",
      "loss 13.938282901644707\n",
      "Epoch:  83\n",
      "training loss =  0.3169162686564881\n",
      "Validation Loss: 0.8946\tTop 1 Validation Accuracy: 0.8237\t Top 5 Validation Accuracy: 0.9584\n",
      "loss 0.30697922840714453\n",
      "loss 0.6155117774009704\n",
      "loss 0.9307674692571163\n",
      "loss 1.2433120492100715\n",
      "loss 1.5471281777322292\n",
      "loss 1.8688729594647884\n",
      "loss 2.182051660269499\n",
      "loss 2.492178725898266\n",
      "loss 2.806014769375324\n",
      "loss 3.123894933313131\n",
      "loss 3.4376716983318327\n",
      "loss 3.745599101781845\n",
      "loss 4.065408392846584\n",
      "loss 4.382340125739574\n",
      "loss 4.693301454037428\n",
      "loss 5.011958119869232\n",
      "loss 5.331928268074989\n",
      "loss 5.646335088610649\n",
      "loss 5.963872568011284\n",
      "loss 6.281941714286805\n",
      "loss 6.596241747140884\n",
      "loss 6.9114881317317485\n",
      "loss 7.226896859556437\n",
      "loss 7.5495408372581005\n",
      "loss 7.862413910031319\n",
      "loss 8.183703093826772\n",
      "loss 8.494833486229181\n",
      "loss 8.817603585720063\n",
      "loss 9.128028687387705\n",
      "loss 9.446752765774727\n",
      "loss 9.75805064857006\n",
      "loss 10.07796707123518\n",
      "loss 10.39021806538105\n",
      "loss 10.702335277497768\n",
      "loss 11.030617579966783\n",
      "loss 11.347999435514211\n",
      "loss 11.671431395560504\n",
      "loss 11.985945090204478\n",
      "loss 12.303327452093363\n",
      "loss 12.62640933021903\n",
      "loss 12.941283251941204\n",
      "loss 13.268739628940821\n",
      "loss 13.588581371456385\n",
      "loss 13.90756020694971\n",
      "Epoch:  84\n",
      "training loss =  0.31613531943275763\n",
      "Validation Loss: 0.8943\tTop 1 Validation Accuracy: 0.8236\t Top 5 Validation Accuracy: 0.9584\n",
      "loss 0.31844683215022085\n",
      "loss 0.6367472051084042\n",
      "loss 0.9510987821221352\n",
      "loss 1.2670360791683197\n",
      "loss 1.5837288695573806\n",
      "loss 1.896894553899765\n",
      "loss 2.207676773518324\n",
      "loss 2.5191082537174223\n",
      "loss 2.8343707586824896\n",
      "loss 3.1513124710321425\n",
      "loss 3.466445957869291\n",
      "loss 3.7783737972378733\n",
      "loss 4.090735241174698\n",
      "loss 4.416572477370501\n",
      "loss 4.732106930613518\n",
      "loss 5.053400570601225\n",
      "loss 5.362812965810299\n",
      "loss 5.677784873843193\n",
      "loss 5.990834352821111\n",
      "loss 6.308124224543572\n",
      "loss 6.627000993788243\n",
      "loss 6.946002132445574\n",
      "loss 7.265221307575703\n",
      "loss 7.580899726897478\n",
      "loss 7.90379415884614\n",
      "loss 8.222360043227672\n",
      "loss 8.542960802912711\n",
      "loss 8.850745273530483\n",
      "loss 9.169021232277155\n",
      "loss 9.491801511198283\n",
      "loss 9.804089518487453\n",
      "loss 10.125060845166445\n",
      "loss 10.447934369891883\n",
      "loss 10.765632215589285\n",
      "loss 11.08106615036726\n",
      "loss 11.394333088696003\n",
      "loss 11.720799866765738\n",
      "loss 12.040476634055375\n",
      "loss 12.35009891808033\n",
      "loss 12.661425802707672\n",
      "loss 12.980551034063101\n",
      "loss 13.288282551914454\n",
      "loss 13.601208382844925\n",
      "loss 13.917920854240656\n",
      "Epoch:  85\n",
      "training loss =  0.31639183048441194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8990\tTop 1 Validation Accuracy: 0.8236\t Top 5 Validation Accuracy: 0.9583\n",
      "loss 0.31330472871661186\n",
      "loss 0.6255918936431408\n",
      "loss 0.9464607049524784\n",
      "loss 1.2600794304907321\n",
      "loss 1.5818608021736145\n",
      "loss 1.8982395127415657\n",
      "loss 2.2198855593800544\n",
      "loss 2.5362278889119625\n",
      "loss 2.8441498520970345\n",
      "loss 3.1617984391748903\n",
      "loss 3.477929479777813\n",
      "loss 3.7902146115899087\n",
      "loss 4.096612471789122\n",
      "loss 4.414610765874386\n",
      "loss 4.733254755139351\n",
      "loss 5.051517136543989\n",
      "loss 5.373894556611776\n",
      "loss 5.68400531038642\n",
      "loss 5.99734433606267\n",
      "loss 6.3105763927102085\n",
      "loss 6.633904835283756\n",
      "loss 6.954713935703039\n",
      "loss 7.267993452548981\n",
      "loss 7.57869120836258\n",
      "loss 7.8896405313909055\n",
      "loss 8.211246256381273\n",
      "loss 8.523614373207092\n",
      "loss 8.84166780397296\n",
      "loss 9.155185446739196\n",
      "loss 9.467977335304022\n",
      "loss 9.787371806353331\n",
      "loss 10.097171904891729\n",
      "loss 10.410468050986529\n",
      "loss 10.731414847522974\n",
      "loss 11.041948965489864\n",
      "loss 11.351324161738157\n",
      "loss 11.670068921744823\n",
      "loss 11.987421274632215\n",
      "loss 12.303494893759488\n",
      "loss 12.613147274255752\n",
      "loss 12.929859121441842\n",
      "loss 13.240570859014987\n",
      "loss 13.555773677527904\n",
      "loss 13.863357812911271\n",
      "Epoch:  86\n",
      "training loss =  0.3151391364193402\n",
      "Validation Loss: 0.8943\tTop 1 Validation Accuracy: 0.8238\t Top 5 Validation Accuracy: 0.9585\n",
      "loss 0.31429472923278806\n",
      "loss 0.630054462403059\n",
      "loss 0.9477242468297482\n",
      "loss 1.2637087847292423\n",
      "loss 1.5849861873686313\n",
      "loss 1.8997677409648894\n",
      "loss 2.2191886731982233\n",
      "loss 2.523269295245409\n",
      "loss 2.828261313587427\n",
      "loss 3.1395095789432528\n",
      "loss 3.4506504771113398\n",
      "loss 3.7572529415786264\n",
      "loss 4.080387489199638\n",
      "loss 4.3981233468651775\n",
      "loss 4.7121647141873835\n",
      "loss 5.0236984233558175\n",
      "loss 5.343337961882352\n",
      "loss 5.6630936157703395\n",
      "loss 5.9730350022017955\n",
      "loss 6.296874239891768\n",
      "loss 6.618455616086721\n",
      "loss 7.237728636413813\n",
      "loss 7.554617900550365\n",
      "loss 7.872636715918779\n",
      "loss 8.187169141620398\n",
      "loss 8.501754201352597\n",
      "loss 8.80746857509017\n",
      "loss 9.128440510034562\n",
      "loss 9.442399141937495\n",
      "loss 9.75804820805788\n",
      "loss 10.085483133494854\n",
      "loss 10.398815424442292\n",
      "loss 10.711217252612114\n",
      "loss 11.030248873233795\n",
      "loss 11.345631809681654\n",
      "loss 11.661010064482689\n",
      "loss 11.976012640297412\n",
      "loss 12.293990802466869\n",
      "loss 12.613800500631333\n",
      "loss 12.924765408337116\n",
      "loss 13.241411470621824\n",
      "loss 13.561174215078355\n",
      "loss 13.88110696464777\n",
      "Epoch:  87\n",
      "training loss =  0.31550055279513545\n",
      "Validation Loss: 0.8990\tTop 1 Validation Accuracy: 0.8232\t Top 5 Validation Accuracy: 0.9581\n",
      "loss 0.31034589603543283\n",
      "loss 0.6255526885390281\n",
      "loss 0.9432058124244214\n",
      "loss 1.2652446438372136\n",
      "loss 1.5874302238225937\n",
      "loss 1.9016293098032475\n",
      "loss 2.21443530485034\n",
      "loss 2.5283050030469894\n",
      "loss 2.8454739743471147\n",
      "loss 3.1625176475942136\n",
      "loss 3.4800858515501023\n",
      "loss 3.794237548559904\n",
      "loss 4.117655835747719\n",
      "loss 4.4349839355051515\n",
      "loss 4.752193388193846\n",
      "loss 5.0704108256101605\n",
      "loss 5.389990828335285\n",
      "loss 5.7009365861117836\n",
      "loss 6.019433819353581\n",
      "loss 6.334841480702162\n",
      "loss 6.649406406730414\n",
      "loss 6.964997232854366\n",
      "loss 7.272468813955784\n",
      "loss 7.584919329881668\n",
      "loss 7.9000691471993925\n",
      "loss 8.222692316770553\n",
      "loss 8.54066996023059\n",
      "loss 8.85160148486495\n",
      "loss 9.172998170107602\n",
      "loss 9.480131127536296\n",
      "loss 10.109703137278556\n",
      "loss 10.434664388597012\n",
      "loss 10.739209412783385\n",
      "loss 11.055776124447585\n",
      "loss 11.37833019092679\n",
      "loss 11.692577389627695\n",
      "loss 12.015404386669397\n",
      "loss 12.331514827907085\n",
      "loss 12.645364626795054\n",
      "loss 12.952419818937779\n",
      "loss 13.265480426847935\n",
      "loss 13.579709724783898\n",
      "loss 13.897184744030238\n",
      "Epoch:  88\n",
      "training loss =  0.31593538224630097\n",
      "Validation Loss: 0.8969\tTop 1 Validation Accuracy: 0.8239\t Top 5 Validation Accuracy: 0.9584\n",
      "loss 0.3205410547554493\n",
      "loss 0.6409701259434223\n",
      "loss 0.9564082357287407\n",
      "loss 1.268251573741436\n",
      "loss 1.5855741389095783\n",
      "loss 1.902166974246502\n",
      "loss 2.2270906907320023\n",
      "loss 2.5469138112664225\n",
      "loss 2.8628114472329615\n",
      "loss 3.1780832163989543\n",
      "loss 3.4982002307474613\n",
      "loss 3.817973897755146\n",
      "loss 4.131548939347267\n",
      "loss 4.444528657048941\n",
      "loss 4.770568059533835\n",
      "loss 5.086914129853248\n",
      "loss 5.399042806178332\n",
      "loss 5.716477081924677\n",
      "loss 6.038041936457157\n",
      "loss 6.360632243603468\n",
      "loss 6.6736395378410815\n",
      "loss 6.989741473197937\n",
      "loss 7.304405682682991\n",
      "loss 7.622873423695564\n",
      "loss 7.935540856420994\n",
      "loss 8.253327557742596\n",
      "loss 8.56630983620882\n",
      "loss 8.88250392332673\n",
      "loss 9.191189906448125\n",
      "loss 9.508893047124147\n",
      "loss 9.817479857057332\n",
      "loss 10.135553566068412\n",
      "loss 10.456868280768395\n",
      "loss 10.773857449442149\n",
      "loss 11.0838635379076\n",
      "loss 11.401341356486082\n",
      "loss 11.719030969142914\n",
      "loss 12.037014513760806\n",
      "loss 12.353989952802658\n",
      "loss 12.673807119429112\n",
      "loss 12.985374198257922\n",
      "loss 13.300427147001027\n",
      "loss 13.603654899001121\n",
      "loss 13.911166525185108\n",
      "Epoch:  89\n",
      "training loss =  0.316183435902157\n",
      "Validation Loss: 0.8967\tTop 1 Validation Accuracy: 0.8236\t Top 5 Validation Accuracy: 0.9583\n",
      "loss 0.3244266675412655\n",
      "loss 0.6377800990641117\n",
      "loss 0.9496686734259129\n",
      "loss 1.2732046392560006\n",
      "loss 1.5875280000269414\n",
      "loss 1.8990755844116212\n",
      "loss 2.2188267213106156\n",
      "loss 2.531034475415945\n",
      "loss 2.850819364786148\n",
      "loss 3.1679952891170977\n",
      "loss 3.487493681013584\n",
      "loss 3.800131312161684\n",
      "loss 4.1102422797679905\n",
      "loss 4.422323940843344\n",
      "loss 4.732464558780193\n",
      "loss 5.046424121707678\n",
      "loss 5.370120546966791\n",
      "loss 5.685708366185427\n",
      "loss 5.9969363938272\n",
      "loss 6.322916363030672\n",
      "loss 6.64368869960308\n",
      "loss 6.963915361315012\n",
      "loss 7.2791034899652\n",
      "loss 7.585908385813236\n",
      "loss 7.903489175587892\n",
      "loss 8.218369212448597\n",
      "loss 8.53242255628109\n",
      "loss 8.842509160637855\n",
      "loss 9.159206512570382\n",
      "loss 9.477098665982485\n",
      "loss 9.793676186650991\n",
      "loss 10.109734068065881\n",
      "loss 10.420522177219391\n",
      "loss 10.731086135804652\n",
      "loss 11.04985957801342\n",
      "loss 11.366567176580428\n",
      "loss 11.680554553866386\n",
      "loss 11.997437299340964\n",
      "loss 12.305228351205587\n",
      "loss 12.619042222797871\n",
      "loss 12.935289319455624\n",
      "loss 13.251816018968821\n",
      "loss 13.566782775968314\n",
      "loss 13.885129818320275\n",
      "Epoch:  90\n",
      "training loss =  0.31565481659895334\n",
      "Validation Loss: 0.8962\tTop 1 Validation Accuracy: 0.8236\t Top 5 Validation Accuracy: 0.9583\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(modelname)\n",
    "\n",
    "train(model, train_dataloader, validation_dataloader, criterion, optimizer, lr_scheduler, modelpath, writer, device, epochs = num_Epochs)\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load saved model from checkpoint  #####\n",
    "model, optimizer, lr_scheduler, train_loss, v_loss, v_acc, epoch = load(modelpath, model, optimizer, lr_scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Plot Loss Curves ####/\n",
    "plot_loss(epoch, train_loss, v_loss, title = 'New_Data_Apro_AA_Cutout_EB4')\n",
    "plot_acc(epoch, v_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 2.\nOriginal Traceback (most recent call last):\n  File \"/home/ironman/saket/anaconda3/envs/abhishek_env/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 60, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/ironman/saket/anaconda3/envs/abhishek_env/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/ironman/abhishek/AliProducts/architectures/efficientnet.py\", line 257, in forward\n    x = self.extract_features(inputs)\n  File \"/home/ironman/abhishek/AliProducts/architectures/efficientnet.py\", line 239, in extract_features\n    x = block(x, drop_connect_rate=drop_connect_rate)\n  File \"/home/ironman/saket/anaconda3/envs/abhishek_env/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/ironman/abhishek/AliProducts/architectures/efficientnet.py\", line 105, in forward\n    x = self._swish(x)\n  File \"/home/ironman/saket/anaconda3/envs/abhishek_env/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/ironman/abhishek/AliProducts/architectures/efficientnet.py\", line 434, in forward\n    return SwishImplementation.apply(x)\n  File \"/home/ironman/abhishek/AliProducts/architectures/efficientnet.py\", line 422, in forward\n    result = i * torch.sigmoid(i)\nRuntimeError: CUDA out of memory. Tried to allocate 222.00 MiB (GPU 2; 23.65 GiB total capacity; 21.98 GiB already allocated; 92.00 MiB free; 22.74 GiB reserved in total by PyTorch)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2cb6c62b45c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtop1_t_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5_t_acc\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtest_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training Loss: {:.4f}\\tTop 1 Training Accuracy: {:.4f}\\t Top 5 Training Accuracy: {:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop1_t_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop5_t_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/abhishek/AliProducts/Helper/trainer.py\u001b[0m in \u001b[0;36mtest_classify\u001b[0;34m(model, test_loader, criterion, device)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/saket/anaconda3/envs/abhishek_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/saket/anaconda3/envs/abhishek_env/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/saket/anaconda3/envs/abhishek_env/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/saket/anaconda3/envs/abhishek_env/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/saket/anaconda3/envs/abhishek_env/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 2.\nOriginal Traceback (most recent call last):\n  File \"/home/ironman/saket/anaconda3/envs/abhishek_env/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 60, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/ironman/saket/anaconda3/envs/abhishek_env/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/ironman/abhishek/AliProducts/architectures/efficientnet.py\", line 257, in forward\n    x = self.extract_features(inputs)\n  File \"/home/ironman/abhishek/AliProducts/architectures/efficientnet.py\", line 239, in extract_features\n    x = block(x, drop_connect_rate=drop_connect_rate)\n  File \"/home/ironman/saket/anaconda3/envs/abhishek_env/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/ironman/abhishek/AliProducts/architectures/efficientnet.py\", line 105, in forward\n    x = self._swish(x)\n  File \"/home/ironman/saket/anaconda3/envs/abhishek_env/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/ironman/abhishek/AliProducts/architectures/efficientnet.py\", line 434, in forward\n    return SwishImplementation.apply(x)\n  File \"/home/ironman/abhishek/AliProducts/architectures/efficientnet.py\", line 422, in forward\n    result = i * torch.sigmoid(i)\nRuntimeError: CUDA out of memory. Tried to allocate 222.00 MiB (GPU 2; 23.65 GiB total capacity; 21.98 GiB already allocated; 92.00 MiB free; 22.74 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "t_loss,top1_t_acc, top5_t_acc =test_classify(model, train_dataloader, criterion, device)\n",
    "print('Training Loss: {:.4f}\\tTop 1 Training Accuracy: {:.4f}\\t Top 5 Training Accuracy: {:.4f}'.format(t_loss, top1_t_acc, top5_t_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.8962\tTop 1 Validation Accuracy: 0.8236\n",
      "Accuracy:defaultdict(<class 'int'>, {'Top 1 Accuracy': 82.35601951909092, 'Top 5 Accuracy': 95.826367083962, 'Top 10 Accuracy': 96.99397844200682, 'Top 20 Accuracy': 97.76400386032161, 'Top 30 Accuracy': 98.10518017099594, 'Top 50 Accuracy': 98.50276611072599, 'Top 100 Accuracy': 98.90918729356115})\t\n"
     ]
    }
   ],
   "source": [
    "v_loss, top1_acc, accuracy_dict= eval_classify(model, validation_dataloader, criterion, device)\n",
    "print('Validation Loss: {:.4f}\\tTop 1 Validation Accuracy: {:.4f}\\nAccuracy:{}\\t'.format(v_loss, top1_acc, accuracy_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
