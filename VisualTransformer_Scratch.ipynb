{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 28 11:19:19 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 43%   64C    P2   264W / 280W |  18542MiB / 24220MiB |     98%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 91%   87C    P2   190W / 280W |  17046MiB / 24220MiB |     90%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "|100%   88C    P2   184W / 280W |  16826MiB / 24220MiB |     88%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN RTX           Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "|100%   88C    P2   223W / 280W |  16936MiB / 24220MiB |     86%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  TITAN RTX           Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 41%   30C    P8     2W / 280W |     11MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  TITAN RTX           Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 40%   33C    P8    33W / 280W |     11MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  TITAN RTX           Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 41%   29C    P8    20W / 280W |   2526MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  TITAN RTX           Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 41%   26C    P8    13W / 280W |     11MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     28313      C   .../anaconda3/envs/abhishek_env/bin/python 18475MiB |\n",
      "|    1     28313      C   .../anaconda3/envs/abhishek_env/bin/python 16979MiB |\n",
      "|    2     28313      C   .../anaconda3/envs/abhishek_env/bin/python 16759MiB |\n",
      "|    3     28313      C   .../anaconda3/envs/abhishek_env/bin/python 16869MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### IMPORTING NECESSARY MODULES #########\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.append('/home/ironman/abhishek/AliProducts/architectures/pytorch-image-models/timm/models/')\n",
    "sys.path.append('/home/ironman/abhishek/AliProducts/architectures/pytorch-image-models/')\n",
    "sys.path.append('/home/ironman/abhishek/AliProducts/Helper/')\n",
    "\n",
    "from dataloader import mydataset, create_prime_dict \n",
    "from trainer_ViT import train, test_classify, eval_classify\n",
    "from Load_model import load\n",
    "\n",
    "\n",
    "\n",
    "from vision_transformer import vit_base_patch32_384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:4\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:4' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataloading Scheme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlist = '/home/ironman/abhishek/AliProducts/Newlist/NEW_train_list1.txt'\n",
    "validlist = '/home/ironman/abhishek/AliProducts/Newlist/NEW_valid_list1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes =  50030\n"
     ]
    }
   ],
   "source": [
    "prime_dict = create_prime_dict(trainlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train Dataloader #### \n",
    "train_dataset = mydataset(trainlist, prime_dict, name='train')          \n",
    "train_dataloader = data.DataLoader(train_dataset, shuffle= True, batch_size = 512, num_workers=16,pin_memory=True)\n",
    "\n",
    "\n",
    "#### Validation Dataloader #### \n",
    "validation_dataset = mydataset(validlist, prime_dict, name='valid')         \n",
    "validation_dataloader = data.DataLoader(validation_dataset, shuffle=False, batch_size = 256, num_workers=16,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vit_base_patch32_384(pretrained=False)\n",
    "\n",
    "\n",
    "model = nn.DataParallel(model,device_ids=[4,5,6,7]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=50030, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Transfer Learning\n",
    "'''\n",
    "\n",
    "# for param in model.module.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "fc_inputs = model.module.head.in_features\n",
    "\n",
    "model.module.head = nn.Sequential(\n",
    "    nn.Linear(fc_inputs, 50030),\n",
    "#     nn.BatchNorm1d(4096),\n",
    "#     nn.GELU(),\n",
    "#     nn.Linear(1000, 50030)\n",
    "    \n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, weight_decay=1e-4, momentum=0.9)\n",
    "\n",
    "\n",
    "# Epochs\n",
    "num_Epochs = 30\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 10, gamma = 0.1)\n",
    "\n",
    "#Cutmix\n",
    "# beta = 1\n",
    "# cutmix_prob = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'ViT_scratch_vit_base_patch32_384'\n",
    "modelpath = '/home/ironman/abhishek/saved_model_checkpoints/AliProducts/' + modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 10.933627815246583\n",
      "loss 21.733247299194336\n",
      "loss 32.41564968109131\n",
      "loss 42.99922583580017\n",
      "loss 53.48661211013794\n",
      "loss 63.87816764831543\n",
      "loss 74.17049338340759\n",
      "loss 84.36832669258118\n",
      "loss 94.47614013671875\n",
      "loss 104.49102215766906\n",
      "loss 114.40977081298828\n",
      "loss 124.25798411369324\n",
      "loss 134.0140498828888\n",
      "loss 143.67665919303894\n",
      "loss 153.2670813179016\n",
      "loss 162.77277848243713\n",
      "loss 172.1930432987213\n",
      "loss 181.54050104141234\n",
      "loss 190.81232724189758\n",
      "loss 199.99715372085572\n",
      "loss 209.10913783073426\n",
      "loss 218.13279258728028\n",
      "Epoch:  1\n",
      "training loss =  9.905279330641246\n",
      "Validation Loss: 9.6937\tTop 1 Validation Accuracy: 0.0013\t Top 5 Validation Accuracy: 0.0052\n",
      "loss 8.758600730895996\n",
      "loss 17.453941917419435\n",
      "loss 26.115173177719115\n",
      "loss 34.698236322402956\n",
      "loss 43.20842604637146\n",
      "loss 51.626526527404785\n",
      "loss 59.97377611160278\n",
      "loss 68.23331408500671\n",
      "loss 76.41389558315277\n",
      "loss 84.51837792396546\n",
      "loss 92.53543013095856\n",
      "loss 100.46762336730957\n",
      "loss 108.3040635061264\n",
      "loss 116.05524034023284\n",
      "loss 123.74505958557128\n",
      "loss 131.32959958076478\n",
      "loss 138.83025898456575\n",
      "loss 146.2296022605896\n",
      "loss 153.57949521541596\n",
      "loss 160.84018001556396\n",
      "loss 175.13181907653808\n",
      "Epoch:  2\n",
      "training loss =  7.950524231083959\n",
      "Validation Loss: 8.8380\tTop 1 Validation Accuracy: 0.0118\t Top 5 Validation Accuracy: 0.0344\n",
      "loss 6.553572525978089\n",
      "loss 13.016101813316345\n",
      "loss 19.45566903591156\n",
      "loss 25.865927515029906\n",
      "loss 32.247093348503114\n",
      "loss 38.61132004737854\n",
      "loss 44.876769828796384\n",
      "loss 51.093532872200015\n",
      "loss 57.248820867538456\n",
      "loss 63.35669542312622\n",
      "loss 69.44321599960327\n",
      "loss 75.46034486293793\n",
      "loss 81.43522010326386\n",
      "loss 87.31580589294434\n",
      "loss 93.16958053588867\n",
      "loss 98.96280424594879\n",
      "loss 104.69903389453889\n",
      "loss 110.39636783123017\n",
      "loss 116.01885437488556\n",
      "loss 121.63333372592926\n",
      "loss 127.17412393569947\n",
      "loss 132.69207122325898\n",
      "Epoch:  3\n",
      "training loss =  6.025744894854457\n",
      "Validation Loss: 7.8209\tTop 1 Validation Accuracy: 0.0385\t Top 5 Validation Accuracy: 0.0976\n",
      "loss 4.648338756561279\n",
      "loss 9.273978838920593\n",
      "loss 13.918392000198365\n",
      "loss 18.550149059295656\n",
      "loss 23.191508774757384\n",
      "loss 27.848588709831237\n",
      "loss 32.46585461616516\n",
      "loss 37.10404834270477\n",
      "loss 41.73709538936615\n",
      "loss 46.389462962150574\n",
      "loss 50.99769954681396\n",
      "loss 55.58368588924408\n",
      "loss 60.1824160528183\n",
      "loss 64.74983683109284\n",
      "loss 69.2944851732254\n",
      "loss 73.83249948501587\n",
      "loss 78.32119105815887\n",
      "loss 82.80113568782807\n",
      "loss 87.23070221424103\n",
      "loss 91.67117411851883\n",
      "loss 96.10517340660095\n",
      "loss 100.50239916324615\n",
      "Epoch:  4\n",
      "training loss =  4.565705425876508\n",
      "Validation Loss: 7.4933\tTop 1 Validation Accuracy: 0.0602\t Top 5 Validation Accuracy: 0.1405\n",
      "loss 3.457635099887848\n",
      "loss 6.820678293704987\n",
      "loss 10.25371789932251\n",
      "loss 13.672331421375274\n",
      "loss 17.118252952098846\n",
      "loss 20.602406945228577\n",
      "loss 24.140806138515472\n",
      "loss 27.68533598423004\n",
      "loss 31.234781692028047\n",
      "loss 34.81424869298935\n",
      "loss 38.39370792388916\n",
      "loss 41.9692547249794\n",
      "loss 45.58202959537506\n",
      "loss 49.21196017742157\n",
      "loss 52.80054654121399\n",
      "loss 56.41872903108597\n",
      "loss 60.008972797393795\n",
      "loss 63.61259624242783\n",
      "loss 67.20855221033096\n",
      "loss 70.81025798559189\n",
      "loss 74.40348191022873\n",
      "loss 77.98959815502167\n",
      "Epoch:  5\n",
      "training loss =  3.545616647322401\n",
      "Validation Loss: 6.8182\tTop 1 Validation Accuracy: 0.0963\t Top 5 Validation Accuracy: 0.2047\n",
      "loss 2.5534076142311095\n",
      "loss 5.074111576080322\n",
      "loss 7.608775100708008\n",
      "loss 10.180601000785828\n",
      "loss 12.805029647350311\n",
      "loss 15.461999509334564\n",
      "loss 18.198440027236938\n",
      "loss 20.963760485649107\n",
      "loss 23.744484100341797\n",
      "loss 26.53632469654083\n",
      "loss 29.325750920772553\n",
      "loss 32.19252746343613\n",
      "loss 35.11023347616196\n",
      "loss 37.98997964382172\n",
      "loss 40.896070716381075\n",
      "loss 43.854142656326296\n",
      "loss 46.865394225120546\n",
      "loss 49.82105524539948\n",
      "loss 52.830433444976805\n",
      "loss 55.80691002368927\n",
      "loss 58.80344709634781\n",
      "loss 61.81882665634155\n",
      "Epoch:  6\n",
      "training loss =  2.8118915931998396\n",
      "Validation Loss: 6.6501\tTop 1 Validation Accuracy: 0.1093\t Top 5 Validation Accuracy: 0.2292\n",
      "loss 1.942106832265854\n",
      "loss 3.8477853643894195\n",
      "loss 5.77841943860054\n",
      "loss 7.772106369733811\n",
      "loss 9.795832841396331\n",
      "loss 11.850606977939606\n",
      "loss 13.97336808681488\n",
      "loss 16.15092576980591\n",
      "loss 18.345294498205185\n",
      "loss 20.618530719280244\n",
      "loss 22.8696509206295\n",
      "loss 25.203357751369477\n",
      "loss 27.52749005317688\n",
      "loss 29.888120901584625\n",
      "loss 32.26924154281616\n",
      "loss 34.65336105585098\n",
      "loss 37.10586399793625\n",
      "loss 39.57469589471817\n",
      "loss 42.07777611255646\n",
      "loss 44.56841820001602\n",
      "loss 47.08858528137207\n",
      "loss 49.60047083377838\n",
      "Epoch:  7\n",
      "training loss =  2.257064361259234\n",
      "Validation Loss: 6.3173\tTop 1 Validation Accuracy: 0.1335\t Top 5 Validation Accuracy: 0.2692\n",
      "loss 1.468102513551712\n",
      "loss 2.904995472431183\n",
      "loss 4.383950924873352\n",
      "loss 5.877136586904526\n",
      "loss 7.436457129716874\n",
      "loss 9.041507015228271\n",
      "loss 10.686895633935928\n",
      "loss 12.395976264476776\n",
      "loss 14.101309497356414\n",
      "loss 15.865004371404648\n",
      "loss 17.680503723621367\n",
      "loss 19.544534294605256\n",
      "loss 21.4452701151371\n",
      "loss 23.367190055847168\n",
      "loss 25.351038632392882\n",
      "loss 27.351714869737624\n",
      "loss 29.357245815992357\n",
      "loss 31.41550995230675\n",
      "loss 33.50505524396896\n",
      "loss 35.59950186371803\n",
      "loss 37.725455561876295\n",
      "loss 39.86911231994629\n",
      "Epoch:  8\n",
      "training loss =  1.8160251887689391\n",
      "Validation Loss: 6.5114\tTop 1 Validation Accuracy: 0.1274\t Top 5 Validation Accuracy: 0.2553\n",
      "loss 1.131187560558319\n",
      "loss 2.1979912233352663\n",
      "loss 3.309940293431282\n",
      "loss 4.481021720767021\n",
      "loss 6.914412930011749\n",
      "loss 8.204450815916061\n",
      "loss 9.51985234260559\n",
      "loss 10.894913040399551\n",
      "loss 12.311062335968018\n",
      "loss 13.75837054014206\n",
      "loss 15.249023349285126\n",
      "loss 16.779455077648162\n",
      "loss 18.334531384706498\n",
      "loss 19.9437823843956\n",
      "loss 21.589608446359634\n",
      "loss 23.260682767629625\n",
      "loss 24.971205804347992\n",
      "loss 26.68122202515602\n",
      "loss 28.440653014183045\n",
      "loss 30.239436124563216\n",
      "loss 32.074169313907625\n",
      "Epoch:  9\n",
      "training loss =  1.4616161135675239\n",
      "Validation Loss: 6.7082\tTop 1 Validation Accuracy: 0.1221\t Top 5 Validation Accuracy: 0.2478\n",
      "loss 0.8593652719259262\n",
      "loss 1.6571130228042603\n",
      "loss 2.4859297519922254\n",
      "loss 3.352336102128029\n",
      "loss 4.264107424020767\n",
      "loss 5.21712983906269\n",
      "loss 6.199171660542488\n",
      "loss 7.236792657375336\n",
      "loss 8.305736039876939\n",
      "loss 9.405915940403938\n",
      "loss 10.558182429075242\n",
      "loss 11.744878634214402\n",
      "loss 12.980626182556152\n",
      "loss 14.249436465501786\n",
      "loss 15.530075980424881\n",
      "loss 16.855184191465376\n",
      "loss 18.22763103723526\n",
      "loss 19.656867940425872\n",
      "loss 21.11444706559181\n",
      "loss 22.607829501628874\n",
      "loss 24.144412797689437\n",
      "loss 25.68133651614189\n",
      "Epoch:  10\n",
      "training loss =  1.1718189164781743\n",
      "Validation Loss: 6.5259\tTop 1 Validation Accuracy: 0.1309\t Top 5 Validation Accuracy: 0.2638\n",
      "loss 0.5514064610004425\n",
      "loss 1.0390581893920898\n",
      "loss 1.5001580411195754\n",
      "loss 1.9477974238991738\n",
      "loss 2.3816626942157746\n",
      "loss 2.8137029054760934\n",
      "loss 3.2339663168787958\n",
      "loss 3.64713279992342\n",
      "loss 4.051295025348663\n",
      "loss 4.467091943919659\n",
      "loss 4.8681303358078\n",
      "loss 5.276755885481834\n",
      "loss 5.677514470219612\n",
      "loss 6.078496854007244\n",
      "loss 6.473965461552143\n",
      "loss 6.863345376849175\n",
      "loss 7.257577141821384\n",
      "loss 7.649059990048409\n",
      "loss 8.046740460693837\n",
      "loss 8.437544252872467\n",
      "loss 8.83190895318985\n",
      "loss 9.223070996999741\n",
      "Epoch:  11\n",
      "training loss =  0.4188056391858154\n",
      "Validation Loss: 6.1128\tTop 1 Validation Accuracy: 0.1622\t Top 5 Validation Accuracy: 0.3069\n",
      "loss 0.2916324082016945\n",
      "loss 0.5854702672362327\n",
      "loss 0.8813810402154922\n",
      "loss 1.178634939342737\n",
      "loss 1.4804925748705864\n",
      "loss 1.786636309325695\n",
      "loss 2.087039863616228\n",
      "loss 2.3940184472501276\n",
      "loss 2.6959096823632716\n",
      "loss 3.0065817914903166\n",
      "loss 3.3120791925489903\n",
      "loss 3.6192894995212557\n",
      "loss 3.9287213008105755\n",
      "loss 4.239474052190781\n",
      "loss 4.557194656580687\n",
      "loss 4.875695222318172\n",
      "loss 5.187808172702789\n",
      "loss 5.5018949855864046\n",
      "loss 5.8151884584128855\n",
      "loss 6.138832990825176\n",
      "loss 6.455037853717804\n",
      "loss 6.771830442845822\n",
      "Epoch:  12\n",
      "training loss =  0.3080017230734765\n",
      "Validation Loss: 6.0891\tTop 1 Validation Accuracy: 0.1625\t Top 5 Validation Accuracy: 0.3076\n",
      "loss 0.24965385749936103\n",
      "loss 0.49550611913204196\n",
      "loss 0.7435322725772857\n",
      "loss 0.9971722820401192\n",
      "loss 1.2504377374053002\n",
      "loss 1.5064502400159836\n",
      "loss 1.7601938614249228\n",
      "loss 2.0175506971776485\n",
      "loss 2.272893745154142\n",
      "loss 2.5335475657880306\n",
      "loss 2.7963612990081312\n",
      "loss 3.0592237938940525\n",
      "loss 3.321339639723301\n",
      "loss 3.5860476191341877\n",
      "loss 4.123523815572262\n",
      "loss 4.3849537591636185\n",
      "loss 4.656999400556088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 4.928913845717907\n",
      "loss 5.206485079675913\n",
      "loss 5.475172499716282\n",
      "loss 5.751386700719595\n",
      "Epoch:  13\n",
      "training loss =  0.26162714040134666\n",
      "Validation Loss: 6.0928\tTop 1 Validation Accuracy: 0.1634\t Top 5 Validation Accuracy: 0.3084\n",
      "loss 0.2124767306447029\n",
      "loss 0.4326511204242706\n",
      "loss 0.6513983422517776\n",
      "loss 0.8676120422780513\n",
      "loss 1.0855594128370285\n",
      "loss 1.3076799124479295\n",
      "loss 1.5243361127376556\n",
      "loss 1.7515611051023006\n",
      "loss 1.975921687334776\n",
      "loss 2.2048850375413895\n",
      "loss 2.4306453359127045\n",
      "loss 2.6623615458607675\n",
      "loss 2.897471466511488\n",
      "loss 3.137016724795103\n",
      "loss 3.372972179353237\n",
      "loss 3.6107492043077944\n",
      "loss 3.8530283312499525\n",
      "loss 4.095401875823736\n",
      "loss 4.335737729966641\n",
      "loss 4.583084492981434\n",
      "loss 4.827397936582566\n",
      "loss 5.071153498440981\n",
      "Epoch:  14\n",
      "training loss =  0.2306111086186745\n",
      "Validation Loss: 6.1014\tTop 1 Validation Accuracy: 0.1617\t Top 5 Validation Accuracy: 0.3061\n",
      "loss 0.1945379178225994\n",
      "loss 0.3877435454726219\n",
      "loss 0.5817832763493062\n",
      "loss 0.7837712214887143\n",
      "loss 0.9819899639487266\n",
      "loss 1.181311680674553\n",
      "loss 1.3809719449281692\n",
      "loss 1.582934191673994\n",
      "loss 1.785567043274641\n",
      "loss 1.9886452436447144\n",
      "loss 2.1941072735190392\n",
      "loss 2.402942441403866\n",
      "loss 2.6118201410770414\n",
      "loss 2.821501410603523\n",
      "loss 3.0346335610747337\n",
      "loss 3.2466124814748762\n",
      "loss 3.464088068306446\n",
      "loss 3.678655036240816\n",
      "loss 3.898207198828459\n",
      "loss 4.118478696793318\n",
      "loss 4.339167542159557\n",
      "loss 4.562402542829513\n",
      "Epoch:  15\n",
      "training loss =  0.2075164059994461\n",
      "Validation Loss: 6.0838\tTop 1 Validation Accuracy: 0.1634\t Top 5 Validation Accuracy: 0.3081\n",
      "loss 0.1690521492063999\n",
      "loss 0.3423054476082325\n",
      "loss 0.5183217068016529\n",
      "loss 0.6954305738210678\n",
      "loss 0.8734820754826069\n",
      "loss 1.05509870454669\n",
      "loss 1.2380596232414245\n",
      "loss 1.4239672109484673\n",
      "loss 1.6086505112051963\n",
      "loss 1.7986099904775619\n",
      "loss 1.988644873648882\n",
      "loss 2.178691883087158\n",
      "loss 2.3672573885321615\n",
      "loss 2.5665084193646908\n",
      "loss 2.7651640723645685\n",
      "loss 2.9605742248892786\n",
      "loss 3.156851900070906\n",
      "loss 3.353457943350077\n",
      "loss 3.55495999366045\n",
      "loss 3.7572287544608116\n",
      "loss 3.9639490289986132\n",
      "loss 4.1682896992564205\n",
      "Epoch:  16\n",
      "training loss =  0.18961099460185002\n",
      "Validation Loss: 6.1029\tTop 1 Validation Accuracy: 0.1612\t Top 5 Validation Accuracy: 0.3050\n",
      "loss 0.16018153503537177\n",
      "loss 0.32000444740056994\n",
      "loss 0.4828504624217749\n",
      "loss 0.6464178896695375\n",
      "loss 0.8151278878003358\n",
      "loss 0.9823972667008638\n",
      "loss 1.1500400189310311\n",
      "loss 1.3224197547882794\n",
      "loss 1.4917991100996733\n",
      "loss 1.6659541476517916\n",
      "loss 1.8406266025453806\n",
      "loss 2.018552170321345\n",
      "loss 2.196159527823329\n",
      "loss 2.3743472079187633\n",
      "loss 2.5574589186161756\n",
      "loss 2.74117617867887\n",
      "loss 2.9239217346161603\n",
      "loss 3.1086179956048725\n",
      "loss 3.2953374288231134\n",
      "loss 3.4796830827742813\n",
      "loss 3.6687095003575085\n",
      "loss 3.8561689879745247\n",
      "Epoch:  17\n",
      "training loss =  0.1754581866913187\n",
      "Validation Loss: 6.0718\tTop 1 Validation Accuracy: 0.1634\t Top 5 Validation Accuracy: 0.3092\n",
      "loss 0.1484032530337572\n",
      "loss 0.3006336981803179\n",
      "loss 0.4543022558838129\n",
      "loss 0.6069524353742599\n",
      "loss 0.7636662152409553\n",
      "loss 0.9205825665593147\n",
      "loss 1.0779360474646091\n",
      "loss 1.2362907334417104\n",
      "loss 1.3985829255729914\n",
      "loss 1.5603660824149848\n",
      "loss 1.7240461624413728\n",
      "loss 1.8865355753153563\n",
      "loss 2.053232454136014\n",
      "loss 2.2198068813234566\n",
      "loss 2.38720128364861\n",
      "loss 2.556571570262313\n",
      "loss 2.728626285120845\n",
      "loss 2.9000905927270653\n",
      "loss 3.07231890194118\n",
      "loss 3.2471596064418553\n",
      "loss 3.4233077888935806\n",
      "loss 3.601817802861333\n",
      "Epoch:  18\n",
      "training loss =  0.16400749533497494\n",
      "Validation Loss: 6.0682\tTop 1 Validation Accuracy: 0.1627\t Top 5 Validation Accuracy: 0.3080\n",
      "loss 0.13809698276221752\n",
      "loss 0.28011595018208024\n",
      "loss 0.4233926395326853\n",
      "loss 0.5681977336108684\n",
      "loss 0.7140083461999893\n",
      "loss 0.8606571178883314\n",
      "loss 1.007713472172618\n",
      "loss 1.1576210405677556\n",
      "loss 1.3071917966753244\n",
      "loss 1.4595139800757169\n",
      "loss 1.613782282024622\n",
      "loss 1.769501801431179\n",
      "loss 1.9258625511080028\n",
      "loss 2.083958173915744\n",
      "loss 2.2416659205406906\n",
      "loss 2.401670485660434\n",
      "loss 2.5632349730283024\n",
      "loss 2.7253380843997004\n",
      "loss 2.889502548724413\n",
      "loss 3.0562003807723523\n",
      "loss 3.227225638329983\n",
      "loss 3.3949627400934697\n",
      "Epoch:  19\n",
      "training loss =  0.1545341963471054\n",
      "Validation Loss: 6.0778\tTop 1 Validation Accuracy: 0.1633\t Top 5 Validation Accuracy: 0.3075\n",
      "loss 0.13230304121971131\n",
      "loss 0.26501425489783287\n",
      "loss 0.3984813253581524\n",
      "loss 0.5339898665994406\n",
      "loss 0.671653813123703\n",
      "loss 0.81098656617105\n",
      "loss 0.9522190083563328\n",
      "loss 1.0946770530194043\n",
      "loss 1.2408060999959707\n",
      "loss 1.3835710768401623\n",
      "loss 1.5289778378605843\n",
      "loss 1.6772952497750522\n",
      "loss 1.8265952050685883\n",
      "loss 1.975666402876377\n",
      "loss 2.128137923181057\n",
      "loss 2.2804346717894077\n",
      "loss 2.4349689696729184\n",
      "loss 2.589630327373743\n",
      "loss 2.7470169830322266\n",
      "loss 2.9051977257430552\n",
      "loss 3.0648980829119683\n",
      "loss 3.2259855914115905\n",
      "Epoch:  20\n",
      "training loss =  0.14675907837897004\n",
      "Validation Loss: 6.0441\tTop 1 Validation Accuracy: 0.1647\t Top 5 Validation Accuracy: 0.3115\n",
      "loss 0.12527347125113011\n",
      "loss 0.2504012640565634\n",
      "loss 0.373448444083333\n",
      "loss 0.4961245462298393\n",
      "loss 0.6188116657733918\n",
      "loss 0.7434910340607166\n",
      "loss 0.8666526791453362\n",
      "loss 0.9886662489175797\n",
      "loss 1.1124750500917435\n",
      "loss 1.2357890039682389\n",
      "loss 1.3593445276468992\n",
      "loss 1.4826737381517887\n",
      "loss 1.6059602975100278\n",
      "loss 1.72879966519773\n",
      "loss 1.852524551153183\n",
      "loss 1.9750352124869823\n",
      "loss 2.098132999241352\n",
      "loss 2.221246134713292\n",
      "loss 2.345407368540764\n",
      "loss 2.470204969868064\n",
      "loss 2.594959251880646\n",
      "loss 2.720105317533016\n",
      "Epoch:  21\n",
      "training loss =  0.12363139397578596\n",
      "Validation Loss: 6.0327\tTop 1 Validation Accuracy: 0.1660\t Top 5 Validation Accuracy: 0.3124\n",
      "loss 0.11894967786967754\n",
      "loss 0.24037571787834167\n",
      "loss 0.36409391663968566\n",
      "loss 0.4851991128921509\n",
      "loss 0.6089834635704756\n",
      "loss 0.730799770206213\n",
      "loss 0.8531067204475403\n",
      "loss 0.9732996937632561\n",
      "loss 1.095598812699318\n",
      "loss 1.2179023703187704\n",
      "loss 1.3396984053403138\n",
      "loss 1.461333960071206\n",
      "loss 1.58397453866899\n",
      "loss 1.7068768680095672\n",
      "loss 1.8301013584434986\n",
      "loss 1.9540002826601266\n",
      "loss 2.075897408127785\n",
      "loss 2.1969327691942455\n",
      "loss 2.3205727675557135\n",
      "loss 2.443982443213463\n",
      "loss 2.5672407221794127\n",
      "loss 2.690216150060296\n",
      "Epoch:  22\n",
      "training loss =  0.12228951019255056\n",
      "Validation Loss: 6.0315\tTop 1 Validation Accuracy: 0.1661\t Top 5 Validation Accuracy: 0.3129\n",
      "loss 0.1188580796122551\n",
      "loss 0.24045199960470198\n",
      "loss 0.35963167242705824\n",
      "loss 0.48046020038425924\n",
      "loss 0.6005671514570713\n",
      "loss 0.7226759725809098\n",
      "loss 0.8429038267582655\n",
      "loss 0.9644615758210421\n",
      "loss 1.0838075172901154\n",
      "loss 1.2062232645601034\n",
      "loss 1.3279285871237516\n",
      "loss 1.4497404175251722\n",
      "loss 1.5731209061294793\n",
      "loss 1.696082989051938\n",
      "loss 1.8195895731449128\n",
      "loss 1.9414616968482732\n",
      "loss 2.0635304913669823\n",
      "loss 2.1860431961715223\n",
      "loss 2.3082745226472614\n",
      "loss 2.4308520784974097\n",
      "loss 2.5545155219733715\n",
      "loss 2.6782893036305904\n",
      "Epoch:  23\n",
      "training loss =  0.12174642764085489\n",
      "Validation Loss: 6.0324\tTop 1 Validation Accuracy: 0.1661\t Top 5 Validation Accuracy: 0.3126\n",
      "loss 0.1198808442056179\n",
      "loss 0.2383381597697735\n",
      "loss 0.3592187836766243\n",
      "loss 0.479656011685729\n",
      "loss 0.6002893020957708\n",
      "loss 0.7222428373247385\n",
      "loss 0.8442265257984399\n",
      "loss 0.9638098408281803\n",
      "loss 1.0838301320374013\n",
      "loss 1.204254816249013\n",
      "loss 1.3234668147563935\n",
      "loss 1.446013974249363\n",
      "loss 1.5670563969016076\n",
      "loss 1.6889180439710616\n",
      "loss 1.8110623341053724\n",
      "loss 1.931885872259736\n",
      "loss 2.053969462364912\n",
      "loss 2.1761382175982\n",
      "loss 2.2976966540515424\n",
      "loss 2.4199766653776167\n",
      "loss 2.5435297486931088\n",
      "loss 2.667935070171952\n",
      "Epoch:  24\n",
      "training loss =  0.12128957274885808\n",
      "Validation Loss: 6.0289\tTop 1 Validation Accuracy: 0.1663\t Top 5 Validation Accuracy: 0.3131\n",
      "loss 0.11940733820199967\n",
      "loss 0.23895651035010815\n",
      "loss 0.35842814691364766\n",
      "loss 0.4779009909927845\n",
      "loss 0.5977655076235533\n",
      "loss 0.7172519163787365\n",
      "loss 0.8379246737062931\n",
      "loss 0.9593351854383946\n",
      "loss 1.079411252439022\n",
      "loss 1.1993052299320697\n",
      "loss 1.3208990990370513\n",
      "loss 1.5629441966116429\n",
      "loss 1.682892350256443\n",
      "loss 1.8030792973935603\n",
      "loss 1.9251022528856994\n",
      "loss 2.0459327182173728\n",
      "loss 2.16722284168005\n",
      "loss 2.290502091422677\n",
      "loss 2.412782313376665\n",
      "loss 2.5357983511686326\n",
      "loss 2.659191024377942\n",
      "Epoch:  25\n",
      "training loss =  0.12088733924579599\n",
      "Validation Loss: 6.0287\tTop 1 Validation Accuracy: 0.1666\t Top 5 Validation Accuracy: 0.3131\n",
      "loss 0.11807468831539154\n",
      "loss 0.23838412925601005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.3580237223953009\n",
      "loss 0.4770677004754543\n",
      "loss 0.5960210333019496\n",
      "loss 0.7171022240817547\n",
      "loss 0.8383257056027651\n",
      "loss 0.9566338270902633\n",
      "loss 1.0759795651584865\n",
      "loss 1.196406601294875\n",
      "loss 1.316924124136567\n",
      "loss 1.4386785269528628\n",
      "loss 1.5590517237782477\n",
      "loss 1.6794287169724702\n",
      "loss 1.801115638539195\n",
      "loss 1.9226213017851115\n",
      "loss 2.043155759498477\n",
      "loss 2.1640663213282822\n",
      "loss 2.2861316736787556\n",
      "loss 2.4081365071982144\n",
      "loss 2.5285788635909556\n",
      "loss 2.650822877138853\n",
      "Epoch:  26\n",
      "training loss =  0.12051895491296438\n",
      "Validation Loss: 6.0310\tTop 1 Validation Accuracy: 0.1662\t Top 5 Validation Accuracy: 0.3128\n",
      "loss 0.11836088322103024\n",
      "loss 0.2368499570339918\n",
      "loss 0.35492916136980057\n",
      "loss 0.47366785421967506\n",
      "loss 0.5922138479351997\n",
      "loss 0.7110052414238452\n",
      "loss 0.8302869275957346\n",
      "loss 0.950721924751997\n",
      "loss 1.071143632233143\n",
      "loss 1.1908825252205133\n",
      "loss 1.3113579070568084\n",
      "loss 1.4316626039892435\n",
      "loss 1.5511043374985456\n",
      "loss 1.6723508287221194\n",
      "loss 1.7930876483768226\n",
      "loss 1.913799621462822\n",
      "loss 2.033992990702391\n",
      "loss 2.1559597922861578\n",
      "loss 2.400826414451003\n",
      "loss 2.5199780958890914\n",
      "loss 2.6431360482424497\n",
      "Epoch:  27\n",
      "training loss =  0.12016209277907293\n",
      "Validation Loss: 6.0263\tTop 1 Validation Accuracy: 0.1666\t Top 5 Validation Accuracy: 0.3132\n",
      "loss 0.11961273513734341\n",
      "loss 0.23780971251428126\n",
      "loss 0.35718417160212995\n",
      "loss 0.4758693061769009\n",
      "loss 0.595545070618391\n",
      "loss 0.7163318310678005\n",
      "loss 0.8351088428497314\n",
      "loss 0.9537386731058359\n",
      "loss 1.073896143361926\n",
      "loss 1.1929884058237077\n",
      "loss 1.3120310246944427\n",
      "loss 1.43051628254354\n",
      "loss 1.5514011524617672\n",
      "loss 1.6720990975946188\n",
      "loss 1.7921633680164815\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(modelname)\n",
    "\n",
    "train(model, train_dataloader, validation_dataloader, criterion, optimizer, lr_scheduler, modelpath, writer, device, epochs = num_Epochs)\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load saved model from checkpoint\n",
    "'''\n",
    "model, optimizer, lr_scheduler, train_loss, v_loss, v_acc, epoch = load(modelpath, model, optimizer, lr_scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6577\tTop 1 Validation Accuracy: 0.8654\n",
      "Accuracy:defaultdict(<class 'int'>, {'Top 1 Accuracy': 86.54392178672833, 'Top 5 Accuracy': 96.05128355238122, 'Top 10 Accuracy': 97.26604806369464, 'Top 20 Accuracy': 98.00954248748647, 'Top 30 Accuracy': 98.32860111816878, 'Top 50 Accuracy': 98.66814975265639, 'Top 100 Accuracy': 99.03404267775078})\t\n"
     ]
    }
   ],
   "source": [
    "v_loss, top1_acc, accuracy_dict= eval_classify(model, validation_dataloader, criterion, device)\n",
    "print('Validation Loss: {:.4f}\\tTop 1 Validation Accuracy: {:.4f}\\nAccuracy:{}\\t'.format(v_loss, top1_acc, accuracy_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
