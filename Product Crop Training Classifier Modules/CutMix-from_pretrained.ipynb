{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug  3 10:51:19 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 40%   56C    P2   232W / 280W |  10217MiB / 24220MiB |     80%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 67%   86C    P2   158W / 280W |  10174MiB / 24220MiB |     75%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 87%   87C    P2   157W / 280W |  10174MiB / 24220MiB |     75%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN RTX           Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 79%   86C    P2   226W / 280W |  10174MiB / 24220MiB |     77%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  TITAN RTX           Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 41%   24C    P8     2W / 280W |    990MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  TITAN RTX           Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 41%   24C    P8    15W / 280W |   1216MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  TITAN RTX           Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 41%   22C    P8     3W / 280W |     11MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  TITAN RTX           Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 41%   24C    P8    12W / 280W |     11MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     17730      C   .../anaconda3/envs/abhishek_env/bin/python   867MiB |\n",
      "|    0     44832      C   python                                      9335MiB |\n",
      "|    1     44832      C   python                                     10163MiB |\n",
      "|    2     44832      C   python                                     10163MiB |\n",
      "|    3     44832      C   python                                     10163MiB |\n",
      "|    4     17730      C   .../anaconda3/envs/abhishek_env/bin/python   975MiB |\n",
      "|    5     34005      C   python3                                     1203MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### IMPORTING NECESSARY MODULES #########\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import transforms, datasets, models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:4' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataloading Scheme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlist = 'new_classification_lists/new_classification_trainlist.txt'\n",
    "validlist ='new_classification_lists/new_classification_vallist.txt'\n",
    "# testlist = 'new_classification_lists/new_classification_testlist.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of Unique product Ids to Labels(0 to 31127 classes)\n",
    "# output = dictionary containing mapping of each upc to a label from (0 to 31127)  \n",
    "\n",
    "with open(trainlist, mode = 'r') as f:\n",
    "    \n",
    "    Y=[]\n",
    "    for line in f:\n",
    "        path, UPC = line[:-1].split(',')\n",
    "\n",
    "        Y.append(UPC)\n",
    "        \n",
    "upc_list = sorted(set(Y))\n",
    "\n",
    "upc_dict = { upc_list[i] :i for i in range(0, len(upc_list) ) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydataset():    \n",
    "\n",
    "    def __init__(self, classification_list, upc_dict, name):\n",
    "\n",
    "        super(mydataset).__init__()\n",
    "        \n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        \n",
    "        with open(classification_list, mode = 'r') as f:\n",
    "            \n",
    "            for line in f:\n",
    "                path, UPC = line[:-1].split(',')\n",
    "\n",
    "                self.X.append(path)\n",
    "                self.Y.append(upc_dict[UPC])\n",
    "        \n",
    "\n",
    "        if name == 'valid':\n",
    "            self.transform = transforms.Compose([   \n",
    "#                                                     transforms.Resize(256),\n",
    "#                                                     transforms.CenterCrop(224),\n",
    "                                                    transforms.RandomResizedCrop(224),\n",
    "                                                    transforms.ToTensor(),\n",
    "                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                    std=[0.229, 0.224, 0.225])\n",
    "                                                ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([   transforms.RandomResizedCrop(224),\n",
    "                                                transforms.RandomHorizontalFlip(),\n",
    "#                                                 transforms.RandomErasing(p=0.5)\n",
    "                                                transforms.ToTensor(),\n",
    "                                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                    std=[0.229, 0.224, 0.225])\n",
    "                                                                                            ])\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        image = self.X[index]        \n",
    "        label = float(self.Y[index])\n",
    "        \n",
    "        image = (Image.open(image))\n",
    "               \n",
    "        image = self.transform(image)\n",
    "        \n",
    "        return image, torch.as_tensor(label).long()\n",
    "        \n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Train Dataloader #### \n",
    "train_dataset = mydataset(trainlist, upc_dict, name='train')          \n",
    "train_dataloader = data.DataLoader(train_dataset, shuffle= True, batch_size = 128, num_workers=16,pin_memory=True)\n",
    "\n",
    "\n",
    "#### Validation Dataloader #### \n",
    "validation_dataset = mydataset(validlist, upc_dict, name='valid')         \n",
    "validation_dataloader = data.DataLoader(validation_dataset, shuffle=False, batch_size = 128, num_workers=16,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESNET Architecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "fc_inputs = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(fc_inputs, 31128)\n",
    "#     nn.ReLU(),\n",
    "#     nn.Dropout(0.4),\n",
    "#     nn.Linear(256, 10),\n",
    "#     nn.LogSoftmax(dim=1) # For using NLLLoss()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.DataParallel(model,device_ids=[4,5]).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, test_loader,beta, cutmix_prob, epochs):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        avg_loss = 0.0\n",
    "        \n",
    "        for batch_num, (feats, target) in enumerate(data_loader):\n",
    "            feats, target = feats.to(device), target.to(device)\n",
    "            \n",
    "            \n",
    "            r = np.random.rand(1)\n",
    "            if beta > 0 and r < cutmix_prob:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(beta, beta)\n",
    "                rand_index = torch.randperm(feats.size()[0]).to(device)\n",
    "                target_a = target\n",
    "                target_b = target[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(feats.size(), lam)\n",
    "                feats[:, :, bbx1:bbx2, bby1:bby2] = feats[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (feats.size()[-1] * feats.size()[-2]))\n",
    "                # compute output\n",
    "                output = model(feats)\n",
    "                loss = criterion(output, target_a) * lam + criterion(output, target_b) * (1. - lam)\n",
    "            else:\n",
    "                # compute output\n",
    "                output = model(feats)\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "\n",
    "                                  \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            avg_loss += loss.item()\n",
    "\n",
    "#             if batch_num % 200 == 199:\n",
    "#                 print('loss', avg_loss/200)\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            del feats\n",
    "            del target\n",
    "            del loss\n",
    "        \n",
    "        print('Epoch: ', epoch+49)\n",
    "\n",
    "        print('training loss = ', avg_loss/len(data_loader))\n",
    "        train_loss.append(avg_loss/len(data_loader))\n",
    "\n",
    "        ## Check performance on validation set after an Epoch\n",
    "        valid_loss, valid_acc = test_classify(model, test_loader)\n",
    "        print('Val Loss: {:.4f}\\tVal Accuracy: {:.4f}'.format(valid_loss, valid_acc))\n",
    "        v_loss.append(valid_loss)\n",
    "        v_acc.append(valid_acc)\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        #########save model checkpoint #########\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'Training_Loss_List':train_loss,\n",
    "            'Validation_Loss_List':v_loss,\n",
    "            'Validation_Accuracy_List': v_acc,\n",
    "            'Epoch':epoch\n",
    "            }, 'saved_model_checkpoints/cutmix_from_pretrained')\n",
    "\n",
    "\n",
    "def test_classify(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    accuracy = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_num, (feats, labels) in enumerate(test_loader):\n",
    "        feats, labels = feats.to(device), labels.to(device)\n",
    "        outputs = model(feats)\n",
    "        \n",
    "        _, pred_labels = torch.max(F.softmax(outputs, dim=1), 1)\n",
    "        pred_labels = pred_labels.view(-1)\n",
    "        \n",
    "        loss = criterion(outputs, labels.long())\n",
    "        \n",
    "        accuracy += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "        total += len(labels)\n",
    "        test_loss.extend([loss.item()]*feats.size()[0])\n",
    "        del feats\n",
    "        del labels\n",
    "\n",
    "    model.train()\n",
    "    return np.mean(test_loss), accuracy/total\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 30, gamma = 0.1)\n",
    "\n",
    "\n",
    "# Epochs\n",
    "num_Epochs = 25\n",
    "\n",
    "beta=1\n",
    "\n",
    "cutmix_prob = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss= []\n",
    "v_loss = []\n",
    "v_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train(model, train_dataloader, validation_dataloader, beta, cutmix_prob, epochs = num_Epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Load saved model from checkpoint  #########\n",
    "\n",
    "checkpoint = torch.load('saved_model_checkpoints/cutmix_from_pretrained')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "train_loss = checkpoint['Training_Loss_List'] \n",
    "v_loss = checkpoint['Validation_Loss_List']\n",
    "v_acc = checkpoint['Validation_Accuracy_List']\n",
    "epoch = checkpoint['Epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "x = np.arange(91,121)\n",
    "plt.plot(x, train_loss, label = 'Training Loss')\n",
    "plt.plot(x, v_loss, label = 'Validation Loss')\n",
    "plt.xlabel('Epochs', fontsize =16)\n",
    "plt.ylabel('Loss', fontsize =16)\n",
    "plt.title('Loss v/s Epochs',fontsize =16)\n",
    "plt.legend(fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s='Abc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.islower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1='Abc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1==s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
