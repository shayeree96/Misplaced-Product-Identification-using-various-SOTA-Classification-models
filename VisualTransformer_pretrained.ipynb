{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 28 19:21:22 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 41%   39C    P2    68W / 280W |   2754MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 41%   51C    P8    25W / 280W |     11MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 67%   83C    P2   115W / 280W |   4210MiB / 24220MiB |     55%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN RTX           Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 66%   80C    P2   106W / 280W |   3620MiB / 24220MiB |     75%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  TITAN RTX           Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 95%   86C    P2   103W / 280W |  19411MiB / 24220MiB |     96%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  TITAN RTX           Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 99%   87C    P2   146W / 280W |  18941MiB / 24220MiB |     99%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  TITAN RTX           Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 56%   74C    P2   114W / 280W |  19447MiB / 24220MiB |     93%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  TITAN RTX           Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 97%   86C    P2   121W / 280W |  22685MiB / 24220MiB |     83%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     19182      C   .../anaconda3/envs/shayeree_env/bin/python   859MiB |\n",
      "|    0     22975      C   .../anaconda3/envs/shayeree_env/bin/python   859MiB |\n",
      "|    0     36480      C   .../anaconda3/envs/abhishek_env/bin/python   965MiB |\n",
      "|    2     19182      C   .../anaconda3/envs/shayeree_env/bin/python  6139MiB |\n",
      "|    3     22975      C   .../anaconda3/envs/shayeree_env/bin/python  3667MiB |\n",
      "|    4     22975      C   .../anaconda3/envs/shayeree_env/bin/python   871MiB |\n",
      "|    4     36480      C   .../anaconda3/envs/abhishek_env/bin/python 18475MiB |\n",
      "|    5     22975      C   .../anaconda3/envs/shayeree_env/bin/python  2007MiB |\n",
      "|    5     36480      C   .../anaconda3/envs/abhishek_env/bin/python 16869MiB |\n",
      "|    6     36480      C   .../anaconda3/envs/abhishek_env/bin/python 16869MiB |\n",
      "|    7     22975      C   .../anaconda3/envs/shayeree_env/bin/python  5751MiB |\n",
      "|    7     36480      C   .../anaconda3/envs/abhishek_env/bin/python 16869MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### IMPORTING NECESSARY MODULES #########\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.append('/home/ironman/abhishek/AliProducts/architectures/pytorch-image-models/timm/models/')\n",
    "sys.path.append('/home/ironman/abhishek/AliProducts/architectures/pytorch-image-models/')\n",
    "sys.path.append('/home/ironman/abhishek/AliProducts/Helper/')\n",
    "\n",
    "from dataloader import mydataset, create_prime_dict \n",
    "from trainer_ViT import train, test_classify, eval_classify\n",
    "from Load_model import load\n",
    "\n",
    "\n",
    "\n",
    "from vision_transformer import vit_base_patch32_384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataloading Scheme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlist = '/home/ironman/abhishek/AliProducts/Newlist/NEW_train_list1.txt'\n",
    "validlist = '/home/ironman/abhishek/AliProducts/Newlist/NEW_valid_list1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes =  50030\n"
     ]
    }
   ],
   "source": [
    "prime_dict = create_prime_dict(trainlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train Dataloader #### \n",
    "train_dataset = mydataset(trainlist, prime_dict, name='train')          \n",
    "train_dataloader = data.DataLoader(train_dataset, shuffle= True, batch_size = 256, num_workers=16,pin_memory=True)\n",
    "\n",
    "\n",
    "#### Validation Dataloader #### \n",
    "validation_dataset = mydataset(validlist, prime_dict, name='valid')         \n",
    "validation_dataloader = data.DataLoader(validation_dataset, shuffle=False, batch_size = 64, num_workers=16,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vit_base_patch32_384(pretrained=True)\n",
    "\n",
    "\n",
    "model = nn.DataParallel(model,device_ids=[2,3]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=1000, bias=True)\n",
       "      (1): GELU()\n",
       "      (2): Linear(in_features=1000, out_features=50030, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Transfer Learning\n",
    "'''\n",
    "\n",
    "# for param in model.module.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "fc_inputs = model.module.head.in_features\n",
    "\n",
    "model.module.head = nn.Sequential(\n",
    "    nn.Linear(fc_inputs, 1000),\n",
    "#     nn.BatchNorm1d(4096),\n",
    "    nn.GELU(),\n",
    "    nn.Linear(1000, 50030)\n",
    "    \n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, weight_decay=1e-4, momentum=0.9)\n",
    "\n",
    "\n",
    "# Epochs\n",
    "num_Epochs = 30\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 10, gamma = 0.1)\n",
    "\n",
    "#Cutmix\n",
    "# beta = 1\n",
    "# cutmix_prob = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'ViT_pretrained_vit_base_patch32_384_mlpadded'\n",
    "modelpath = '/home/ironman/abhishek/saved_model_checkpoints/AliProducts/' + modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 10.82594822883606\n",
      "loss 21.63555132865906\n",
      "loss 32.40773811340332\n",
      "loss 43.06737935066223\n",
      "loss 53.53862006187439\n",
      "loss 63.73400384902954\n",
      "loss 73.58893639564513\n",
      "loss 83.05676627159119\n",
      "loss 92.13545754432678\n",
      "loss 100.79769291877747\n",
      "loss 108.99147634506225\n",
      "loss 116.72287644386292\n",
      "loss 124.00898491382598\n",
      "loss 130.83184237480162\n",
      "loss 137.24160254478454\n",
      "loss 143.31865582942962\n",
      "loss 149.03403333187103\n",
      "loss 154.37838282108308\n",
      "loss 159.43289021015167\n",
      "loss 164.2814518022537\n",
      "loss 168.79427546977996\n",
      "loss 173.2109024143219\n",
      "loss 177.3862962436676\n",
      "loss 181.48733843803404\n",
      "loss 185.34483425855638\n",
      "loss 189.1539590716362\n",
      "loss 192.84520596265793\n",
      "loss 196.45930205106734\n",
      "loss 199.97080763816834\n",
      "loss 203.39186331033707\n",
      "loss 206.73034244298935\n",
      "loss 210.056429977417\n",
      "loss 213.32372375249864\n",
      "loss 216.51953795671463\n",
      "loss 219.65635427236558\n",
      "loss 222.75146915435792\n",
      "loss 225.77938162326814\n",
      "loss 228.7580301785469\n",
      "loss 231.67602324962616\n",
      "loss 234.5677730154991\n",
      "loss 237.42340968370436\n",
      "loss 240.2565420269966\n",
      "loss 243.07776460886\n",
      "loss 245.84817247867585\n",
      "Epoch:  1\n",
      "training loss =  5.557586899226184\n",
      "Validation Loss: 2.1681\tTop 1 Validation Accuracy: 0.5868\t Top 5 Validation Accuracy: 0.8117\n",
      "loss 2.165036504268646\n",
      "loss 4.280793875455856\n",
      "loss 6.384414236545563\n",
      "loss 8.54044240474701\n",
      "loss 10.675184128284455\n",
      "loss 12.779959818124771\n",
      "loss 14.91764976143837\n",
      "loss 17.019878319501878\n",
      "loss 19.170092914104462\n",
      "loss 21.301178970336913\n",
      "loss 23.4533367228508\n",
      "loss 25.569068117141725\n",
      "loss 27.73820314049721\n",
      "loss 29.88457138299942\n",
      "loss 32.03658844470978\n",
      "loss 34.15491120815277\n",
      "loss 36.26963887214661\n",
      "loss 38.452502321004864\n",
      "loss 40.58156605362892\n",
      "loss 42.73683349728584\n",
      "loss 44.88973948121071\n",
      "loss 47.046975818872454\n",
      "loss 49.168744238615034\n",
      "loss 51.33367619752884\n",
      "loss 53.479478443861005\n",
      "loss 55.64376310586929\n",
      "loss 57.79046836972237\n",
      "loss 59.88321278214455\n",
      "loss 61.99109206199646\n",
      "loss 64.16759019613266\n",
      "loss 66.29928822278977\n",
      "loss 68.42192729473113\n",
      "loss 70.56214653730393\n",
      "loss 72.68027089118958\n",
      "loss 74.78750133991241\n",
      "loss 76.90497427940369\n",
      "loss 79.01060555815697\n",
      "loss 81.11389409303665\n",
      "loss 83.26594607114792\n",
      "loss 85.38496524095535\n",
      "loss 87.49641673445701\n",
      "loss 89.60306755423545\n",
      "loss 91.70904483318328\n",
      "loss 93.84278993964195\n",
      "Epoch:  2\n",
      "training loss =  2.1328380739981068\n",
      "Validation Loss: 1.8563\tTop 1 Validation Accuracy: 0.6451\t Top 5 Validation Accuracy: 0.8587\n",
      "loss 1.4525954163074493\n",
      "loss 2.8815465426445006\n",
      "loss 4.286074925661087\n",
      "loss 5.718887514472008\n",
      "loss 7.166335456967354\n",
      "loss 8.644696262478828\n",
      "loss 10.126463515162468\n",
      "loss 11.63049594938755\n",
      "loss 13.155425797104835\n",
      "loss 14.693569945693016\n",
      "loss 16.225596711039543\n",
      "loss 17.778165565133094\n",
      "loss 19.328481976389885\n",
      "loss 20.910843438506127\n",
      "loss 22.506374828219414\n",
      "loss 24.128673146367074\n",
      "loss 25.754262591004373\n",
      "loss 27.38725469172001\n",
      "loss 29.02377103507519\n",
      "loss 30.681448145508767\n",
      "loss 32.34643559753895\n",
      "loss 34.04793065011501\n",
      "loss 35.70901815831661\n",
      "loss 37.42633948147297\n",
      "loss 39.17532893240452\n",
      "loss 40.88711666882038\n",
      "loss 42.58986515581608\n",
      "loss 44.31414084851742\n",
      "loss 46.04869731485844\n",
      "loss 47.806020879149436\n",
      "loss 49.53311991989612\n",
      "loss 51.29483575880528\n",
      "loss 53.08642300665379\n",
      "loss 54.84259639799595\n",
      "loss 56.66292883694172\n",
      "loss 58.44504619777203\n",
      "loss 60.244445789456364\n",
      "loss 62.05614259421825\n",
      "loss 63.840385997891424\n",
      "loss 65.65031117022038\n",
      "loss 67.46079792678356\n",
      "loss 69.29081886589528\n",
      "loss 71.12155453622341\n",
      "loss 72.97897190988064\n",
      "Epoch:  3\n",
      "training loss =  1.660934294706949\n",
      "Validation Loss: 1.8405\tTop 1 Validation Accuracy: 0.6546\t Top 5 Validation Accuracy: 0.8581\n",
      "loss 2.290829159617424\n",
      "loss 3.472584438323975\n",
      "loss 4.659660390615463\n",
      "loss 5.864673928022385\n",
      "loss 7.066813727021217\n",
      "loss 8.325830176472664\n",
      "loss 9.561213274598122\n",
      "loss 10.811923763155937\n",
      "loss 12.102433428764343\n",
      "loss 13.39857403755188\n",
      "loss 14.70871611714363\n",
      "loss 16.062290452718734\n",
      "loss 17.432205897569656\n",
      "loss 18.844189369678496\n",
      "loss 20.211898815631866\n",
      "loss 21.633987340927124\n",
      "loss 23.04384305357933\n",
      "loss 24.490685378313064\n",
      "loss 25.95653601050377\n",
      "loss 27.426238924264908\n",
      "loss 28.88678099513054\n",
      "loss 30.381291974782943\n",
      "loss 31.864461731910705\n",
      "loss 33.390039203166964\n",
      "loss 34.900818353891374\n",
      "loss 36.43391746520996\n",
      "loss 38.00556405186653\n",
      "loss 39.57509368896484\n",
      "loss 41.14600476026535\n",
      "loss 42.73849635243416\n",
      "loss 44.34702949285507\n",
      "loss 45.940897783041\n",
      "loss 47.540524479150776\n",
      "loss 49.17831998467445\n",
      "loss 50.816643928289416\n",
      "loss 52.47485846042633\n",
      "loss 54.144548351764676\n",
      "loss 55.81733976721764\n",
      "loss 57.46748049259186\n",
      "loss 59.137766392230986\n",
      "loss 60.85054894685745\n",
      "loss 62.562269399166105\n",
      "loss 64.25467186450959\n",
      "Epoch:  4\n",
      "training loss =  1.4630142192720483\n",
      "Validation Loss: 1.9877\tTop 1 Validation Accuracy: 0.6324\t Top 5 Validation Accuracy: 0.8377\n",
      "loss 1.0199109745025634\n",
      "loss 1.9974753934144973\n",
      "loss 3.0205185914039614\n",
      "loss 4.040422619581222\n",
      "loss 5.081180482506752\n",
      "loss 6.144386677742005\n",
      "loss 7.205572896003723\n",
      "loss 8.318935707211494\n",
      "loss 9.459458441734315\n",
      "loss 10.611576462984084\n",
      "loss 11.808479908108712\n",
      "loss 13.004575253129005\n",
      "loss 14.209892646074294\n",
      "loss 15.441601583361626\n",
      "loss 16.70441985845566\n",
      "loss 17.993570405244828\n",
      "loss 19.276995327472687\n",
      "loss 20.587842955589295\n",
      "loss 21.939411593675615\n",
      "loss 23.296979324817656\n",
      "loss 24.66769896388054\n",
      "loss 26.017923357486726\n",
      "loss 27.384864002466202\n",
      "loss 28.778555946350096\n",
      "loss 30.200188554525376\n",
      "loss 31.604369430541993\n",
      "loss 33.031886894702915\n",
      "loss 34.474232079982755\n",
      "loss 35.966936110258104\n",
      "loss 37.48288345098496\n",
      "loss 38.97597678184509\n",
      "loss 40.47065823674202\n",
      "loss 41.95661337971687\n",
      "loss 43.46853834033013\n",
      "loss 44.996973044872284\n",
      "loss 46.531749436855314\n",
      "loss 48.10069249153137\n",
      "loss 49.67025190591812\n",
      "loss 51.24795984864235\n",
      "loss 52.824920986890795\n",
      "loss 54.395989005565646\n",
      "loss 56.03133901834488\n",
      "loss 57.661983547210696\n",
      "loss 59.26488444566726\n",
      "Epoch:  5\n",
      "training loss =  1.3497028907068611\n",
      "Validation Loss: 2.1638\tTop 1 Validation Accuracy: 0.6084\t Top 5 Validation Accuracy: 0.8121\n",
      "loss 0.9407122814655304\n",
      "loss 1.8377024388313294\n",
      "loss 2.7619196689128875\n",
      "loss 3.669267365336418\n",
      "loss 4.634217909574509\n",
      "loss 5.596763420701027\n",
      "loss 6.613015143275261\n",
      "loss 7.6317281150817875\n",
      "loss 8.673240155577659\n",
      "loss 9.72287113904953\n",
      "loss 10.809433035254479\n",
      "loss 11.90717321574688\n",
      "loss 13.03219275534153\n",
      "loss 14.180308972597123\n",
      "loss 15.3247004789114\n",
      "loss 16.512008063197136\n",
      "loss 17.71897821724415\n",
      "loss 18.91745654463768\n",
      "loss 20.15230563104153\n",
      "loss 21.372126923799513\n",
      "loss 22.658556500673296\n",
      "loss 23.96496986031532\n",
      "loss 25.263702632188796\n",
      "loss 26.58848707795143\n",
      "loss 27.914037938117982\n",
      "loss 29.25426219344139\n",
      "loss 30.6274766433239\n",
      "loss 31.99168351531029\n",
      "loss 33.35795602440834\n",
      "loss 34.7496436548233\n",
      "loss 36.1427341067791\n",
      "loss 37.55378256440163\n",
      "loss 39.01495259165764\n",
      "loss 40.47026314496994\n",
      "loss 41.9502294588089\n",
      "loss 43.412864310741426\n",
      "loss 44.90412955880165\n",
      "loss 46.412178900241855\n",
      "loss 47.93646995663643\n",
      "loss 49.44513011217117\n",
      "loss 50.95103145122528\n",
      "loss 52.476179566383365\n",
      "loss 54.01758482456207\n",
      "loss 55.569828209877016\n",
      "Epoch:  6\n",
      "training loss =  1.2656847737010795\n",
      "Validation Loss: 2.1457\tTop 1 Validation Accuracy: 0.6114\t Top 5 Validation Accuracy: 0.8137\n",
      "loss 0.857678856253624\n",
      "loss 1.6836280232667924\n",
      "loss 2.52269902408123\n",
      "loss 3.3574436283111573\n",
      "loss 4.206593744754791\n",
      "loss 5.071088790893555\n",
      "loss 5.988968915343285\n",
      "loss 6.912986851930619\n",
      "loss 7.881143065094948\n",
      "loss 8.82058623969555\n",
      "loss 9.83114198744297\n",
      "loss 10.855013474225998\n",
      "loss 11.876800463199615\n",
      "loss 12.939556430578232\n",
      "loss 14.020034262537957\n",
      "loss 15.099252890348435\n",
      "loss 16.226998195648193\n",
      "loss 17.355079323649406\n",
      "loss 18.490481951236724\n",
      "loss 19.674338898062707\n",
      "loss 20.866110883951187\n",
      "loss 22.06303535759449\n",
      "loss 23.296298233270644\n",
      "loss 24.531869785785673\n",
      "loss 25.805680437088014\n",
      "loss 27.070583403110504\n",
      "loss 28.359984030127524\n",
      "loss 29.66632673561573\n",
      "loss 31.002092027068137\n",
      "loss 32.33396860539913\n",
      "loss 33.68010724008084\n",
      "loss 35.04314712762832\n",
      "loss 36.409500453472134\n",
      "loss 37.78935204803943\n",
      "loss 39.173742346167565\n",
      "loss 40.57944062292576\n",
      "loss 42.015396025776866\n",
      "loss 43.44262067377567\n",
      "loss 44.86608819901943\n",
      "loss 46.307823013663295\n",
      "loss 47.76582004249096\n",
      "loss 49.255640217661856\n",
      "loss 50.799437628388404\n",
      "loss 52.28776208102703\n",
      "Epoch:  7\n",
      "training loss =  1.1915355363346791\n",
      "Validation Loss: 2.2543\tTop 1 Validation Accuracy: 0.5974\t Top 5 Validation Accuracy: 0.8010\n",
      "loss 0.8414000517129898\n",
      "loss 1.6243084108829497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.4164986884593964\n",
      "loss 3.2217390370368957\n",
      "loss 4.034864583015442\n",
      "loss 4.88416322350502\n",
      "loss 5.73066682100296\n",
      "loss 6.611034525036811\n",
      "loss 7.513768311142922\n",
      "loss 8.44815440773964\n",
      "loss 9.371645398736\n",
      "loss 10.329968422651291\n",
      "loss 11.315584715008736\n",
      "loss 12.299922425150871\n",
      "loss 13.32246769964695\n",
      "loss 14.37076464176178\n",
      "loss 15.414580703377723\n",
      "loss 16.504852572083472\n",
      "loss 17.57747867822647\n",
      "loss 18.655234323143958\n",
      "loss 19.774667590856552\n",
      "loss 20.929778911471367\n",
      "loss 22.08407855987549\n",
      "loss 23.24386607706547\n",
      "loss 24.452331691384316\n",
      "loss 25.64300217926502\n",
      "loss 26.882636727690695\n",
      "loss 28.13981659770012\n",
      "loss 29.41103259563446\n",
      "loss 30.668233798742293\n",
      "loss 31.940993430018423\n",
      "loss 33.23389583587647\n",
      "loss 34.554469304084776\n",
      "loss 35.8578355884552\n",
      "loss 37.17195714771748\n",
      "loss 38.54716098189354\n",
      "loss 39.8916356754303\n",
      "loss 41.28657398700714\n",
      "loss 42.70878590643406\n",
      "loss 44.11100720107555\n",
      "loss 45.530630254149436\n",
      "loss 46.94285540759564\n",
      "loss 48.36171020925045\n",
      "loss 49.795534334778786\n",
      "Epoch:  8\n",
      "training loss =  1.135033039489649\n",
      "Validation Loss: 2.5495\tTop 1 Validation Accuracy: 0.5621\t Top 5 Validation Accuracy: 0.7645\n",
      "loss 0.8076011407375335\n",
      "loss 1.5540652948617935\n",
      "loss 2.302308241724968\n",
      "loss 3.0612568360567094\n",
      "loss 3.8351831030845642\n",
      "loss 4.6299942964315415\n",
      "loss 5.454711263179779\n",
      "loss 6.254167147278785\n",
      "loss 7.086658980250359\n",
      "loss 7.916775705814362\n",
      "loss 8.805336598157883\n",
      "loss 9.696601709127426\n",
      "loss 10.606795852184296\n",
      "loss 11.541709810495377\n",
      "loss 12.521938859820366\n",
      "loss 13.48316200554371\n",
      "loss 14.476196336150169\n",
      "loss 15.4885548889637\n",
      "loss 16.531077305674554\n",
      "loss 17.55937010169029\n",
      "loss 18.643942044377326\n",
      "loss 19.714852902889252\n",
      "loss 20.805651054382324\n",
      "loss 21.92187963426113\n",
      "loss 23.04761692583561\n",
      "loss 24.176929721832277\n",
      "loss 25.345979267954828\n",
      "loss 26.54124688863754\n",
      "loss 27.729444851875304\n",
      "loss 28.971854882836343\n",
      "loss 30.2149692350626\n",
      "loss 31.469513934254646\n",
      "loss 32.73735163152218\n",
      "loss 34.00496279895306\n",
      "loss 35.30509932398796\n",
      "loss 36.631374601125714\n",
      "loss 37.94806646108627\n",
      "loss 39.283505454063416\n",
      "loss 40.611797996759414\n",
      "loss 41.969315989613534\n",
      "loss 43.33360075771809\n",
      "loss 44.70295890033245\n",
      "loss 46.07828212320805\n",
      "loss 47.48890492379665\n",
      "Epoch:  9\n",
      "training loss =  1.0831815416233337\n",
      "Validation Loss: 2.4760\tTop 1 Validation Accuracy: 0.5732\t Top 5 Validation Accuracy: 0.7734\n",
      "loss 0.7512412852048874\n",
      "loss 1.4669178423285485\n",
      "loss 2.185865244269371\n",
      "loss 2.910492914021015\n",
      "loss 3.6356527745723723\n",
      "loss 4.3869173467159275\n",
      "loss 5.145570701956749\n",
      "loss 5.93846598148346\n",
      "loss 6.7302055522799495\n",
      "loss 7.5396277138590815\n",
      "loss 8.370829497873784\n",
      "loss 9.223087503015995\n",
      "loss 10.086407772004604\n",
      "loss 10.965705440938473\n",
      "loss 11.873801738917827\n",
      "loss 12.799514495432376\n",
      "loss 13.748677134811878\n",
      "loss 14.718663285076618\n",
      "loss 15.714803203642369\n",
      "loss 16.71989327818155\n",
      "loss 17.73876680880785\n",
      "loss 18.759756883084773\n",
      "loss 19.833938884437085\n",
      "loss 20.92247920781374\n",
      "loss 22.067459520995616\n",
      "loss 23.16981667011976\n",
      "loss 24.30198006182909\n",
      "loss 25.456191878020764\n",
      "loss 26.61590384989977\n",
      "loss 27.794861427247525\n",
      "loss 28.998068968951703\n",
      "loss 30.194467177093028\n",
      "loss 31.400264843404294\n",
      "loss 32.657936833798885\n",
      "loss 33.902386185824874\n",
      "loss 35.156996530592444\n",
      "loss 36.40793442994356\n",
      "loss 37.691949918568135\n",
      "loss 38.999285636246206\n",
      "loss 40.33052531272173\n",
      "loss 41.64378965884447\n",
      "loss 42.97906405776739\n",
      "loss 44.31726036041975\n",
      "loss 45.65895632594824\n",
      "Epoch:  10\n",
      "training loss =  1.0413738245813398\n",
      "Validation Loss: 2.5158\tTop 1 Validation Accuracy: 0.5717\t Top 5 Validation Accuracy: 0.7696\n",
      "loss 0.5915053334832191\n",
      "loss 1.105748272240162\n",
      "loss 1.5608323657512664\n",
      "loss 1.9830134281516074\n",
      "loss 2.37251215711236\n",
      "loss 2.748488119840622\n",
      "loss 3.096340073645115\n",
      "loss 3.4446734166145325\n",
      "loss 3.7713212350010874\n",
      "loss 4.080695947557688\n",
      "loss 4.380589632987976\n",
      "loss 4.668218294531107\n",
      "loss 4.943193310052156\n",
      "loss 5.222421527355909\n",
      "loss 5.481894392818212\n",
      "loss 5.7454211948812\n",
      "loss 6.007894191890955\n",
      "loss 6.249037316441536\n",
      "loss 6.498614218235016\n",
      "loss 6.736528307199478\n",
      "loss 6.977743517905473\n",
      "loss 7.2097790295630695\n",
      "loss 7.433654966205358\n",
      "loss 7.669262074902654\n",
      "loss 7.877906939312815\n",
      "loss 8.094378319829703\n",
      "loss 8.306429169028997\n",
      "loss 8.514998688846827\n",
      "loss 8.719886860400438\n",
      "loss 8.927697913125158\n",
      "loss 9.132832276374101\n",
      "loss 9.333398162797094\n",
      "loss 9.53858105570078\n",
      "loss 9.735476567670704\n",
      "loss 9.935917309224605\n",
      "loss 10.135979225412012\n",
      "loss 10.329686444625258\n",
      "loss 10.523943447843195\n",
      "loss 10.71419484630227\n",
      "loss 10.904219358712435\n",
      "loss 11.098197562992572\n",
      "loss 11.285944219604135\n",
      "loss 11.482767285183073\n",
      "loss 11.663427828997374\n",
      "Validation Loss: 1.6901\tTop 1 Validation Accuracy: 0.6864\t Top 5 Validation Accuracy: 0.8615\n",
      "loss 0.10259082663804292\n",
      "loss 0.20557036589831112\n",
      "loss 0.30630172688513996\n",
      "loss 0.4128185448423028\n",
      "loss 0.5184412625059486\n",
      "loss 0.6257178140804172\n",
      "loss 0.7343277318403125\n",
      "loss 0.8401864992827177\n",
      "loss 0.9449635385721922\n",
      "loss 1.0499365579336881\n",
      "loss 1.1543371918424965\n",
      "loss 1.2604879806563258\n",
      "loss 1.3625297793373465\n",
      "loss 1.4681888907030225\n",
      "loss 1.572017413750291\n",
      "loss 1.6791323570162058\n",
      "loss 1.7854428312927484\n",
      "loss 1.890920448973775\n",
      "loss 1.997529877088964\n",
      "loss 2.103799668438733\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(modelname)\n",
    "\n",
    "train(model, train_dataloader, validation_dataloader, criterion, optimizer, lr_scheduler, modelpath, writer, device, epochs = num_Epochs)\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load saved model from checkpoint\n",
    "'''\n",
    "model, optimizer, lr_scheduler, train_loss, v_loss, v_acc, epoch = load(modelpath, model, optimizer, lr_scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6577\tTop 1 Validation Accuracy: 0.8654\n",
      "Accuracy:defaultdict(<class 'int'>, {'Top 1 Accuracy': 86.54392178672833, 'Top 5 Accuracy': 96.05128355238122, 'Top 10 Accuracy': 97.26604806369464, 'Top 20 Accuracy': 98.00954248748647, 'Top 30 Accuracy': 98.32860111816878, 'Top 50 Accuracy': 98.66814975265639, 'Top 100 Accuracy': 99.03404267775078})\t\n"
     ]
    }
   ],
   "source": [
    "v_loss, top1_acc, accuracy_dict= eval_classify(model, validation_dataloader, criterion, device)\n",
    "print('Validation Loss: {:.4f}\\tTop 1 Validation Accuracy: {:.4f}\\nAccuracy:{}\\t'.format(v_loss, top1_acc, accuracy_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
