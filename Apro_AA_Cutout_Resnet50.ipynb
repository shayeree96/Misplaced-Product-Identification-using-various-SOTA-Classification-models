{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov  3 12:11:08 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 41%   35C    P2    67W / 280W |  11688MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 41%   34C    P8    22W / 280W |  16954MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 41%   34C    P8    27W / 280W |  11930MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN RTX           Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 41%   27C    P8     4W / 280W |  11930MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  TITAN RTX           Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 41%   26C    P8     2W / 280W |     11MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  TITAN RTX           Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 41%   26C    P8    15W / 280W |     11MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  TITAN RTX           Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 40%   24C    P8     5W / 280W |   2526MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  TITAN RTX           Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 41%   26C    P8    13W / 280W |     11MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     45374      C   .../anaconda3/envs/shayeree_env/bin/python 11673MiB |\n",
      "|    1     42000      C   .../anaconda3/envs/shayeree_env/bin/python  2509MiB |\n",
      "|    1     43749      C   .../anaconda3/envs/shayeree_env/bin/python  2513MiB |\n",
      "|    1     45374      C   .../anaconda3/envs/shayeree_env/bin/python 11919MiB |\n",
      "|    2     45374      C   .../anaconda3/envs/shayeree_env/bin/python 11919MiB |\n",
      "|    3     45374      C   .../anaconda3/envs/shayeree_env/bin/python 11919MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### IMPORTING NECESSARY MODULES #########\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "sys.path.append('/home/sreena/abhishek/AliProducts/architectures/')\n",
    "sys.path.append('/home/sreena/abhishek/AliProducts/Helper/')\n",
    "from dataloader import mydataset, create_prime_dict \n",
    "from trainer import train, test_classify, eval_classify\n",
    "from resnet_models import ResNet,Bottleneck\n",
    "from Load_model import load\n",
    "from plot_curves import plot_loss, plot_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataloading Scheme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlist = '/home/sreena/abhishek/AliProducts/lists/balanced_training_list.txt'\n",
    "validlist = '/home/sreena/abhishek/AliProducts/lists/balanced_validation_list.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes =  43043\n"
     ]
    }
   ],
   "source": [
    "prime_dict = create_prime_dict(trainlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train Dataloader #### \n",
    "train_dataset = mydataset(trainlist, prime_dict, name='train')          \n",
    "train_dataloader = data.DataLoader(train_dataset, shuffle= True, batch_size = 256, num_workers=16,pin_memory=True)\n",
    "\n",
    "\n",
    "#### Validation Dataloader #### \n",
    "validation_dataset = mydataset(validlist, prime_dict, name='valid')         \n",
    "validation_dataloader = data.DataLoader(validation_dataset, shuffle=False, batch_size = 128, num_workers=16,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (batchnorm): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc): Linear(in_features=2048, out_features=43043, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(Bottleneck, [3, 4, 6, 3], num_classes = 43043)\n",
    "\n",
    "model = nn.DataParallel(model,device_ids=[0,1,2,3]).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4, momentum=0.9)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 30, gamma = 0.1)\n",
    "\n",
    "# Epochs\n",
    "num_Epochs = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = '../saved_model_checkpoints/AliProducts/Apro_AA_Cutout_R50_copy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 11.596273498535156\n",
      "loss 22.748490953445433\n",
      "loss 33.7499858379364\n",
      "loss 44.63201066017151\n",
      "loss 55.399776000976566\n",
      "loss 66.09168650627136\n",
      "loss 76.71288962364197\n",
      "loss 87.26547222137451\n",
      "loss 97.75624344825745\n",
      "loss 108.18809692382813\n",
      "loss 118.54619094848633\n",
      "loss 128.87068860054015\n",
      "loss 139.1414221763611\n",
      "loss 149.36863698005675\n",
      "loss 159.5479545688629\n",
      "loss 169.70107124328612\n",
      "loss 179.8088912677765\n",
      "loss 189.88139450073243\n",
      "loss 199.91470337867736\n",
      "loss 209.90465364456176\n",
      "loss 219.83775647163392\n",
      "loss 229.75090594291686\n",
      "loss 239.622932510376\n",
      "loss 249.44084263801574\n",
      "loss 259.21742690086364\n",
      "loss 268.9465227794647\n",
      "loss 278.62980268478395\n",
      "loss 288.2564816665649\n",
      "loss 297.8421774673462\n",
      "loss 307.37411750793456\n",
      "loss 316.83872997283936\n",
      "loss 326.2721576786041\n",
      "loss 335.63843397140505\n",
      "loss 344.90771324157714\n",
      "loss 354.11675723075865\n",
      "loss 363.259090719223\n",
      "loss 372.31930208206177\n",
      "Epoch:  1\n",
      "training loss =  10.060732050922189\n",
      "loss 8.81529706954956\n",
      "loss 17.559094381332397\n",
      "loss 26.270381355285643\n",
      "loss 34.891597509384155\n",
      "loss 43.45264814376831\n",
      "loss 51.91870593070984\n",
      "loss 60.30023065567016\n",
      "loss 68.61249156951904\n",
      "loss 76.81204669475555\n",
      "loss 84.93227326393128\n",
      "loss 92.96014530181884\n",
      "loss 100.88882314682007\n",
      "loss 108.72726781845093\n",
      "loss 116.46059850215912\n",
      "loss 124.08937982082367\n",
      "loss 131.61189831733702\n",
      "loss 139.01492375850677\n",
      "loss 146.29939068317412\n",
      "loss 153.50298128604888\n",
      "loss 160.61979751110076\n",
      "loss 167.62626854419707\n",
      "loss 174.5678005027771\n",
      "loss 201.11288303375244\n",
      "loss 207.48121633529664\n",
      "loss 213.74726058483122\n",
      "loss 219.9560200691223\n",
      "loss 226.03001064300537\n",
      "loss 232.02924696445464\n",
      "loss 237.98665691375732\n",
      "loss 243.7319579410553\n",
      "loss 249.48836965560912\n",
      "loss 255.0938937520981\n",
      "loss 260.69000658035276\n",
      "loss 266.17183933734896\n",
      "Epoch:  2\n",
      "training loss =  7.190709832481917\n",
      "loss 4.820855555534362\n",
      "loss 9.68295033454895\n",
      "loss 14.505347847938538\n",
      "loss 19.286373138427734\n",
      "loss 23.99978663921356\n",
      "loss 28.698088068962097\n",
      "loss 33.341256322860715\n",
      "loss 37.959176483154295\n",
      "loss 42.60761137008667\n",
      "loss 47.12491648197174\n",
      "loss 51.635799996852874\n",
      "loss 56.13187474489212\n",
      "loss 60.59631161689758\n",
      "loss 64.99892797708512\n",
      "loss 69.37190535545349\n",
      "loss 73.70950593471527\n",
      "loss 78.00388463497161\n",
      "loss 82.3196711564064\n",
      "loss 86.56982631206512\n",
      "loss 90.80988011837006\n",
      "loss 95.02310030937196\n",
      "loss 99.18094894647598\n",
      "loss 103.31985501289368\n",
      "loss 107.37691107988357\n",
      "loss 111.48931814193726\n",
      "loss 115.58945897340774\n",
      "loss 119.61656237840653\n",
      "loss 123.63087378025055\n",
      "loss 127.62537262439727\n",
      "loss 131.58473967313768\n",
      "loss 135.50729938983918\n",
      "loss 139.37724303007127\n",
      "loss 143.28269656419755\n",
      "loss 147.1468761444092\n",
      "loss 151.0001303434372\n",
      "loss 154.83091928720475\n",
      "loss 158.67072452545165\n",
      "Epoch:  3\n",
      "training loss =  4.287735213994144\n",
      "loss 3.067269113063812\n",
      "loss 6.146002204418182\n",
      "loss 9.276942708492278\n",
      "loss 12.351782944202423\n",
      "loss 15.459951419830322\n",
      "loss 18.630739719867705\n",
      "loss 21.769634115695954\n",
      "loss 24.891924443244935\n",
      "loss 28.06244468450546\n",
      "loss 31.301245970726015\n",
      "loss 34.44576176404953\n",
      "loss 37.65931614875794\n",
      "loss 40.85699982881546\n",
      "loss 44.088090014457705\n",
      "loss 47.32728152036667\n",
      "loss 50.568009390830994\n",
      "loss 53.80945072412491\n",
      "loss 57.064946627616884\n",
      "loss 60.35769020318985\n",
      "loss 63.57473991155624\n",
      "loss 66.79667397737504\n",
      "loss 70.06671155452729\n",
      "loss 73.29288454294205\n",
      "loss 76.5147756934166\n",
      "loss 79.75137767791747\n",
      "loss 82.95065485477447\n",
      "loss 86.20277393102646\n",
      "loss 89.42009551286698\n",
      "loss 92.64208748817444\n",
      "loss 95.91098830223083\n",
      "loss 99.13730765581131\n",
      "loss 102.4015466594696\n",
      "loss 105.6745675444603\n",
      "loss 108.90624710559845\n",
      "loss 112.10162214040756\n",
      "loss 115.27712692260742\n",
      "loss 118.49513568401336\n",
      "Epoch:  4\n",
      "training loss =  3.2023562581062572\n",
      "loss 2.4966007220745086\n",
      "loss 5.000764893293381\n",
      "loss 7.518645502328873\n",
      "loss 10.023295228481294\n",
      "loss 12.543886477947234\n",
      "loss 15.11239639878273\n",
      "loss 17.694550091028212\n",
      "loss 20.321153861284255\n",
      "loss 22.971827067136765\n",
      "loss 25.622761429548262\n",
      "loss 28.327344835996627\n",
      "loss 31.060616277456283\n",
      "loss 33.79903153061867\n",
      "loss 36.56582191824913\n",
      "loss 39.33164496779442\n",
      "loss 42.088979011774065\n",
      "loss 44.87799211859703\n",
      "loss 47.693971866369246\n",
      "loss 50.505876916646955\n",
      "loss 53.26919385790825\n",
      "loss 56.083219889402386\n",
      "loss 58.93815564513206\n",
      "loss 61.74311558127403\n",
      "loss 64.6127500450611\n",
      "loss 67.44965189576149\n",
      "loss 70.30368202090263\n",
      "loss 73.17552188515663\n",
      "loss 76.05190935015679\n",
      "loss 78.8983431994915\n",
      "loss 81.78295317530632\n",
      "loss 84.68244111657143\n",
      "loss 87.57139121651649\n",
      "loss 90.45695397257805\n",
      "loss 93.32510363698006\n",
      "loss 96.2361151278019\n",
      "loss 99.17202882647514\n",
      "loss 102.09403890252113\n",
      "Epoch:  5\n",
      "training loss =  2.759735715109478\n",
      "loss 2.1826918077468873\n",
      "loss 4.346519057750702\n",
      "loss 6.513517427444458\n",
      "loss 8.723324557542801\n",
      "loss 10.993728204965592\n",
      "loss 13.281084965467453\n",
      "loss 15.621493813991547\n",
      "loss 17.945766208171843\n",
      "loss 20.318748079538345\n",
      "loss 22.68820149540901\n",
      "loss 25.090371795892715\n",
      "loss 27.54449697613716\n",
      "loss 29.971018855571746\n",
      "loss 32.429846954345706\n",
      "loss 34.90989952087402\n",
      "loss 37.39255306959152\n",
      "loss 39.94722728252411\n",
      "loss 42.4871444439888\n",
      "loss 45.034562734365466\n",
      "loss 47.612867554426195\n",
      "loss 50.186425176858904\n",
      "loss 52.804708446264264\n",
      "loss 55.41601822018623\n",
      "loss 58.050115517377854\n",
      "loss 60.69027548193932\n",
      "loss 63.358038600683216\n",
      "loss 66.0030214035511\n",
      "loss 68.62013310551643\n",
      "loss 71.32082196116447\n",
      "loss 73.98922437548637\n",
      "loss 76.68633044838906\n",
      "loss 79.35129185557365\n",
      "loss 82.04671355605126\n",
      "loss 84.72162394404411\n",
      "loss 87.43074085354804\n",
      "loss 90.15888196349144\n",
      "loss 92.90017846941947\n",
      "Epoch:  6\n",
      "training loss =  2.5112404743230083\n",
      "loss 1.9627464962005616\n",
      "loss 3.923496949672699\n",
      "loss 5.941248459815979\n",
      "loss 7.9665003263950345\n",
      "loss 10.0562502348423\n",
      "loss 12.156989598274231\n",
      "loss 14.27849858522415\n",
      "loss 16.442535930871962\n",
      "loss 18.634411673545838\n",
      "loss 20.83598024725914\n",
      "loss 23.07059523820877\n",
      "loss 25.309709347486496\n",
      "loss 27.604222489595415\n",
      "loss 29.899664527177812\n",
      "loss 32.2228606235981\n",
      "loss 34.56165179252625\n",
      "loss 36.94714247584343\n",
      "loss 39.35355687737465\n",
      "loss 41.782127861976626\n",
      "loss 44.18983788728714\n",
      "loss 46.62495522737503\n",
      "loss 49.061782021522525\n",
      "loss 51.542226153612134\n",
      "loss 53.99584560632706\n",
      "loss 56.468025605678555\n",
      "loss 58.94047600865364\n",
      "loss 61.416228338479996\n",
      "loss 63.962089480161666\n",
      "loss 66.46019815087318\n",
      "loss 68.97703733682633\n",
      "loss 71.51761045455933\n",
      "loss 74.07595579862594\n",
      "loss 76.60330188274384\n",
      "loss 79.22980392932892\n",
      "loss 81.83271844863891\n",
      "loss 84.43766161680222\n",
      "loss 87.00335593938827\n",
      "Epoch:  7\n",
      "training loss =  2.3520011929511253\n",
      "loss 1.8372589719295502\n",
      "loss 3.6703533709049223\n",
      "loss 5.542818806171417\n",
      "loss 7.425722167491913\n",
      "loss 9.344257063865662\n",
      "loss 11.326974620819092\n",
      "loss 13.309233951568604\n",
      "loss 15.329826197624207\n",
      "loss 17.408291965723038\n",
      "loss 19.504471645355224\n",
      "loss 21.61553911924362\n",
      "loss 23.721228227615356\n",
      "loss 25.86975528717041\n",
      "loss 28.00892158985138\n",
      "loss 30.213683829307556\n",
      "loss 32.40414441943169\n",
      "loss 34.63143963813782\n",
      "loss 36.90001676082611\n",
      "loss 39.20649578094483\n",
      "loss 41.53515396118164\n",
      "loss 43.842314089536664\n",
      "loss 46.14927349448204\n",
      "loss 48.450377749204634\n",
      "loss 50.774684977531436\n",
      "loss 53.13181485056877\n",
      "loss 55.53528913855553\n",
      "loss 57.92267310619354\n",
      "loss 60.32732479095459\n",
      "loss 62.753841639757155\n",
      "loss 65.23641183495522\n",
      "loss 72.61017827272416\n",
      "loss 75.04092212438583\n",
      "loss 77.52677795648574\n",
      "loss 79.99120932102204\n",
      "loss 82.45635649681091\n",
      "Epoch:  8\n",
      "training loss =  2.2292040896152017\n",
      "loss 1.7387781953811645\n",
      "loss 3.477246103286743\n",
      "loss 5.251789691448212\n",
      "loss 7.0744183170795445\n",
      "loss 8.868570349216462\n",
      "loss 10.724700523614883\n",
      "loss 12.617220606803894\n",
      "loss 14.52474761724472\n",
      "loss 16.49586933016777\n",
      "loss 18.482063018083572\n",
      "loss 20.504169702529907\n",
      "loss 22.546264871358872\n",
      "loss 24.600179649591446\n",
      "loss 26.681310613155365\n",
      "loss 28.799140833616256\n",
      "loss 30.910142792463304\n",
      "loss 33.08388392329216\n",
      "loss 35.253674094676974\n",
      "loss 37.39054299235344\n",
      "loss 39.590240782499315\n",
      "loss 41.80772000074386\n",
      "loss 44.06495765805244\n",
      "loss 46.33842653989792\n",
      "loss 48.62141103029251\n",
      "loss 50.876720674037934\n",
      "loss 53.15529473185539\n",
      "loss 55.50141991138458\n",
      "loss 57.82540436506272\n",
      "loss 60.15291100263595\n",
      "loss 62.49405026316643\n",
      "loss 64.88000090718269\n",
      "loss 67.23335368871689\n",
      "loss 69.63783830285072\n",
      "loss 72.04238126635552\n",
      "loss 74.43862266540528\n",
      "loss 76.82575121879577\n",
      "loss 79.26208096861839\n",
      "Epoch:  9\n",
      "training loss =  2.142708530733455\n",
      "loss 1.6585763311386108\n",
      "loss 3.2916402077674864\n",
      "loss 4.980574283599854\n",
      "loss 6.6976470017433165\n",
      "loss 8.46718432545662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 10.240632075071336\n",
      "loss 12.069840326309205\n",
      "loss 13.938920387029647\n",
      "loss 15.809349184036256\n",
      "loss 17.729643260240554\n",
      "loss 19.65984716773033\n",
      "loss 21.615733636617662\n",
      "loss 23.604098544120788\n",
      "loss 25.571662653684616\n",
      "loss 27.5611525785923\n",
      "loss 29.612983305454254\n",
      "loss 31.682136840820313\n",
      "loss 33.762827520370486\n",
      "loss 35.87427238225937\n",
      "loss 37.97296233534813\n",
      "loss 40.10644050359726\n",
      "loss 42.27728068351745\n",
      "loss 44.46165667295456\n",
      "loss 46.65139654159546\n",
      "loss 48.924599041938784\n",
      "loss 51.16887447595596\n",
      "loss 53.41809599876404\n",
      "loss 55.67744483232498\n",
      "loss 57.96171327114105\n",
      "loss 60.26143671631813\n",
      "loss 62.60909354448319\n",
      "loss 64.93766951560974\n",
      "loss 67.26440973162651\n",
      "loss 69.60172724366188\n",
      "loss 71.94569890141487\n",
      "loss 74.26609712719917\n",
      "loss 76.603294993639\n",
      "Epoch:  10\n",
      "training loss =  2.07091903921276\n",
      "loss 1.6091773283481599\n",
      "loss 3.25008682012558\n",
      "loss 4.900350543260575\n",
      "loss 6.536472481489182\n",
      "loss 8.215294930934906\n",
      "loss 9.943226191997528\n",
      "loss 11.699727711677552\n",
      "loss 13.495151205062866\n",
      "loss 15.316183601617814\n",
      "loss 17.146505715847017\n",
      "loss 19.04083668589592\n",
      "loss 20.902711980342865\n",
      "loss 22.82528974890709\n",
      "loss 24.713754097223283\n",
      "loss 26.67841361284256\n",
      "loss 28.69798861980438\n",
      "loss 30.688683032989502\n",
      "loss 32.75653917074204\n",
      "loss 34.81257062315941\n",
      "loss 36.873596564531326\n",
      "loss 38.96947718977928\n",
      "loss 41.095314962863924\n",
      "loss 43.21811569452286\n",
      "loss 45.38023329734802\n",
      "loss 52.017053512334826\n",
      "loss 54.22512402653694\n",
      "loss 56.46494537353516\n",
      "loss 58.742077782154084\n",
      "loss 60.99512585878372\n",
      "loss 63.23208615064621\n",
      "loss 65.50740466952324\n",
      "loss 67.7956372487545\n",
      "loss 70.0991645693779\n",
      "loss 72.39250168681144\n",
      "loss 74.7521951508522\n",
      "Epoch:  11\n",
      "training loss =  2.021154076640806\n",
      "loss 1.5568258917331697\n",
      "loss 3.0908751845359803\n",
      "loss 4.691590371131897\n",
      "loss 6.303416088819504\n",
      "loss 7.933755978345871\n",
      "loss 9.598108043670655\n",
      "loss 11.298739637136459\n",
      "loss 13.03602344751358\n",
      "loss 14.823640741109848\n",
      "loss 16.63130752205849\n",
      "loss 18.45621029853821\n",
      "loss 20.269859548807144\n",
      "loss 22.164581973552703\n",
      "loss 24.068817883729935\n",
      "loss 25.999978021383285\n",
      "loss 27.973325268030166\n",
      "loss 29.924074807167052\n",
      "loss 31.90180561542511\n",
      "loss 33.90849644780159\n",
      "loss 35.9592953646183\n",
      "loss 38.04619917154312\n",
      "loss 40.142689875364304\n",
      "loss 42.207672975063325\n",
      "loss 44.29777945995331\n",
      "loss 46.415820368528365\n",
      "loss 48.529238311052325\n",
      "loss 50.66426375985146\n",
      "loss 52.85009883522987\n",
      "loss 55.04785538196564\n",
      "loss 57.26516007065773\n",
      "loss 59.524064024686815\n",
      "loss 61.742212302684784\n",
      "loss 63.98100215673447\n",
      "loss 66.19791513085366\n",
      "loss 68.48486626386642\n",
      "loss 70.74131588101388\n",
      "loss 72.99977437257766\n",
      "Epoch:  12\n",
      "training loss =  1.9737488757834012\n",
      "loss 1.52644681930542\n",
      "loss 3.0296487748622893\n",
      "loss 4.594102832078934\n",
      "loss 6.188784456253051\n",
      "loss 7.808083144426345\n",
      "loss 9.431285454034805\n",
      "loss 11.061425535678863\n",
      "loss 12.763906037807464\n",
      "loss 14.48593598484993\n",
      "loss 16.254691269397735\n",
      "loss 18.043618068695068\n",
      "loss 19.89247782945633\n",
      "loss 21.695127298831938\n",
      "loss 23.574695056676866\n",
      "loss 25.44502267599106\n",
      "loss 27.36607892394066\n",
      "loss 29.28786888718605\n",
      "loss 31.227804967164992\n",
      "loss 33.22540643692017\n",
      "loss 35.24265103578568\n",
      "loss 37.232431782484056\n",
      "loss 39.2485379743576\n",
      "loss 41.32873831510544\n",
      "loss 43.41000428438187\n",
      "loss 45.53912295699119\n",
      "loss 47.67585359096527\n",
      "loss 49.829347907304765\n",
      "loss 51.92166336655617\n",
      "loss 54.08084846377373\n",
      "loss 56.24634450554848\n",
      "loss 58.39482576727867\n",
      "loss 60.55547129392624\n",
      "loss 62.75479033470154\n",
      "loss 64.9237655055523\n",
      "loss 67.17002968430519\n",
      "loss 69.44822525382042\n",
      "loss 71.68419196128845\n",
      "Epoch:  13\n",
      "training loss =  1.937983096047878\n",
      "loss 1.5100788116455077\n",
      "loss 3.0227679002285\n",
      "loss 4.510797554254532\n",
      "loss 6.033652086257934\n",
      "loss 7.62386794090271\n",
      "loss 9.227013216018676\n",
      "loss 10.861646699905396\n",
      "loss 12.51983597755432\n",
      "loss 14.219278279542923\n",
      "loss 15.945635194778442\n",
      "loss 17.70531793117523\n",
      "loss 19.47050780773163\n",
      "loss 21.269018170833586\n",
      "loss 23.093012878894807\n",
      "loss 24.947019381523134\n",
      "loss 26.854641171693803\n",
      "loss 28.714168214797972\n",
      "loss 30.659062708616258\n",
      "loss 32.615636183023454\n",
      "loss 34.59597581863403\n",
      "loss 36.597142769098284\n",
      "loss 38.60882179021835\n",
      "loss 40.6222924554348\n",
      "loss 42.663550362586975\n",
      "loss 44.75065507173538\n",
      "loss 46.819625852108004\n",
      "loss 48.860441393852234\n",
      "loss 50.96320495247841\n",
      "loss 53.093407452106476\n",
      "loss 55.20372609734535\n",
      "loss 57.335543018579486\n",
      "loss 59.528205845355984\n",
      "loss 61.698145289421085\n",
      "loss 63.86747172832489\n",
      "loss 66.04920976161957\n",
      "loss 68.21559621453285\n",
      "loss 70.43487270474434\n",
      "Epoch:  14\n",
      "training loss =  1.9041984471665068\n",
      "loss 1.5066424453258513\n",
      "loss 2.9794376838207244\n",
      "loss 4.467086806297302\n",
      "loss 5.995206357240677\n",
      "loss 7.572745208740234\n",
      "loss 9.13547074317932\n",
      "loss 10.735371743440629\n",
      "loss 12.356471680402755\n",
      "loss 14.021506787538529\n",
      "loss 15.671236218214036\n",
      "loss 17.37314389228821\n",
      "loss 19.1311236679554\n",
      "loss 20.87761115550995\n",
      "loss 22.652699325084686\n",
      "loss 24.467434376478195\n",
      "loss 26.348486804962157\n",
      "loss 28.20864696621895\n",
      "loss 30.10362940311432\n",
      "loss 32.01471334576607\n",
      "loss 33.95822434663773\n",
      "loss 35.88196075201034\n",
      "loss 37.84816564679146\n",
      "loss 39.842464308738705\n",
      "loss 41.87792753815651\n",
      "loss 43.91970778822899\n",
      "loss 45.968941123485564\n",
      "loss 48.030850236415866\n",
      "loss 50.13941616535187\n",
      "loss 52.23378831624985\n",
      "loss 54.33810399651527\n",
      "loss 56.41742431640625\n",
      "loss 58.55323218941689\n",
      "loss 60.75274053692818\n",
      "loss 62.899222736358645\n",
      "loss 65.10665210962296\n",
      "loss 67.3418755376339\n",
      "loss 69.55183207392693\n",
      "Epoch:  15\n",
      "training loss =  1.8806182449642848\n",
      "loss 1.4462902748584747\n",
      "loss 2.907815634012222\n",
      "loss 4.388644882440567\n",
      "loss 5.906277132034302\n",
      "loss 7.416440205574036\n",
      "loss 8.990000950098038\n",
      "loss 10.562161663770675\n",
      "loss 12.161856495141983\n",
      "loss 13.78902845621109\n",
      "loss 15.460999175310135\n",
      "loss 17.153291306495667\n",
      "loss 18.886746517419816\n",
      "loss 20.628754476308824\n",
      "loss 22.41025009274483\n",
      "loss 24.202943065166473\n",
      "loss 26.039042395353317\n",
      "loss 27.90149907708168\n",
      "loss 29.725847486257553\n",
      "loss 31.61893254995346\n",
      "loss 33.546835418939594\n",
      "loss 35.47717228055\n",
      "loss 37.416429229974746\n",
      "loss 39.36438163638115\n",
      "loss 41.34615388154984\n",
      "loss 43.40258611559868\n",
      "loss 45.410898109674456\n",
      "loss 47.48704275131226\n",
      "loss 49.5655057823658\n",
      "loss 51.64018462300301\n",
      "loss 53.70549754977226\n",
      "loss 55.78531044483185\n",
      "loss 57.91511862754822\n",
      "loss 60.03583795070648\n",
      "loss 62.217941501140594\n",
      "loss 64.3870846235752\n",
      "loss 66.53694427609443\n",
      "loss 68.69652807712555\n",
      "Epoch:  16\n",
      "training loss =  1.8572324962348412\n",
      "Validation Loss: 2.3503\tTop 1 Validation Accuracy: 0.7096\t Top 5 Validation Accuracy: 0.8369\n",
      "loss 1.4398782473802567\n",
      "loss 2.866654435992241\n",
      "loss 4.3242349046468735\n",
      "loss 5.7954537004232405\n",
      "loss 7.282342960238457\n",
      "loss 8.814790160059928\n",
      "loss 10.385293565392494\n",
      "loss 11.958999926447868\n",
      "loss 13.597469970583916\n",
      "loss 15.255659735798837\n",
      "loss 16.919915192723273\n",
      "loss 18.61271277844906\n",
      "loss 20.351669436097144\n",
      "loss 22.069359531998636\n",
      "loss 23.824921063780785\n",
      "loss 25.598193313479424\n",
      "loss 27.399413909316063\n",
      "loss 29.23575734078884\n",
      "loss 31.129348372817038\n",
      "loss 32.99438895404339\n",
      "loss 34.88274812042713\n",
      "loss 36.81892261326313\n",
      "loss 38.74762510240078\n",
      "loss 40.71293254435062\n",
      "loss 42.68120157539845\n",
      "loss 44.714852823615075\n",
      "loss 46.73300026476383\n",
      "loss 48.7620490783453\n",
      "loss 50.83774583518505\n",
      "loss 52.88642147123814\n",
      "loss 54.97047905743122\n",
      "loss 57.081411963105204\n",
      "loss 59.18969842731953\n",
      "loss 61.33390261113644\n",
      "loss 63.46036666691303\n",
      "loss 65.60505600035191\n",
      "loss 67.78366479218006\n",
      "Epoch:  17\n",
      "training loss =  1.832547380672107\n",
      "loss 1.4181588518619537\n",
      "loss 2.8205760884284974\n",
      "loss 4.255348076820374\n",
      "loss 5.736262460947037\n",
      "loss 7.218228194713593\n",
      "loss 8.734849247932434\n",
      "loss 10.288827505111694\n",
      "loss 11.864921197891235\n",
      "loss 13.457413213253021\n",
      "loss 15.094988143444061\n",
      "loss 16.750458300113678\n",
      "loss 18.407341768741606\n",
      "loss 20.10031557559967\n",
      "loss 21.846749589443206\n",
      "loss 23.598562413454054\n",
      "loss 25.371758803129197\n",
      "loss 27.14907298564911\n",
      "loss 28.954460294246672\n",
      "loss 30.82552514076233\n",
      "loss 32.667670075893405\n",
      "loss 34.56702342152595\n",
      "loss 36.47021885752678\n",
      "loss 38.378411699533466\n",
      "loss 40.30279311656952\n",
      "loss 42.248936513662336\n",
      "loss 44.24955815315246\n",
      "loss 46.26898099303246\n",
      "loss 48.295483957529065\n",
      "loss 50.31843781232834\n",
      "loss 52.377600555419924\n",
      "loss 54.42682294368744\n",
      "loss 56.481513671875\n",
      "loss 58.567409474849704\n",
      "loss 60.6980251634121\n",
      "loss 62.783287683725355\n",
      "loss 64.93428831458091\n",
      "loss 67.100809943676\n",
      "Epoch:  18\n",
      "training loss =  1.81407344418457\n",
      "loss 1.422857140302658\n",
      "loss 2.8205676245689393\n",
      "loss 4.212991235256195\n",
      "loss 5.646424735784531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 7.115673738718033\n",
      "loss 8.625575969219208\n",
      "loss 10.139751901626587\n",
      "loss 11.693225774765015\n",
      "loss 13.271277552843094\n",
      "loss 14.892294850349426\n",
      "loss 16.528485676050185\n",
      "loss 18.18512448787689\n",
      "loss 19.86912027001381\n",
      "loss 21.587797782421113\n",
      "loss 23.30888095974922\n",
      "loss 25.093033586740493\n",
      "loss 26.859638257026674\n",
      "loss 28.6693274474144\n",
      "loss 30.526070829629898\n",
      "loss 32.40160165309906\n",
      "loss 34.296898450851444\n",
      "loss 36.1625917840004\n",
      "loss 38.11834899663925\n",
      "loss 40.03809939026833\n",
      "loss 41.975172213315965\n",
      "loss 43.952169661521914\n",
      "loss 45.949269852638245\n",
      "loss 47.9191490828991\n",
      "loss 49.9702697122097\n",
      "loss 52.01086965560913\n",
      "loss 54.09569990277291\n",
      "loss 60.32009246706963\n",
      "loss 62.43519679546356\n",
      "loss 64.5455368220806\n",
      "loss 66.63687239527702\n",
      "Epoch:  19\n",
      "training loss =  1.8015875756853124\n",
      "loss 1.377556298971176\n",
      "loss 2.747803041934967\n",
      "loss 4.18627625465393\n",
      "loss 5.616000086665154\n",
      "loss 7.073282825350762\n",
      "loss 8.538827316164971\n",
      "loss 10.06718615591526\n",
      "loss 11.63506234228611\n",
      "loss 13.223551059365272\n",
      "loss 14.801507814526557\n",
      "loss 16.42593819320202\n",
      "loss 18.04973843872547\n",
      "loss 19.719085276722907\n",
      "loss 21.39334133565426\n",
      "loss 23.130608969330787\n",
      "loss 24.868548532128333\n",
      "loss 26.62657558262348\n",
      "loss 28.399091561436652\n",
      "loss 30.19287930190563\n",
      "loss 32.01956205189228\n",
      "loss 33.82656183183193\n",
      "loss 35.723575457930565\n",
      "loss 37.618374266028404\n",
      "loss 39.5497535854578\n",
      "loss 41.47089353144169\n",
      "loss 43.43761568725109\n",
      "loss 45.429315758347514\n",
      "loss 47.39489270865917\n",
      "loss 49.40391435205937\n",
      "loss 51.44786794841289\n",
      "loss 55.490806722044944\n",
      "loss 57.55565790116787\n",
      "loss 59.631646261811255\n",
      "loss 61.72412855923176\n",
      "loss 63.83677184641361\n",
      "loss 65.91858887970447\n",
      "Epoch:  20\n",
      "training loss =  1.7819565695863482\n",
      "loss 1.3564724135398865\n",
      "loss 2.7493156135082244\n",
      "loss 4.117540783882141\n",
      "loss 5.547485857009888\n",
      "loss 6.995059340000153\n",
      "loss 8.465555630922317\n",
      "loss 9.943877130746841\n",
      "loss 11.483691780567169\n",
      "loss 12.990525530576706\n",
      "loss 14.575380917787552\n",
      "loss 16.141997709274293\n",
      "loss 17.80006673336029\n",
      "loss 19.48824682712555\n",
      "loss 21.149413503408432\n",
      "loss 22.8560633957386\n",
      "loss 24.567735840082168\n",
      "loss 26.358449866771696\n",
      "loss 28.166369841098785\n",
      "loss 29.9691186439991\n",
      "loss 31.77633625626564\n",
      "loss 33.63611401796341\n",
      "loss 35.51694234013557\n",
      "loss 37.40667932748794\n",
      "loss 39.32599467515946\n",
      "loss 41.2230845952034\n",
      "loss 43.15573300242424\n",
      "loss 45.086693905591964\n",
      "loss 47.069969881773\n",
      "loss 49.052324267625806\n",
      "loss 51.0555476796627\n",
      "loss 53.06362816929817\n",
      "loss 55.06091924905777\n",
      "loss 57.09083345770836\n",
      "loss 59.12830793261528\n",
      "loss 61.196887041330335\n",
      "loss 63.2931628715992\n",
      "loss 65.3900224328041\n",
      "Epoch:  21\n",
      "training loss =  1.7680270885051277\n",
      "loss 1.3701993107795716\n",
      "loss 2.7271835404634475\n",
      "loss 4.111448813080788\n",
      "loss 5.483968883156776\n",
      "loss 6.920481348633766\n",
      "loss 8.384265665411949\n",
      "loss 9.852920758128166\n",
      "loss 11.401090639233589\n",
      "loss 12.931678630709648\n",
      "loss 14.52197556078434\n",
      "loss 16.095372386574745\n",
      "loss 17.71404476583004\n",
      "loss 19.317938719391822\n",
      "loss 20.922042837738992\n",
      "loss 22.615422622561454\n",
      "loss 24.33281196296215\n",
      "loss 26.07611727297306\n",
      "loss 27.865841754078865\n",
      "loss 29.672064883112906\n",
      "loss 31.48367657482624\n",
      "loss 33.3116553324461\n",
      "loss 35.182763125300404\n",
      "loss 37.06533788502216\n",
      "loss 38.98589469850063\n",
      "loss 40.87659768283367\n",
      "loss 42.75868092119694\n",
      "loss 44.72606533586979\n",
      "loss 46.683244653344154\n",
      "loss 48.60136129200458\n",
      "loss 50.56090707242489\n",
      "loss 52.543579480051996\n",
      "loss 54.59488493859768\n",
      "loss 56.62470431506634\n",
      "loss 58.70992842257023\n",
      "loss 60.79064314305782\n",
      "loss 62.872285810112956\n",
      "loss 64.99264505326748\n",
      "Epoch:  22\n",
      "training loss =  1.7573502325355637\n",
      "loss 4.0763572454452515\n",
      "loss 5.482691080570221\n",
      "loss 6.863577038049698\n",
      "loss 8.293279643058776\n",
      "loss 9.737965418100357\n",
      "loss 11.216307506561279\n",
      "loss 12.74449092388153\n",
      "loss 14.298125313520432\n",
      "loss 15.852267647981643\n",
      "loss 17.433949284553528\n",
      "loss 19.06436393260956\n",
      "loss 20.731083364486693\n",
      "loss 22.417957056760788\n",
      "loss 24.11496599674225\n",
      "loss 25.843219858407974\n",
      "loss 27.612380961179735\n",
      "loss 29.37332026720047\n",
      "loss 31.135787316560744\n",
      "loss 32.9700524032116\n",
      "loss 34.80629303216934\n",
      "loss 36.69096110463143\n",
      "loss 38.57538853168487\n",
      "loss 40.46647491812706\n",
      "loss 42.40122548818588\n",
      "loss 44.347755215168\n",
      "loss 46.33643198132515\n",
      "loss 48.31137645840645\n",
      "loss 50.31824674487114\n",
      "loss 52.329456498622896\n",
      "loss 54.310381077528\n",
      "loss 56.34566019773483\n",
      "loss 58.39748697757721\n",
      "loss 60.454433538913726\n",
      "loss 62.52242552161217\n",
      "loss 64.59601309418679\n",
      "Epoch:  23\n",
      "training loss =  1.7467027975923133\n",
      "loss 1.3681103241443635\n",
      "loss 2.695941466093063\n",
      "loss 6.853561420440673\n",
      "loss 8.281278785467148\n",
      "loss 9.740536719560623\n",
      "loss 11.247996580600738\n",
      "loss 12.759330759048462\n",
      "loss 14.343941590785981\n",
      "loss 15.90963250041008\n",
      "loss 17.52984662413597\n",
      "loss 19.18322494864464\n",
      "loss 20.855802376270294\n",
      "loss 22.503556901216506\n",
      "loss 24.204478331804275\n",
      "loss 25.905858986377716\n",
      "loss 27.636687885522843\n",
      "loss 29.41386721253395\n",
      "loss 31.210988980531692\n",
      "loss 33.028721688985826\n",
      "loss 34.86742027878761\n",
      "loss 36.719057730436326\n",
      "loss 38.59748955845833\n",
      "loss 40.51016971349716\n",
      "loss 42.43762810587883\n",
      "loss 44.35091480493546\n",
      "loss 46.31299667239189\n",
      "loss 48.27272447228432\n",
      "loss 50.24843711137772\n",
      "loss 52.25475786924362\n",
      "loss 54.257409479618076\n",
      "loss 56.27989347934723\n",
      "loss 58.29804990530014\n",
      "loss 60.35842779636383\n",
      "loss 62.41233468651772\n",
      "loss 64.51425799369812\n",
      "Epoch:  24\n",
      "training loss =  1.7444929587477649\n",
      "loss 1.3320843482017517\n",
      "loss 2.6581620240211485\n",
      "loss 3.9877066802978516\n",
      "loss 5.359948126077652\n",
      "loss 6.737097988128662\n",
      "loss 8.156166286468506\n",
      "loss 9.60488826751709\n",
      "loss 11.078742703199387\n",
      "loss 12.578347465991975\n",
      "loss 14.102375311851501\n",
      "loss 15.660635496377944\n",
      "loss 17.240638663768767\n",
      "loss 18.85555902481079\n",
      "loss 20.446855469942093\n",
      "loss 22.121304928064347\n",
      "loss 23.825384908914565\n",
      "loss 25.52872630238533\n",
      "loss 27.24091843366623\n",
      "loss 29.001313747167586\n",
      "loss 30.763524140119554\n",
      "loss 32.582060195207596\n",
      "loss 34.388202369213104\n",
      "loss 36.23481670260429\n",
      "loss 38.16095290541649\n",
      "loss 40.072300311326984\n",
      "loss 41.99908749699593\n",
      "loss 43.92588223934174\n",
      "loss 45.90397279381752\n",
      "loss 47.84762004971504\n",
      "loss 49.82114032506943\n",
      "loss 51.796398475170136\n",
      "loss 53.80673610925675\n",
      "loss 55.84215581059456\n",
      "loss 57.86054751396179\n",
      "loss 59.90911322236061\n",
      "loss 61.96045046925545\n",
      "loss 64.00881033182144\n",
      "Epoch:  25\n",
      "training loss =  1.7305501312909821\n",
      "loss 1.329429268836975\n",
      "loss 2.6325603902339934\n",
      "loss 3.951694145202637\n",
      "loss 5.320624741315842\n",
      "loss 6.683698532581329\n",
      "loss 8.08066477060318\n",
      "loss 9.49417224407196\n",
      "loss 10.973955688476563\n",
      "loss 12.501935167312622\n",
      "loss 14.060942326784135\n",
      "loss 15.623469609022141\n",
      "loss 17.23501561522484\n",
      "loss 18.84412814259529\n",
      "loss 20.44050035595894\n",
      "loss 22.114517447948455\n",
      "loss 27.20200890660286\n",
      "loss 28.927176225185395\n",
      "loss 30.70735057234764\n",
      "loss 32.52538750767708\n",
      "loss 34.34285277724266\n",
      "loss 36.142698267698286\n",
      "loss 38.00167662024498\n",
      "loss 39.908982204198836\n",
      "loss 41.828240329027174\n",
      "loss 43.75524375915527\n",
      "loss 45.706370512247084\n",
      "loss 47.65867232441902\n",
      "loss 49.59914209961891\n",
      "loss 51.590867521762846\n",
      "loss 53.582133944034574\n",
      "loss 55.606159012317654\n",
      "loss 57.63813037872315\n",
      "loss 59.66658060669899\n",
      "loss 61.72473087787628\n",
      "loss 63.779920067787174\n",
      "Epoch:  26\n",
      "training loss =  1.724511922611713\n",
      "loss 1.3236345851421356\n",
      "loss 2.635692337155342\n",
      "loss 3.935887169241905\n",
      "loss 5.271709273457527\n",
      "loss 6.6700451558828355\n",
      "loss 8.076363562941552\n",
      "loss 9.496651979088783\n",
      "loss 10.924354408383369\n",
      "loss 12.434436212182044\n",
      "loss 13.943160541653633\n",
      "loss 15.489876361489296\n",
      "loss 17.065800753235816\n",
      "loss 18.646761558651924\n",
      "loss 20.29738368690014\n",
      "loss 21.897604901194573\n",
      "loss 23.596826516985892\n",
      "loss 25.293241105675698\n",
      "loss 26.97885895907879\n",
      "loss 28.726923624873162\n",
      "loss 30.485726949572562\n",
      "loss 32.28079841196537\n",
      "loss 34.08456972062588\n",
      "loss 35.90775660812855\n",
      "loss 37.77502068340778\n",
      "loss 39.61445688188076\n",
      "loss 41.50956229746342\n",
      "loss 43.3848303848505\n",
      "loss 45.340993726849554\n",
      "loss 47.249703473448754\n",
      "loss 49.18956661760807\n",
      "loss 51.14057969510555\n",
      "loss 53.16007299005985\n",
      "loss 55.13986330211163\n",
      "loss 57.17492850244045\n",
      "loss 59.19664203703403\n",
      "loss 61.282178871035576\n",
      "loss 63.300941737294195\n",
      "Epoch:  27\n",
      "training loss =  1.7115484588481296\n",
      "loss 1.3264571380615235\n",
      "loss 2.6318975085020067\n",
      "loss 3.935361567735672\n",
      "loss 5.279449095726013\n",
      "loss 6.646323912143707\n",
      "loss 8.035280886888504\n",
      "loss 9.469947074651719\n",
      "loss 10.928481571674347\n",
      "loss 12.42293328523636\n",
      "loss 13.93337420463562\n",
      "loss 15.445130234956741\n",
      "loss 17.005825841426848\n",
      "loss 18.59305328130722\n",
      "loss 20.19576449036598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 21.821868438720703\n",
      "loss 23.493823701143263\n",
      "loss 25.166573407649995\n",
      "loss 26.83883920788765\n",
      "loss 28.546021124124525\n",
      "loss 30.302893849611284\n",
      "loss 32.090433623790744\n",
      "loss 33.87741080880165\n",
      "loss 35.68845121026039\n",
      "loss 37.541359672546385\n",
      "loss 39.41930737257004\n",
      "loss 41.292046941518784\n",
      "loss 43.18518195033074\n",
      "loss 45.0755021250248\n",
      "loss 46.96958045840263\n",
      "loss 48.930478641986845\n",
      "loss 50.87628025650978\n",
      "loss 52.87362020134926\n",
      "loss 54.881718602180484\n",
      "loss 56.90013919472695\n",
      "loss 58.93394629716873\n",
      "loss 60.98397824764252\n",
      "loss 63.024182909727095\n",
      "Epoch:  28\n",
      "training loss =  1.7040564773344498\n",
      "loss 1.2949912351369859\n",
      "loss 2.6094205850362777\n",
      "loss 3.904471293091774\n",
      "loss 5.248545911312103\n",
      "loss 6.615122691392899\n",
      "loss 8.031847025752068\n",
      "loss 9.421749215126038\n",
      "loss 10.873244837522506\n",
      "loss 12.333633185625077\n",
      "loss 13.849200299978257\n",
      "loss 15.380253802537919\n",
      "loss 16.92630555033684\n",
      "loss 18.512742327451704\n",
      "loss 20.11649008154869\n",
      "loss 21.77985515832901\n",
      "loss 23.43275866866112\n",
      "loss 25.15217633008957\n",
      "loss 26.855668128728865\n",
      "loss 28.586049464941024\n",
      "loss 30.34809634566307\n",
      "loss 32.11694322824478\n",
      "loss 33.936729542016984\n",
      "loss 35.75623465895653\n",
      "loss 37.54268627524376\n",
      "loss 39.42593128800392\n",
      "loss 41.294676450490954\n",
      "loss 43.19590591430664\n",
      "loss 45.07791359782219\n",
      "loss 46.99392422199249\n",
      "loss 48.93043138027191\n",
      "loss 50.900867059230805\n",
      "loss 52.84952192187309\n",
      "loss 54.8352929854393\n",
      "loss 56.83957617521286\n",
      "loss 58.85832635879517\n",
      "loss 60.83156897544861\n",
      "loss 62.875569722652436\n",
      "Epoch:  29\n",
      "training loss =  1.7000203885123966\n",
      "loss 1.2956029868125916\n",
      "loss 2.60855747461319\n",
      "loss 3.9552821201086044\n",
      "loss 5.2980132764577865\n",
      "loss 6.632807866930961\n",
      "loss 8.034787316918374\n",
      "loss 9.470988757014275\n",
      "loss 10.910314136147498\n",
      "loss 12.3964143794775\n",
      "loss 13.862566791176796\n",
      "loss 15.402785615324975\n",
      "loss 16.941182193160056\n",
      "loss 18.4909899109602\n",
      "loss 20.07404715001583\n",
      "loss 21.72250197350979\n",
      "loss 23.376585305333137\n",
      "loss 25.032242243885992\n",
      "loss 26.709589453339575\n",
      "loss 28.439275988936423\n",
      "loss 30.19995330989361\n",
      "loss 31.94946904718876\n",
      "loss 33.730744506716725\n",
      "loss 35.52817693769932\n",
      "loss 37.334894436001775\n",
      "loss 39.13797324001789\n",
      "loss 41.007595594525334\n",
      "loss 42.86609208166599\n",
      "loss 44.76040380179882\n",
      "loss 46.69334016740322\n",
      "loss 48.63273568928242\n",
      "loss 50.57927812159061\n",
      "loss 52.5264546340704\n",
      "loss 54.4709765702486\n",
      "loss 56.422215786576274\n",
      "loss 58.41626578629017\n",
      "loss 60.424464260935785\n",
      "loss 62.4573980563879\n",
      "Epoch:  30\n",
      "training loss =  1.6884826551173169\n",
      "loss 1.2238703697919846\n",
      "loss 2.3164512437582014\n",
      "loss 3.366859686970711\n",
      "loss 4.361442997455597\n",
      "loss 5.315867785215378\n",
      "loss 6.250896348357201\n",
      "loss 7.165685041546822\n",
      "loss 8.055041843652726\n",
      "loss 8.922890347242355\n",
      "loss 9.775884348154069\n",
      "loss 10.636830902695657\n",
      "loss 11.474553285241127\n",
      "loss 12.28395609498024\n",
      "loss 13.120004211068153\n",
      "loss 13.912166815400123\n",
      "loss 14.717504918575287\n",
      "loss 15.521040533781052\n",
      "loss 16.306862499713898\n",
      "loss 17.09911282002926\n",
      "loss 17.88314330279827\n",
      "loss 18.66298851430416\n",
      "loss 19.428148963749408\n",
      "loss 20.184054124951363\n",
      "loss 20.93181710064411\n",
      "loss 21.688023559451103\n",
      "loss 22.41842770457268\n",
      "loss 23.167872714400293\n",
      "loss 23.889295375645162\n",
      "loss 24.61293319582939\n",
      "loss 25.344247117340565\n",
      "loss 26.069687215685846\n",
      "loss 26.791661015152933\n",
      "loss 27.501453109383583\n",
      "loss 28.220280832350255\n",
      "loss 28.93919158041477\n",
      "loss 29.65905182749033\n",
      "loss 30.364529774487018\n",
      "Epoch:  31\n",
      "training loss =  0.8206346490922114\n",
      "Validation Loss: 1.8418\tTop 1 Validation Accuracy: 0.7686\t Top 5 Validation Accuracy: 0.8776\n",
      "loss 0.5970773383975029\n",
      "loss 1.206122374534607\n",
      "loss 1.812665886580944\n",
      "loss 2.418247717320919\n",
      "loss 3.0132296034693717\n",
      "loss 3.61605567663908\n",
      "loss 4.22065422385931\n",
      "loss 4.830528549849987\n",
      "loss 5.451903481483459\n",
      "loss 6.058253280818462\n",
      "loss 6.664712361395359\n",
      "loss 7.256673515737057\n",
      "loss 7.857076126337051\n",
      "loss 8.443343797028065\n",
      "loss 9.045199471116065\n",
      "loss 9.646847245395184\n",
      "loss 10.250758062005042\n",
      "loss 10.830608938634395\n",
      "loss 11.424167086184024\n",
      "loss 12.024597251415253\n",
      "loss 12.624139940738678\n",
      "loss 13.220284776091576\n",
      "loss 13.8076046153903\n",
      "loss 14.396197416484355\n",
      "loss 14.981720676720142\n",
      "loss 15.578889337182044\n",
      "loss 16.186062672436236\n",
      "loss 16.78019263744354\n",
      "loss 17.3719225949049\n",
      "loss 17.959470828175544\n",
      "loss 18.551548805832862\n",
      "loss 19.145521193742752\n",
      "loss 19.734508341252806\n",
      "loss 20.327732754349707\n",
      "loss 20.92713498696685\n",
      "loss 21.507099024802447\n",
      "loss 22.08869288906455\n",
      "Epoch:  32\n",
      "training loss =  0.5969103590791555\n",
      "loss 0.5035401517152787\n",
      "loss 0.9956671729683876\n",
      "loss 1.5024189341068268\n",
      "loss 2.0245187312364576\n",
      "loss 2.5227363163232805\n",
      "loss 3.0334912586212157\n",
      "loss 3.530369140803814\n",
      "loss 4.040381759107113\n",
      "loss 4.551672163009644\n",
      "loss 5.0542026400566105\n",
      "loss 5.569855603277683\n",
      "loss 6.080262082517147\n",
      "loss 6.595590324997902\n",
      "loss 7.121001197099686\n",
      "loss 7.629307631254196\n",
      "loss 8.154191156625748\n",
      "loss 8.672678802907466\n",
      "loss 9.177000456750394\n",
      "loss 9.689435620605945\n",
      "loss 10.204159382283688\n",
      "loss 10.722236272394657\n",
      "loss 11.245798271596431\n",
      "loss 11.759476953744889\n",
      "loss 12.27241512954235\n",
      "loss 12.803092737793923\n",
      "loss 13.326258469223976\n",
      "loss 13.840955165922642\n",
      "loss 14.345536687970162\n",
      "loss 14.871065242886543\n",
      "loss 15.378095362186432\n",
      "loss 15.901369998455047\n",
      "loss 16.424650569856166\n",
      "loss 16.94630115509033\n",
      "loss 17.47982479393482\n",
      "loss 17.992377521693708\n",
      "loss 18.506868691444396\n",
      "loss 19.03025418907404\n",
      "Epoch:  33\n",
      "training loss =  0.5143045797272773\n",
      "loss 0.44949055880308153\n",
      "loss 0.8968097381293774\n",
      "loss 1.335918403118849\n",
      "loss 1.7798323272168637\n",
      "loss 2.2220490483939646\n",
      "loss 2.669387473613024\n",
      "loss 3.1318248377740385\n",
      "loss 3.5822437809407712\n",
      "loss 4.042065290361643\n",
      "loss 4.496225548833609\n",
      "loss 4.944092451184988\n",
      "loss 5.398932362347841\n",
      "loss 5.860626446157694\n",
      "loss 6.309956034868955\n",
      "loss 6.761182993501425\n",
      "loss 7.218559197932482\n",
      "loss 7.687690044492483\n",
      "loss 8.148040245324374\n",
      "loss 8.610739869326354\n",
      "loss 9.071657995432615\n",
      "loss 9.532109347283841\n",
      "loss 10.002261000573634\n",
      "loss 10.47454833984375\n",
      "loss 10.937970823347568\n",
      "loss 11.401656794548035\n",
      "loss 11.877021215558052\n",
      "loss 12.348734772205352\n",
      "loss 12.819840832352638\n",
      "loss 13.277797589600086\n",
      "loss 13.747457084953785\n",
      "loss 14.236309622228145\n",
      "loss 14.711587267816066\n",
      "loss 15.195833215415478\n",
      "loss 15.683820531070232\n",
      "loss 16.15565990239382\n",
      "loss 16.636131887435912\n",
      "loss 17.10555348068476\n",
      "Epoch:  34\n",
      "training loss =  0.4623046473557009\n",
      "loss 0.4021039083600044\n",
      "loss 0.8032845637202263\n",
      "loss 1.2023298525810242\n",
      "loss 1.6166851410269738\n",
      "loss 2.024326403439045\n",
      "loss 2.4355661559104917\n",
      "loss 2.8535066485404967\n",
      "loss 3.2672322215139866\n",
      "loss 3.6813364112377167\n",
      "loss 4.106878111660481\n",
      "loss 4.519651691317558\n",
      "loss 4.934317892044783\n",
      "loss 5.361244166344404\n",
      "loss 5.777114832699299\n",
      "loss 6.202076435387134\n",
      "loss 6.622126953303814\n",
      "loss 7.040748071521521\n",
      "loss 7.461158792227507\n",
      "loss 7.884580766707659\n",
      "loss 8.305823230296374\n",
      "loss 8.742644404917955\n",
      "loss 9.16248378828168\n",
      "loss 9.598672767281533\n",
      "loss 10.035615845024585\n",
      "loss 10.463777374923229\n",
      "loss 10.89447363615036\n",
      "loss 11.330811869204044\n",
      "loss 11.760767609775066\n",
      "loss 12.200397468805313\n",
      "loss 12.638546941280365\n",
      "loss 13.071409695744514\n",
      "loss 13.510574704408645\n",
      "loss 13.94874822244048\n",
      "loss 14.376048907786608\n",
      "loss 14.803322950452566\n",
      "loss 15.240368354469538\n",
      "loss 15.687249712198973\n",
      "Epoch:  35\n",
      "training loss =  0.4240755711543711\n",
      "loss 0.3740283264219761\n",
      "loss 0.7395702539384366\n",
      "loss 1.1112070064246655\n",
      "loss 1.4853031131625176\n",
      "loss 1.8640510991215706\n",
      "loss 2.245650023818016\n",
      "loss 2.6192727953195574\n",
      "loss 3.0113243794441225\n",
      "loss 3.3957037626206876\n",
      "loss 3.778935822844505\n",
      "loss 4.174574399888516\n",
      "loss 4.573218816965818\n",
      "loss 4.955787158310414\n",
      "loss 5.3404196012020115\n",
      "loss 5.730667846798897\n",
      "loss 6.1306399431824685\n",
      "loss 6.518416291624308\n",
      "loss 6.922696342766285\n",
      "loss 7.318660518676043\n",
      "loss 7.71481964752078\n",
      "loss 8.105982537567616\n",
      "loss 8.526286440491676\n",
      "loss 8.919359067827463\n",
      "loss 9.319887898117305\n",
      "loss 9.718630870431662\n",
      "loss 10.130524259209633\n",
      "loss 10.530090810060502\n",
      "loss 10.925262440741061\n",
      "loss 11.325873858630658\n",
      "loss 11.725733982622623\n",
      "loss 12.127164325714112\n",
      "loss 12.533545730113984\n",
      "loss 12.945172876268625\n",
      "loss 13.35318479552865\n",
      "loss 13.775056498795747\n",
      "loss 14.185579924732446\n",
      "loss 14.588536739051342\n",
      "Epoch:  36\n",
      "training loss =  0.3944564049202765\n",
      "loss 0.3516758631169796\n",
      "loss 0.7111499193310737\n",
      "loss 1.0735102996230126\n",
      "loss 1.423525136858225\n",
      "loss 1.7794182634353637\n",
      "loss 2.1309722262620925\n",
      "loss 2.4963088835775853\n",
      "loss 2.868237994462252\n",
      "loss 3.231367845386267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 3.592467807382345\n",
      "loss 3.9525555197894575\n",
      "loss 4.306700756400824\n",
      "loss 4.672283150553703\n",
      "loss 5.0455682802200315\n",
      "loss 5.414100653380156\n",
      "loss 5.780653134286403\n",
      "loss 6.14909411072731\n",
      "loss 6.521903623342514\n",
      "loss 6.911194252967834\n",
      "loss 7.28446801006794\n",
      "loss 7.649304782003164\n",
      "loss 8.030895725637674\n",
      "loss 8.397678276002408\n",
      "loss 8.783211009055377\n",
      "loss 9.159937547445297\n",
      "loss 9.528753596693278\n",
      "loss 9.911121421009302\n",
      "loss 10.286036720126868\n",
      "loss 10.669335954487323\n",
      "loss 11.052096256613732\n",
      "loss 11.437338532209397\n",
      "loss 11.830316160619258\n",
      "loss 12.222550420165062\n",
      "loss 12.597692072093487\n",
      "loss 12.994150563180447\n",
      "loss 13.374798817038537\n",
      "loss 13.760267570018769\n",
      "Epoch:  37\n",
      "training loss =  0.3720556120683409\n",
      "loss 0.3438410234451294\n",
      "loss 0.6666810709238052\n",
      "loss 0.9955715049803257\n",
      "loss 1.3345137426257134\n",
      "loss 1.6599659004807472\n",
      "loss 1.99666972219944\n",
      "loss 2.328630320727825\n",
      "loss 2.6755869929492473\n",
      "loss 3.014435938894749\n",
      "loss 3.358457781970501\n",
      "loss 3.7029701612889765\n",
      "loss 4.040652023404837\n",
      "loss 4.390509499311447\n",
      "loss 4.735088260322809\n",
      "loss 5.09272240549326\n",
      "loss 5.436916512995959\n",
      "loss 5.789427984505892\n",
      "loss 6.144975753426552\n",
      "loss 6.501670259386301\n",
      "loss 6.847783234715462\n",
      "loss 7.209823262989521\n",
      "loss 7.566076174676418\n",
      "loss 7.918267194330692\n",
      "loss 8.28116233214736\n",
      "loss 8.647635659277439\n",
      "loss 9.012046866118908\n",
      "loss 9.370970324128866\n",
      "loss 9.736722495555878\n",
      "loss 10.102066438943147\n",
      "loss 10.462199144661426\n",
      "loss 10.840474407076835\n",
      "loss 11.211181061118841\n",
      "loss 11.581456617563964\n",
      "loss 11.96139150723815\n",
      "loss 12.328091680258513\n",
      "loss 12.699762437194586\n",
      "loss 13.063060863018036\n",
      "Epoch:  38\n",
      "training loss =  0.3531682933754827\n",
      "loss 0.31537581607699394\n",
      "loss 0.6314875034987927\n",
      "loss 0.9565592749416828\n",
      "loss 1.272898276001215\n",
      "loss 1.5853718049824237\n",
      "loss 1.9054504081606864\n",
      "loss 2.2273236317932605\n",
      "loss 2.548828541636467\n",
      "loss 2.881652924865484\n",
      "loss 3.204841098189354\n",
      "loss 3.5393921793997287\n",
      "loss 3.865650936961174\n",
      "loss 4.1930592529475685\n",
      "loss 4.527392909377813\n",
      "loss 4.864078087359667\n",
      "loss 5.199278267621994\n",
      "loss 5.539888302832842\n",
      "loss 5.8809331050515175\n",
      "loss 6.214967201054097\n",
      "loss 6.555759657025337\n",
      "loss 6.892914274036884\n",
      "loss 7.235304399877787\n",
      "loss 7.576735509485006\n",
      "loss 7.9293582679331305\n",
      "loss 8.276687202304602\n",
      "loss 8.624033041000366\n",
      "loss 8.980973785221577\n",
      "loss 9.335411180257797\n",
      "loss 9.68818641975522\n",
      "loss 10.047760297954083\n",
      "loss 10.395306912511588\n",
      "loss 10.758676011413336\n",
      "loss 11.106578982770444\n",
      "loss 11.459852344989777\n",
      "loss 11.826249782443046\n",
      "loss 12.176154953837395\n",
      "loss 12.531624778211118\n",
      "Epoch:  39\n",
      "training loss =  0.33882334980322787\n",
      "loss 0.29740290582180023\n",
      "loss 0.5986836878955364\n",
      "loss 0.9035768263041973\n",
      "loss 1.204558916091919\n",
      "loss 1.5072820526361466\n",
      "loss 1.8045574352145195\n",
      "loss 2.1153739148378374\n",
      "loss 2.422683774828911\n",
      "loss 2.745556838810444\n",
      "loss 3.053302700072527\n",
      "loss 3.374839104562998\n",
      "loss 3.681665795445442\n",
      "loss 4.003372029662132\n",
      "loss 4.327456717789173\n",
      "loss 4.654615255892277\n",
      "loss 4.9904213838279246\n",
      "loss 5.314807451218367\n",
      "loss 5.645544284135103\n",
      "loss 5.972335530072451\n",
      "loss 6.303458366990089\n",
      "loss 6.630376954376698\n",
      "loss 6.960434262156486\n",
      "loss 7.300786016583443\n",
      "loss 7.6413166931271554\n",
      "loss 7.97508019387722\n",
      "loss 8.30979656085372\n",
      "loss 8.653898283690214\n",
      "loss 9.001953725963832\n",
      "loss 9.342843262404203\n",
      "loss 9.681937636882067\n",
      "loss 10.02684158667922\n",
      "loss 10.370406154692173\n",
      "loss 10.714424508363008\n",
      "loss 11.0552904099226\n",
      "loss 11.405247680991888\n",
      "loss 11.755021809339523\n",
      "loss 12.100768346339464\n",
      "Epoch:  40\n",
      "training loss =  0.3271459609688148\n",
      "loss 0.29346387058496476\n",
      "loss 0.5885499900579453\n",
      "loss 0.8786087512969971\n",
      "loss 1.1633263498544693\n",
      "loss 1.4579437565803528\n",
      "loss 1.7539315550029277\n",
      "loss 2.0537323589622973\n",
      "loss 2.3573521669209003\n",
      "loss 2.6533275192975996\n",
      "loss 2.947510160654783\n",
      "loss 3.2489150626957417\n",
      "loss 3.5612454010546206\n",
      "loss 3.87219698369503\n",
      "loss 4.179605761170388\n",
      "loss 4.48575871065259\n",
      "loss 4.792214522510767\n",
      "loss 5.103622001558542\n",
      "loss 5.41383669808507\n",
      "loss 5.722848576903343\n",
      "loss 6.040981579571962\n",
      "loss 6.360413238555193\n",
      "loss 6.687900495529175\n",
      "loss 6.997493970543146\n",
      "loss 7.321667435467243\n",
      "loss 7.655506425350905\n",
      "loss 7.974892766028643\n",
      "loss 8.293790767043829\n",
      "loss 8.62479676231742\n",
      "loss 8.941974447518588\n",
      "loss 9.266797938793898\n",
      "loss 9.599105481654405\n",
      "loss 9.933675358593463\n",
      "loss 10.266639472544194\n",
      "loss 10.590765313208102\n",
      "loss 10.929812428504228\n",
      "loss 11.264782506227494\n",
      "loss 11.602589097619056\n",
      "Epoch:  41\n",
      "training loss =  0.3136518815954901\n",
      "loss 0.2728202912211418\n",
      "loss 0.5522125807404518\n",
      "loss 1.3917712517082692\n",
      "loss 1.6769462269544602\n",
      "loss 1.967215902507305\n",
      "loss 2.2617168283462523\n",
      "loss 2.5583083583414554\n",
      "loss 2.8486138677597044\n",
      "loss 3.1489426156878473\n",
      "loss 3.441546649038792\n",
      "loss 3.7483188486099244\n",
      "loss 4.044008048921824\n",
      "loss 4.347622623592615\n",
      "loss 4.652367956340313\n",
      "loss 4.953572862744331\n",
      "loss 5.258256615102291\n",
      "loss 5.556616232395172\n",
      "loss 5.867154207825661\n",
      "loss 6.190541503280401\n",
      "loss 6.499325358271599\n",
      "loss 6.810767057389021\n",
      "loss 7.123445723354816\n",
      "loss 7.435984484106302\n",
      "loss 7.755785351395607\n",
      "loss 8.075098561048508\n",
      "loss 8.39365885451436\n",
      "loss 8.709003720283508\n",
      "loss 9.029443921595812\n",
      "loss 9.346341705471277\n",
      "loss 9.675011984854937\n",
      "loss 10.002268156707286\n",
      "loss 10.335863897800445\n",
      "loss 10.662619419395924\n",
      "loss 10.985268143862486\n",
      "loss 11.302966655343772\n",
      "Epoch:  42\n",
      "training loss =  0.3056195000970914\n",
      "loss 0.27885932981967926\n",
      "loss 0.5467213079333305\n",
      "loss 0.8243927603960037\n",
      "loss 1.1072939576208591\n",
      "loss 1.3919328951835632\n",
      "loss 1.6738316862285136\n",
      "loss 1.9588972529768944\n",
      "loss 2.2400037710368634\n",
      "loss 2.520449891984463\n",
      "loss 2.813113173544407\n",
      "loss 3.097983296662569\n",
      "loss 3.384371719062328\n",
      "loss 3.663964600265026\n",
      "loss 3.9556843338906766\n",
      "loss 4.250991454273462\n",
      "loss 4.547776069641113\n",
      "loss 4.839999556541443\n",
      "loss 5.138790477216244\n",
      "loss 5.432792233377695\n",
      "loss 5.733548966795206\n",
      "loss 6.040905350297689\n",
      "loss 6.346834003180265\n",
      "loss 6.651674784719944\n",
      "loss 6.957338047772646\n",
      "loss 7.260609871298075\n",
      "loss 7.5695913437008855\n",
      "loss 7.870272312909365\n",
      "loss 8.18622385919094\n",
      "loss 8.49741395458579\n",
      "loss 8.809359683543443\n",
      "loss 9.119940458983184\n",
      "loss 9.445353759527206\n",
      "loss 9.765924899727105\n",
      "loss 10.077603054344655\n",
      "loss 10.389886577874423\n",
      "loss 10.701468853801488\n",
      "loss 11.01850979372859\n",
      "Epoch:  43\n",
      "training loss =  0.29790942958174993\n",
      "loss 0.2610988664627075\n",
      "loss 0.5266085988283158\n",
      "loss 0.7924678766727448\n",
      "loss 1.0637288244068623\n",
      "loss 1.3389379009604454\n",
      "loss 1.6132766918838024\n",
      "loss 1.883105557113886\n",
      "loss 2.157638591974974\n",
      "loss 2.433590202629566\n",
      "loss 2.7113162304461\n",
      "loss 2.991237336546183\n",
      "loss 3.2830071464180945\n",
      "loss 3.5641582368314264\n",
      "loss 3.84670461460948\n",
      "loss 4.137192852497101\n",
      "loss 4.425850005596876\n",
      "loss 4.71025103405118\n",
      "loss 4.992469907850027\n",
      "loss 5.282143838107586\n",
      "loss 5.570666878968478\n",
      "loss 5.867996926307678\n",
      "loss 6.15750894650817\n",
      "loss 6.454058835059405\n",
      "loss 6.747447736263275\n",
      "loss 7.044192573428154\n",
      "loss 7.352042504251004\n",
      "loss 7.653494943231344\n",
      "loss 7.960789511054754\n",
      "loss 8.270975143909455\n",
      "loss 8.577720677405596\n",
      "loss 8.887670590728522\n",
      "loss 9.209833710342645\n",
      "loss 9.520015293210745\n",
      "loss 9.837557912021875\n",
      "loss 10.14871353790164\n",
      "loss 10.464203124642372\n",
      "loss 10.77966679289937\n",
      "Epoch:  44\n",
      "training loss =  0.29143290380068726\n",
      "loss 0.2562499098479748\n",
      "loss 0.5083719004690647\n",
      "loss 0.7704815500974656\n",
      "loss 1.0379090318083763\n",
      "loss 1.3061799910664558\n",
      "loss 1.5742730149626731\n",
      "loss 1.8370409958064555\n",
      "loss 2.108945256471634\n",
      "loss 2.3797928473353385\n",
      "loss 2.6485490521788595\n",
      "loss 2.934430896192789\n",
      "loss 3.204958405047655\n",
      "loss 3.490398408174515\n",
      "loss 3.762616248726845\n",
      "loss 4.049772090017796\n",
      "loss 4.318397251218557\n",
      "loss 4.598372375220061\n",
      "loss 4.885269052386284\n",
      "loss 5.16587493956089\n",
      "loss 5.462876812070608\n",
      "loss 5.760833751261234\n",
      "loss 6.050412363409996\n",
      "loss 6.3399847313761715\n",
      "loss 6.628120357692242\n",
      "loss 6.911994209736585\n",
      "loss 7.209477849155665\n",
      "loss 7.506100471615792\n",
      "loss 7.806817479431629\n",
      "loss 8.11216764524579\n",
      "loss 8.417673685103654\n",
      "loss 8.719244132488965\n",
      "loss 9.024590169042348\n",
      "loss 9.329501633942128\n",
      "loss 9.633788066208362\n",
      "loss 9.934243214428426\n",
      "loss 10.23285678178072\n",
      "loss 10.542749200910329\n",
      "Epoch:  45\n",
      "training loss =  0.285005987683396\n",
      "loss 0.253007672727108\n",
      "loss 0.5089648672938347\n",
      "loss 0.7572274264693261\n",
      "loss 1.012050704807043\n",
      "loss 1.2641914363205433\n",
      "loss 1.5233014136552812\n",
      "loss 1.7816008715331555\n",
      "loss 2.049212988615036\n",
      "loss 2.3059577581286432\n",
      "loss 2.5763679626584053\n",
      "loss 2.8440550163388254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 3.1146786990761757\n",
      "loss 3.394480284899473\n",
      "loss 3.672158421278\n",
      "loss 3.94680919572711\n",
      "loss 4.219596837311983\n",
      "loss 4.492508406788111\n",
      "loss 4.775653813332319\n",
      "loss 5.057414205819368\n",
      "loss 5.346147809177637\n",
      "loss 5.633909670114517\n",
      "loss 5.921294278651476\n",
      "loss 6.199456808567047\n",
      "loss 6.494273094683885\n",
      "loss 6.780516329705716\n",
      "loss 7.064846346527338\n",
      "loss 7.35474127754569\n",
      "loss 7.648730367571115\n",
      "loss 7.936148201525211\n",
      "loss 8.22388472482562\n",
      "loss 8.527654289454222\n",
      "loss 8.824265553802253\n",
      "loss 9.124786255508662\n",
      "loss 9.417662395387888\n",
      "loss 9.718246041834355\n",
      "loss 10.010088170617818\n",
      "loss 10.307942112982273\n",
      "Epoch:  46\n",
      "training loss =  0.2787248205633732\n",
      "Validation Loss: 1.5856\tTop 1 Validation Accuracy: 0.7830\t Top 5 Validation Accuracy: 0.8884\n",
      "loss 0.24646517738699913\n",
      "loss 0.4923646755516529\n",
      "loss 0.7434503522515297\n",
      "loss 1.0046029917895793\n",
      "loss 1.2605329695343972\n",
      "loss 1.513528638780117\n",
      "loss 1.7733641405403615\n",
      "loss 2.0328035731613636\n",
      "loss 2.2965747593343258\n",
      "loss 2.5562646560370923\n",
      "loss 2.8216954186558723\n",
      "loss 3.0942284196615217\n",
      "loss 3.359064452499151\n",
      "loss 3.6288842903077603\n",
      "loss 3.9081010380387307\n",
      "loss 4.173374896794558\n",
      "loss 4.44630051150918\n",
      "loss 4.723705124258995\n",
      "loss 4.994027491062879\n",
      "loss 5.264340580403805\n",
      "loss 5.542635056823492\n",
      "loss 5.8204442608356475\n",
      "loss 6.100153723657131\n",
      "loss 6.379028521627188\n",
      "loss 6.660175701677799\n",
      "loss 6.937360509186983\n",
      "loss 7.22525726750493\n",
      "loss 7.516420221477747\n",
      "loss 7.805839097052813\n",
      "loss 8.089247794896364\n",
      "loss 8.393760629445314\n",
      "loss 8.68307800129056\n",
      "loss 8.978593938499689\n",
      "loss 9.280390981584787\n",
      "loss 9.579296488463878\n",
      "loss 9.880364101678133\n",
      "loss 10.181894578039646\n",
      "Epoch:  47\n",
      "training loss =  0.2752613717971994\n",
      "loss 0.23900151059031485\n",
      "loss 0.48451141953468324\n",
      "loss 0.7351154474914074\n",
      "loss 0.9818844774365425\n",
      "loss 1.2310844807326793\n",
      "loss 1.487944229543209\n",
      "loss 1.7484937684237958\n",
      "loss 2.00597374856472\n",
      "loss 2.2712629795074464\n",
      "loss 2.5313634780049323\n",
      "loss 2.784848184287548\n",
      "loss 3.0569322589039802\n",
      "loss 3.314313689619303\n",
      "loss 3.5851696956157686\n",
      "loss 3.8472069405019282\n",
      "loss 4.10653045937419\n",
      "loss 4.37070544809103\n",
      "loss 4.635375385433435\n",
      "loss 4.9042436872422694\n",
      "loss 5.174473145902157\n",
      "loss 5.452170062810183\n",
      "loss 5.724284306317568\n",
      "loss 6.008518328666687\n",
      "loss 6.292306135296822\n",
      "loss 6.569372796267271\n",
      "loss 6.85031888589263\n",
      "loss 7.134119545817375\n",
      "loss 7.420716974288225\n",
      "loss 7.70579172372818\n",
      "loss 7.997919580191374\n",
      "loss 8.282047356665135\n",
      "loss 8.559656732827426\n",
      "loss 8.85399483397603\n",
      "loss 9.148552950024605\n",
      "loss 9.44095538586378\n",
      "loss 9.731962981671096\n",
      "loss 10.030844437479972\n",
      "Epoch:  48\n",
      "training loss =  0.2712347427886035\n",
      "loss 0.2353034582734108\n",
      "loss 0.4803131748735905\n",
      "loss 0.728301821500063\n",
      "loss 0.9766384449601173\n",
      "loss 1.226458714455366\n",
      "loss 1.4722882443666458\n",
      "loss 1.7191526120901108\n",
      "loss 1.970492233633995\n",
      "loss 2.2259885258972645\n",
      "loss 2.479326969832182\n",
      "loss 2.72945988714695\n",
      "loss 2.990270285606384\n",
      "loss 3.258276741206646\n",
      "loss 3.5208363842964174\n",
      "loss 3.777307495325804\n",
      "loss 4.042933778315782\n",
      "loss 4.310772189050913\n",
      "loss 4.575928285866976\n",
      "loss 4.844485633969307\n",
      "loss 5.1180065900087355\n",
      "loss 5.383078244030475\n",
      "loss 5.65335304632783\n",
      "loss 5.933441854268312\n",
      "loss 6.20877975910902\n",
      "loss 6.485404144525528\n",
      "loss 6.76536765575409\n",
      "loss 7.05143379420042\n",
      "loss 7.334717463552952\n",
      "loss 7.615027501881123\n",
      "loss 7.887671002447605\n",
      "loss 8.182412046045066\n",
      "loss 8.458610700517893\n",
      "loss 8.756748926639556\n",
      "loss 9.049058539420367\n",
      "loss 9.337185002863407\n",
      "loss 9.63007422208786\n",
      "loss 9.916826608479022\n",
      "Epoch:  49\n",
      "training loss =  0.26810009543597296\n",
      "loss 0.23753638982772826\n",
      "loss 0.47812196373939514\n",
      "loss 0.7224914434552193\n",
      "loss 0.9687969322502613\n",
      "loss 1.2097633361816407\n",
      "loss 1.4477883884310723\n",
      "loss 1.6836688044667243\n",
      "loss 1.9311614000797273\n",
      "loss 2.1770168870687483\n",
      "loss 2.4241400077939033\n",
      "loss 2.687201951742172\n",
      "loss 2.942153545022011\n",
      "loss 3.2044344444572928\n",
      "loss 3.4628571002185344\n",
      "loss 3.7224946829676626\n",
      "loss 3.9774866169691085\n",
      "loss 4.2415447163581845\n",
      "loss 4.506461955606937\n",
      "loss 4.7710799372196195\n",
      "loss 5.043318345844746\n",
      "loss 5.309745535105467\n",
      "loss 5.5811711211502555\n",
      "loss 5.85287840694189\n",
      "loss 6.121839783191681\n",
      "loss 6.392634312659502\n",
      "loss 6.665240648686886\n",
      "loss 6.943571250140667\n",
      "loss 7.216272877603769\n",
      "loss 7.4981978784501555\n",
      "loss 7.7773006726801395\n",
      "loss 8.068175582140684\n",
      "loss 8.355976417809725\n",
      "loss 8.640116661339999\n",
      "loss 8.92362333908677\n",
      "loss 9.200621043145656\n",
      "loss 9.493182734251022\n",
      "loss 9.78077536523342\n",
      "Epoch:  50\n",
      "training loss =  0.26440392465950957\n",
      "loss 0.23422265261411668\n",
      "loss 0.47065577819943427\n",
      "loss 0.7076987788081169\n",
      "loss 0.9467704582214356\n",
      "loss 1.1859802988171577\n",
      "loss 1.4274547703564167\n",
      "loss 1.6712186709046364\n",
      "loss 1.9156989578902721\n",
      "loss 2.1641065433621405\n",
      "loss 2.4191204500198364\n",
      "loss 2.6704253646731377\n",
      "loss 2.926538749784231\n",
      "loss 3.181453673392534\n",
      "loss 3.4360052777826784\n",
      "loss 3.690404134839773\n",
      "loss 3.948225056231022\n",
      "loss 4.212086423784495\n",
      "loss 4.471409255117178\n",
      "loss 4.736689835935831\n",
      "loss 5.009698667675257\n",
      "loss 5.275278813093901\n",
      "loss 5.538847169876099\n",
      "loss 5.808766242861748\n",
      "loss 6.078668557703495\n",
      "loss 6.345354449450969\n",
      "loss 6.620351650267839\n",
      "loss 6.894377691745758\n",
      "loss 7.178048423826694\n",
      "loss 7.4672888690233234\n",
      "loss 7.743427029550076\n",
      "loss 8.023172739297152\n",
      "loss 8.309627299308778\n",
      "loss 8.585327440053225\n",
      "loss 8.869929510354996\n",
      "loss 9.157794790267944\n",
      "loss 9.440090817511082\n",
      "loss 9.727791589945555\n",
      "Epoch:  51\n",
      "training loss =  0.2629572220622995\n",
      "loss 0.22703133299946784\n",
      "loss 0.45800556004047394\n",
      "loss 0.6901214064657688\n",
      "loss 0.925803837031126\n",
      "loss 1.1624517081677914\n",
      "loss 1.4065221467614173\n",
      "loss 1.649400628656149\n",
      "loss 1.8800909543037414\n",
      "loss 2.1228921614587306\n",
      "loss 2.378022878319025\n",
      "loss 2.623560773283243\n",
      "loss 2.874529758542776\n",
      "loss 3.123428531289101\n",
      "loss 3.374468283802271\n",
      "loss 3.6312641759216784\n",
      "loss 3.8925284153223036\n",
      "loss 4.154501851499081\n",
      "loss 4.411849954873324\n",
      "loss 4.662644789218903\n",
      "loss 4.925594852119684\n",
      "loss 5.18352769061923\n",
      "loss 5.4506566943228245\n",
      "loss 5.718092561662197\n",
      "loss 5.9877957747876644\n",
      "loss 6.254661680758\n",
      "loss 6.523529904335737\n",
      "loss 6.792514472901821\n",
      "loss 7.059421925991773\n",
      "loss 7.340196073949337\n",
      "loss 7.618982553780079\n",
      "loss 7.905564204752445\n",
      "loss 8.187693665921689\n",
      "loss 8.475800714492799\n",
      "loss 8.758703213334083\n",
      "loss 9.04570487305522\n",
      "loss 9.331664610952139\n",
      "loss 9.617091657817364\n",
      "Epoch:  52\n",
      "training loss =  0.26005423386559384\n",
      "loss 0.22710767045617103\n",
      "loss 0.46334132581949233\n",
      "loss 0.696685325652361\n",
      "loss 0.9264607274532318\n",
      "loss 1.1642262807488442\n",
      "loss 1.4009322853386401\n",
      "loss 1.6386655759811402\n",
      "loss 1.8774134857952596\n",
      "loss 2.118339900970459\n",
      "loss 2.359231534898281\n",
      "loss 2.6029972943663595\n",
      "loss 2.8526759827136994\n",
      "loss 3.099102770537138\n",
      "loss 3.351999996304512\n",
      "loss 3.606620137244463\n",
      "loss 3.8589527367055414\n",
      "loss 4.117477361112833\n",
      "loss 4.375418911874294\n",
      "loss 4.628279794752598\n",
      "loss 4.8851552937924865\n",
      "loss 5.149440374821425\n",
      "loss 5.414140684902668\n",
      "loss 5.6828779865801335\n",
      "loss 5.952869754880667\n",
      "loss 6.220818694233895\n",
      "loss 6.489630441069603\n",
      "loss 6.762277123332024\n",
      "loss 7.0370154148340225\n",
      "loss 7.3106470900774\n",
      "loss 7.591115174889564\n",
      "loss 7.870241289883852\n",
      "loss 8.152405692636966\n",
      "loss 8.432540694326162\n",
      "loss 8.708097558766603\n",
      "loss 8.99108818128705\n",
      "loss 9.281025721281766\n",
      "loss 9.568692840486765\n",
      "Epoch:  53\n",
      "training loss =  0.2587298417400085\n",
      "loss 0.22306195162236692\n",
      "loss 0.4511473984271288\n",
      "loss 0.6788141415268183\n",
      "loss 0.9131836236268281\n",
      "loss 1.148100897744298\n",
      "loss 1.3861897506564855\n",
      "loss 1.6257832960039378\n",
      "loss 1.865078913345933\n",
      "loss 2.1048898474127054\n",
      "loss 2.351628627404571\n",
      "loss 2.599347944185138\n",
      "loss 2.8476138732582332\n",
      "loss 3.100389875099063\n",
      "loss 3.3530518474429845\n",
      "loss 3.598395867869258\n",
      "loss 3.8474576532095672\n",
      "loss 4.105250791087746\n",
      "loss 4.362571211978793\n",
      "loss 4.62685601182282\n",
      "loss 4.8820882297307255\n",
      "loss 5.144843405708671\n",
      "loss 5.402122839316726\n",
      "loss 5.666687056496739\n",
      "loss 5.9259734497219325\n",
      "loss 6.1906569532305005\n",
      "loss 6.462804420664907\n",
      "loss 6.734841853752732\n",
      "loss 7.004852959886193\n",
      "loss 7.276863612309098\n",
      "loss 7.548578405156731\n",
      "loss 7.833350873962044\n",
      "loss 8.108616983219981\n",
      "loss 8.386059094145894\n",
      "loss 8.670004640892149\n",
      "loss 8.954287728741765\n",
      "loss 9.23782834611833\n",
      "loss 9.523423525169491\n",
      "Epoch:  54\n",
      "training loss =  0.2574700659232896\n",
      "loss 0.2273273730278015\n",
      "loss 0.45291080251336097\n",
      "loss 0.6812197650969029\n",
      "loss 0.9104977111518383\n",
      "loss 1.1460713711380959\n",
      "loss 1.3774394051730632\n",
      "loss 1.6068202416598796\n",
      "loss 1.8502077302336692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.090391447395086\n",
      "loss 2.32462229013443\n",
      "loss 2.5625709185004233\n",
      "loss 2.804404816031456\n",
      "loss 3.054155566841364\n",
      "loss 3.2991980651021002\n",
      "loss 3.544527078270912\n",
      "loss 3.79092263430357\n",
      "loss 4.04534061089158\n",
      "loss 4.296034253686667\n",
      "loss 4.548729721009732\n",
      "loss 4.809927303642034\n",
      "loss 5.0619186639785765\n",
      "loss 5.3245133888721465\n",
      "loss 5.591700306385755\n",
      "loss 5.85652251586318\n",
      "loss 6.113996158540249\n",
      "loss 6.383989661484957\n",
      "loss 6.659883319586515\n",
      "loss 6.931688933968544\n",
      "loss 7.2058311074972154\n",
      "loss 7.487305631041527\n",
      "loss 7.758959697186947\n",
      "loss 8.035123758465051\n",
      "loss 8.319995034486055\n",
      "loss 8.598574120253325\n",
      "loss 8.874898278266192\n",
      "loss 9.154906468242407\n",
      "loss 9.441548344492912\n",
      "Epoch:  55\n",
      "training loss =  0.25528762673058214\n",
      "loss 0.23252053841948508\n",
      "loss 0.45741367429494856\n",
      "loss 0.68839320525527\n",
      "loss 0.9152012199163437\n",
      "loss 1.1503911715745927\n",
      "loss 1.3786566184461118\n",
      "loss 1.6184058578312397\n",
      "loss 2.3508025594055653\n",
      "loss 2.5999912545084953\n",
      "loss 2.8420196236670017\n",
      "loss 3.0829634638130665\n",
      "loss 3.332285014241934\n",
      "loss 3.569790160804987\n",
      "loss 3.8249185767769815\n",
      "loss 4.071878522932529\n",
      "loss 4.3277963815629485\n",
      "loss 4.5854195381700995\n",
      "loss 4.8449519951641555\n",
      "loss 5.104352365285158\n",
      "loss 5.366365868747234\n",
      "loss 5.634543693959713\n",
      "loss 5.899003773331642\n",
      "loss 6.160282035470009\n",
      "loss 6.422217116951942\n",
      "loss 6.6897841414809225\n",
      "loss 6.95711266219616\n",
      "loss 7.226410326361656\n",
      "loss 7.495182534903288\n",
      "loss 7.76694233417511\n",
      "loss 8.041070807278157\n",
      "loss 8.314300872981548\n",
      "loss 8.586931085735559\n",
      "loss 8.86932956457138\n",
      "loss 9.151998800337315\n",
      "loss 9.43108491331339\n",
      "Epoch:  56\n",
      "training loss =  0.25504636104485723\n",
      "loss 0.2188558892905712\n",
      "loss 0.4413399812579155\n",
      "loss 0.6634029626846314\n",
      "loss 0.8976364664733409\n",
      "loss 1.1297875933349133\n",
      "loss 1.3593004004657268\n",
      "loss 1.5868783220648766\n",
      "loss 1.8200132367014885\n",
      "loss 2.0560388079285623\n",
      "loss 2.289225562363863\n",
      "loss 2.5315951783955097\n",
      "loss 2.775385630875826\n",
      "loss 3.019427991360426\n",
      "loss 3.26342234224081\n",
      "loss 3.5062341441214087\n",
      "loss 3.758406342715025\n",
      "loss 4.006907299309969\n",
      "loss 4.258977094143629\n",
      "loss 4.5152782985568045\n",
      "loss 4.764154068976641\n",
      "loss 5.018358322679997\n",
      "loss 5.2799516125023365\n",
      "loss 5.540376100540161\n",
      "loss 5.805393626838923\n",
      "loss 6.0664459311962124\n",
      "loss 6.32755512803793\n",
      "loss 6.596197827607393\n",
      "loss 6.875861426144838\n",
      "loss 7.15271303743124\n",
      "loss 7.4257825255393985\n",
      "loss 7.7085104982554915\n",
      "loss 7.982160981744528\n",
      "loss 8.260297986716033\n",
      "loss 8.538351517170668\n",
      "loss 8.81987292960286\n",
      "loss 9.096753439158201\n",
      "loss 9.375335774421693\n",
      "Epoch:  57\n",
      "training loss =  0.2535703748440466\n",
      "loss 0.22345664948225022\n",
      "loss 0.4439244584739208\n",
      "loss 0.6702326725423337\n",
      "loss 0.8949788950383664\n",
      "loss 1.1253764817118646\n",
      "loss 1.357238419353962\n",
      "loss 1.5912191678583623\n",
      "loss 1.8240661863982677\n",
      "loss 2.0587400604784487\n",
      "loss 2.297376118451357\n",
      "loss 2.537961625903845\n",
      "loss 2.7750071646273136\n",
      "loss 3.018924643397331\n",
      "loss 3.2616149964928627\n",
      "loss 3.5090962690114975\n",
      "loss 3.763648584485054\n",
      "loss 4.017849776744843\n",
      "loss 4.261358899176121\n",
      "loss 4.515371793955564\n",
      "loss 4.768070820122957\n",
      "loss 5.022625141590834\n",
      "loss 5.277831483334303\n",
      "loss 5.54574598416686\n",
      "loss 5.804550683349371\n",
      "loss 6.068499775975942\n",
      "loss 6.3305170752108095\n",
      "loss 6.59526237398386\n",
      "loss 6.869751694947481\n",
      "loss 7.14448377251625\n",
      "loss 7.418384432941675\n",
      "loss 7.690354228019714\n",
      "loss 7.961074606031179\n",
      "loss 8.242859396040439\n",
      "loss 8.525427252948283\n",
      "loss 8.801976579129695\n",
      "loss 9.083093731552362\n",
      "loss 9.364402844458818\n",
      "Epoch:  58\n",
      "training loss =  0.25325940369289457\n",
      "loss 0.2231380209326744\n",
      "loss 0.45693703413009645\n",
      "loss 0.6816188180446625\n",
      "loss 0.9072854240238667\n",
      "loss 1.1410945945978164\n",
      "loss 1.3734979456663132\n",
      "loss 1.6044325855374337\n",
      "loss 1.8350753450393678\n",
      "loss 2.071935725361109\n",
      "loss 2.3053778809309007\n",
      "loss 2.5414624136686323\n",
      "loss 2.787016002237797\n",
      "loss 3.019471005052328\n",
      "loss 3.2599405224621294\n",
      "loss 3.51109113663435\n",
      "loss 3.755952634215355\n",
      "loss 4.005478710085153\n",
      "loss 4.256929229944944\n",
      "loss 4.506565952450037\n",
      "loss 4.764948496669531\n",
      "loss 5.02404827490449\n",
      "loss 5.279072385877371\n",
      "loss 5.545401199609041\n",
      "loss 5.81467039451003\n",
      "loss 6.074407887160778\n",
      "loss 6.335161072462797\n",
      "loss 6.594376299679279\n",
      "loss 6.864920997619629\n",
      "loss 7.1324253176152705\n",
      "loss 7.403752685636282\n",
      "loss 7.674130997210741\n",
      "loss 7.95099811181426\n",
      "loss 8.223780563175678\n",
      "loss 8.493817727863789\n",
      "loss 8.770610857009888\n",
      "loss 9.051905447691679\n",
      "loss 9.334206211715937\n",
      "Epoch:  59\n",
      "training loss =  0.2524149150363769\n",
      "loss 0.2264588087797165\n",
      "loss 0.4481000992655754\n",
      "loss 0.6750932951271534\n",
      "loss 0.900080637484789\n",
      "loss 1.1272896119952203\n",
      "loss 1.3607879687845708\n",
      "loss 1.5915581208467484\n",
      "loss 1.8224285362660886\n",
      "loss 2.0585111328959464\n",
      "loss 2.292688142955303\n",
      "loss 2.5348826639354227\n",
      "loss 2.7626680685579776\n",
      "loss 3.0028783357143403\n",
      "loss 3.2440119822323323\n",
      "loss 3.483498290628195\n",
      "loss 3.7275385364890097\n",
      "loss 3.979674658626318\n",
      "loss 4.226788866370916\n",
      "loss 4.479007119089365\n",
      "loss 4.732548101395369\n",
      "loss 4.986538174599409\n",
      "loss 5.240474410057068\n",
      "loss 5.4928174725174905\n",
      "loss 5.757242286205292\n",
      "loss 6.020602084845304\n",
      "loss 6.288143942207098\n",
      "loss 6.556052400916815\n",
      "loss 6.824020913243293\n",
      "loss 7.086572606414556\n",
      "loss 7.359434627592564\n",
      "loss 7.625695096701383\n",
      "loss 7.901302058845759\n",
      "loss 8.17107079014182\n",
      "loss 8.446694175750018\n",
      "loss 8.727678337395192\n",
      "loss 9.00999723419547\n",
      "loss 9.29586267516017\n",
      "Epoch:  60\n",
      "training loss =  0.2513097501609857\n",
      "loss 0.2133623667061329\n",
      "loss 0.4199496775865555\n",
      "loss 0.6178934116661549\n",
      "loss 0.8242269498109818\n",
      "loss 1.0208334217965602\n",
      "loss 1.2140212246775628\n",
      "loss 1.4056809523701668\n",
      "loss 1.5994267554581165\n",
      "loss 1.7896042105555534\n",
      "loss 1.9767652033269405\n",
      "loss 2.1658826149255037\n",
      "loss 2.3514908795803784\n",
      "loss 2.5354991122335195\n",
      "loss 3.2696058996766806\n",
      "loss 3.452755954042077\n",
      "loss 3.6393398450315\n",
      "loss 3.822100450694561\n",
      "loss 4.00247159563005\n",
      "loss 4.180291882306338\n",
      "loss 4.3631557961553336\n",
      "loss 4.542733289077878\n",
      "loss 4.723753757476807\n",
      "loss 4.9035305392742154\n",
      "loss 5.085162865966558\n",
      "loss 5.266043199449777\n",
      "loss 5.4496032409369946\n",
      "loss 5.630807018354535\n",
      "loss 5.810502590686083\n",
      "loss 5.988567969277501\n",
      "loss 6.164402599856257\n",
      "loss 6.343958732113242\n",
      "loss 6.518250431418419\n",
      "loss 6.694251044765115\n",
      "loss 6.871318849772215\n",
      "Epoch:  61\n",
      "training loss =  0.18572829785149536\n",
      "Validation Loss: 1.5169\tTop 1 Validation Accuracy: 0.7896\t Top 5 Validation Accuracy: 0.8917\n",
      "loss 0.17040380157530308\n",
      "loss 0.3423787312954664\n",
      "loss 0.5185426166653633\n",
      "loss 0.6850476742535829\n",
      "loss 0.8563881973177194\n",
      "loss 1.0281733151525259\n",
      "loss 1.2003628897666931\n",
      "loss 1.370863136574626\n",
      "loss 1.5384505910426378\n",
      "loss 1.7110292363911868\n",
      "loss 1.875154846906662\n",
      "loss 2.045247030258179\n",
      "loss 2.217686233893037\n",
      "loss 2.3870453122258186\n",
      "loss 2.5538283119350673\n",
      "loss 2.725697941556573\n",
      "loss 2.897148326933384\n",
      "loss 3.0648385303467514\n",
      "loss 3.2319539227336644\n",
      "loss 3.403351867645979\n",
      "loss 3.570991590321064\n",
      "loss 3.7397847452759745\n",
      "loss 3.9127235861867664\n",
      "loss 4.08109137520194\n",
      "loss 4.260222215428948\n",
      "loss 4.433644340634346\n",
      "loss 4.602848244532943\n",
      "loss 4.771720471978187\n",
      "loss 4.940761861279607\n",
      "loss 5.112621982246638\n",
      "loss 5.281880383267999\n",
      "loss 5.458842778950929\n",
      "loss 5.631366767808795\n",
      "loss 5.799342044815421\n",
      "loss 5.969082682877779\n",
      "loss 6.136339915543795\n",
      "loss 6.300262508913875\n",
      "Epoch:  62\n",
      "training loss =  0.17029408461559742\n",
      "loss 0.16101850539445878\n",
      "loss 0.3244745679944754\n",
      "loss 0.4980162217468023\n",
      "loss 0.66367890663445\n",
      "loss 0.8279321351647377\n",
      "loss 0.9905820351839065\n",
      "loss 1.1532260107249022\n",
      "loss 1.3189096578210593\n",
      "loss 1.4853627356141805\n",
      "loss 1.6469989027827978\n",
      "loss 1.8118152856081724\n",
      "loss 1.9781009249389172\n",
      "loss 2.141338359862566\n",
      "loss 2.3007677713781596\n",
      "loss 2.462596143037081\n",
      "loss 2.6267365308851005\n",
      "loss 2.800371610149741\n",
      "loss 2.9690823748707773\n",
      "loss 3.1336451930552722\n",
      "loss 3.296430145725608\n",
      "loss 3.4630416187644006\n",
      "loss 3.6312307102978227\n",
      "loss 3.7959585943818093\n",
      "loss 3.9553621765226126\n",
      "loss 4.119198306053877\n",
      "loss 4.2863627692312\n",
      "loss 4.450262558609247\n",
      "loss 4.611931678578258\n",
      "loss 4.774501218423247\n",
      "loss 4.94283213891089\n",
      "loss 5.112723175808787\n",
      "loss 5.280633728355169\n",
      "loss 5.449366589486599\n",
      "loss 5.617246744409203\n",
      "loss 5.786785158962012\n",
      "loss 5.9520446934551\n",
      "loss 6.1191267516464\n",
      "Epoch:  63\n",
      "training loss =  0.1654217916801833\n",
      "loss 0.1603723628073931\n",
      "loss 0.3193963634967804\n",
      "loss 0.4849606282263994\n",
      "loss 0.6520812539756298\n",
      "loss 0.8087469127774238\n",
      "loss 0.967713944464922\n",
      "loss 1.130659998729825\n",
      "loss 1.289528012648225\n",
      "loss 1.4532064016163349\n",
      "loss 1.6154462905973197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.779748572036624\n",
      "loss 1.9417951323837042\n",
      "loss 2.101785517707467\n",
      "loss 2.2673400706797837\n",
      "loss 2.434578724652529\n",
      "loss 2.594439801722765\n",
      "loss 2.756113144606352\n",
      "loss 2.915493797287345\n",
      "loss 3.0735065206885337\n",
      "loss 3.2373119912296535\n",
      "loss 3.3987549901008607\n",
      "loss 3.5611645413935182\n",
      "loss 3.7216333816200495\n",
      "loss 3.8894343770295383\n",
      "loss 4.050073188692331\n",
      "loss 4.211946157291532\n",
      "loss 4.371706754714251\n",
      "loss 4.532973541617394\n",
      "loss 4.701843018308282\n",
      "loss 4.866531304270029\n",
      "loss 5.033526525124907\n",
      "loss 5.194658487588168\n",
      "loss 5.358149928078055\n",
      "loss 5.5253525289148095\n",
      "loss 5.687301891446114\n",
      "loss 5.847854504287243\n",
      "loss 6.015645714700222\n",
      "Epoch:  64\n",
      "training loss =  0.162661213854879\n",
      "loss 0.15655201867222787\n",
      "loss 0.3111343666911125\n",
      "loss 0.4690967594832182\n",
      "loss 0.6286743869632483\n",
      "loss 0.7845834849029779\n",
      "loss 0.9381309378892183\n",
      "loss 1.0968880112469197\n",
      "loss 1.2552826633304357\n",
      "loss 1.4143654145300388\n",
      "loss 1.5758932679891586\n",
      "loss 1.7369725880026818\n",
      "loss 1.8918672478199006\n",
      "loss 2.0523073700070382\n",
      "loss 2.207760011702776\n",
      "loss 2.365371752381325\n",
      "loss 2.527803522348404\n",
      "loss 2.685969478785992\n",
      "loss 2.847747906297445\n",
      "loss 3.009729882776737\n",
      "loss 3.176567468121648\n",
      "loss 3.3368933067470787\n",
      "loss 3.496314342468977\n",
      "loss 3.6578979740291833\n",
      "loss 3.815663201659918\n",
      "loss 3.9774385771900413\n",
      "loss 4.1352356104552745\n",
      "loss 4.297728097066283\n",
      "loss 4.457959760203957\n",
      "loss 4.622273017391563\n",
      "loss 4.785819606930017\n",
      "loss 4.952031836211681\n",
      "loss 5.1092253062129025\n",
      "loss 5.270373487100005\n",
      "loss 5.433552768900991\n",
      "loss 5.590596701428294\n",
      "loss 5.753725368604064\n",
      "loss 5.913138194829226\n",
      "Epoch:  65\n",
      "training loss =  0.15987688343593107\n",
      "loss 0.15899347230792046\n",
      "loss 0.31849159456789494\n",
      "loss 0.47705249801278116\n",
      "loss 0.6325019209831954\n",
      "loss 0.7922772356122733\n",
      "loss 0.9491454441100359\n",
      "loss 1.108061869814992\n",
      "loss 1.2620994846522808\n",
      "loss 1.4175189673155546\n",
      "loss 1.5713470715284348\n",
      "loss 1.727004404142499\n",
      "loss 1.8832423661649227\n",
      "loss 2.0386647875607014\n",
      "loss 2.1964826680719853\n",
      "loss 2.3479425404965877\n",
      "loss 2.506618184223771\n",
      "loss 2.6632858503609897\n",
      "loss 2.827726744636893\n",
      "loss 2.9857602728158237\n",
      "loss 3.149133342951536\n",
      "loss 3.3077331117540596\n",
      "loss 3.463567394167185\n",
      "loss 3.619140859693289\n",
      "loss 3.78066369317472\n",
      "loss 3.9387387899309396\n",
      "loss 4.099762140437961\n",
      "loss 4.259201405346394\n",
      "loss 4.421950540989638\n",
      "loss 4.582275204584002\n",
      "loss 4.739334440976381\n",
      "loss 4.903913705050945\n",
      "loss 5.065081184357405\n",
      "loss 5.221592423021793\n",
      "loss 5.380349661409855\n",
      "loss 5.543432266190648\n",
      "loss 5.708550822883844\n",
      "loss 5.872493585497141\n",
      "Epoch:  66\n",
      "training loss =  0.15875773190133552\n",
      "loss 0.15263642840087413\n",
      "loss 0.3062093570828438\n",
      "loss 0.45930255636572836\n",
      "loss 0.6154684139043093\n",
      "loss 0.7683640865236521\n",
      "loss 0.9206047223508358\n",
      "loss 1.0747250659763814\n",
      "loss 1.2304493347555399\n",
      "loss 1.3818826771527528\n",
      "loss 1.5387373620271683\n",
      "loss 1.6944154153764248\n",
      "loss 1.848289348706603\n",
      "loss 2.0084674862027168\n",
      "loss 2.1637713622301815\n",
      "loss 2.3208386344462633\n",
      "loss 2.4833436720073223\n",
      "loss 2.636484729498625\n",
      "loss 2.7989990247040986\n",
      "loss 2.957526337206364\n",
      "loss 3.1160722065716984\n",
      "loss 3.2759636893123387\n",
      "loss 3.4360831095278264\n",
      "loss 3.5923883141577244\n",
      "loss 3.747202887684107\n",
      "loss 3.9063159989565612\n",
      "loss 4.067009518370032\n",
      "loss 4.225013527795673\n",
      "loss 4.380134518519044\n",
      "loss 4.53888729326427\n",
      "loss 4.701594536155462\n",
      "loss 4.860127459019423\n",
      "loss 5.021836134269834\n",
      "loss 5.182069850191474\n",
      "loss 5.337367654666305\n",
      "loss 5.494730252847075\n",
      "loss 5.654289336279034\n",
      "loss 5.819525654986501\n",
      "Epoch:  67\n",
      "training loss =  0.15734228086593757\n",
      "loss 0.15222903445363045\n",
      "loss 0.3037842767685652\n",
      "loss 0.4578607370704412\n",
      "loss 0.6062351952493191\n",
      "loss 0.7593472410738468\n",
      "loss 0.9108818371593952\n",
      "loss 1.067301557287574\n",
      "loss 1.217340667322278\n",
      "loss 1.3733793687820435\n",
      "loss 1.5260384454578162\n",
      "loss 1.6821457502245902\n",
      "loss 1.8393359012901782\n",
      "loss 1.994650908857584\n",
      "loss 2.1533423478156326\n",
      "loss 2.3090649642050267\n",
      "loss 2.465574183091521\n",
      "loss 2.6220917503535746\n",
      "loss 3.2555025655031202\n",
      "loss 3.4099375399947167\n",
      "loss 3.567093123793602\n",
      "loss 3.7298682945221664\n",
      "loss 3.891426764950156\n",
      "loss 4.049223032221198\n",
      "loss 4.200874787792563\n",
      "loss 4.360654912889004\n",
      "loss 4.520231421589852\n",
      "loss 4.675671368986368\n",
      "loss 4.832690878137946\n",
      "loss 4.990911022126674\n",
      "loss 5.147397054284811\n",
      "loss 5.309109167605638\n",
      "loss 5.463965946063399\n",
      "loss 5.622107155099511\n",
      "loss 5.781560117602348\n",
      "Epoch:  68\n",
      "training loss =  0.1563069460356303\n",
      "loss 0.15172183513641357\n",
      "loss 0.308901262357831\n",
      "loss 0.45881223551928996\n",
      "loss 0.6127289861440659\n",
      "loss 0.7665395546704531\n",
      "loss 0.9187785632908344\n",
      "loss 1.074212934449315\n",
      "loss 1.229806924983859\n",
      "loss 1.3850428077578545\n",
      "loss 1.5379219450801611\n",
      "loss 1.6950124821811914\n",
      "loss 1.8508409247547388\n",
      "loss 2.0079776463657617\n",
      "loss 2.16681326366961\n",
      "loss 2.3226325745880603\n",
      "loss 2.4800791055709124\n",
      "loss 2.636514875218272\n",
      "loss 2.789316670894623\n",
      "loss 2.9533834134787322\n",
      "loss 3.1059095847606657\n",
      "loss 3.267416690811515\n",
      "loss 3.4252336479723455\n",
      "loss 3.578536513671279\n",
      "loss 3.733065156787634\n",
      "loss 3.891209543272853\n",
      "loss 4.043597269058227\n",
      "loss 4.2007068150490525\n",
      "loss 4.358437633812428\n",
      "loss 4.516960631832481\n",
      "loss 4.6725581365078686\n",
      "loss 4.833497793674469\n",
      "loss 4.985794523581863\n",
      "loss 5.1441176185756925\n",
      "loss 5.299765646159649\n",
      "loss 5.457947329133749\n",
      "loss 5.6168029530346395\n",
      "loss 5.774583537206054\n",
      "Epoch:  69\n",
      "training loss =  0.15604237380425243\n",
      "loss 0.15920325204730035\n",
      "loss 0.3132296700775623\n",
      "loss 0.46827316328883173\n",
      "loss 0.6230496089160442\n",
      "loss 0.7753190253674984\n",
      "loss 0.9331681507825852\n",
      "loss 1.086772497445345\n",
      "loss 1.2391552618145942\n",
      "loss 1.393589611798525\n",
      "loss 1.544128524363041\n",
      "loss 1.7016506923735142\n",
      "loss 1.8567093805968762\n",
      "loss 2.0107832274585964\n",
      "loss 2.1735134129971265\n",
      "loss 2.3287334985286\n",
      "loss 2.4808531355112793\n",
      "loss 2.635297318994999\n",
      "loss 2.79253596611321\n",
      "loss 2.94861569955945\n",
      "loss 3.104245183095336\n",
      "loss 3.258910980671644\n",
      "loss 3.4161128748208283\n",
      "loss 3.571155299767852\n",
      "loss 3.7272084644436836\n",
      "loss 3.884911266490817\n",
      "loss 4.0444355245679615\n",
      "loss 4.199796075075865\n",
      "loss 4.355537260621786\n",
      "loss 4.511630388200283\n",
      "loss 4.672430826723575\n",
      "loss 4.830821116790175\n",
      "loss 4.989595535174012\n",
      "loss 5.144807991161943\n",
      "loss 5.302024536952376\n",
      "loss 5.464211936295032\n",
      "loss 5.622083612903952\n",
      "loss 5.775465242564678\n",
      "Epoch:  70\n",
      "training loss =  0.15612730246398016\n",
      "loss 0.1510464933514595\n",
      "loss 0.30398697063326835\n",
      "loss 0.456024949029088\n",
      "loss 0.6045719268918037\n",
      "loss 0.758064571917057\n",
      "loss 0.9113080701231957\n",
      "loss 1.0656016022711992\n",
      "loss 1.21926156334579\n",
      "loss 1.3731287205964327\n",
      "loss 1.5266208221018314\n",
      "loss 1.6782068697363137\n",
      "loss 1.8324510723352432\n",
      "loss 1.9845585442334412\n",
      "loss 2.140907103344798\n",
      "loss 2.2952021843194963\n",
      "loss 2.4478460043668746\n",
      "loss 2.6011802197992804\n",
      "loss 2.7540799349546434\n",
      "loss 2.9081211514770984\n",
      "loss 3.0612923535704613\n",
      "loss 3.2157758785039188\n",
      "loss 3.3713931292295456\n",
      "loss 3.5243330994993447\n",
      "loss 3.6834404616057874\n",
      "loss 3.8367703488469123\n",
      "loss 3.997832406833768\n",
      "loss 4.151215635389089\n",
      "loss 4.305288982540369\n",
      "loss 4.463635163530707\n",
      "loss 4.617340211942792\n",
      "loss 4.775749652311206\n",
      "loss 4.9348434264957906\n",
      "loss 5.087198804691434\n",
      "loss 5.241679187119007\n",
      "loss 5.397080596536398\n",
      "loss 5.554865129068494\n",
      "loss 5.712578387930989\n",
      "Epoch:  71\n",
      "training loss =  0.1544030359231432\n",
      "loss 0.15355701893568038\n",
      "loss 0.30651669412851335\n",
      "loss 0.45472450703382494\n",
      "loss 0.6043351479619742\n",
      "loss 0.7548576141893864\n",
      "loss 0.906522065103054\n",
      "loss 1.062211008220911\n",
      "loss 1.2110081146657468\n",
      "loss 1.364927718937397\n",
      "loss 1.5169481863826513\n",
      "loss 1.6727740472555161\n",
      "loss 1.8224450638145209\n",
      "loss 1.9743208196759223\n",
      "loss 2.126624838784337\n",
      "loss 2.2808234339952467\n",
      "loss 2.438881079852581\n",
      "loss 2.599264654144645\n",
      "loss 2.7568555469810962\n",
      "loss 2.9128069115430115\n",
      "loss 3.0689177487790587\n",
      "loss 3.227525207921863\n",
      "loss 3.385083238184452\n",
      "loss 3.543013245165348\n",
      "loss 3.7046377409994604\n",
      "loss 3.8600091165304184\n",
      "loss 4.017007646933198\n",
      "loss 4.169593398347497\n",
      "loss 4.324998032450676\n",
      "loss 4.485097953081131\n",
      "loss 4.642027978301048\n",
      "loss 4.794033255055547\n",
      "loss 4.950321198776364\n",
      "loss 5.108803004026413\n",
      "loss 5.2650088211894035\n",
      "loss 5.417980771362782\n",
      "loss 5.571445797905326\n",
      "loss 5.729780038818717\n",
      "Epoch:  72\n",
      "training loss =  0.15490936903151856\n",
      "loss 0.15506757721304892\n",
      "loss 0.31199089258909224\n",
      "loss 0.4677803909778595\n",
      "loss 0.6198985417187214\n",
      "loss 0.7695716035366058\n",
      "loss 0.9223687385767698\n",
      "loss 1.0704990506917238\n",
      "loss 1.2249488708376886\n",
      "loss 1.372989865988493\n",
      "loss 1.5272056978940964\n",
      "loss 1.6781690079718827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.8323039513081312\n",
      "loss 1.9824500011652708\n",
      "loss 2.1424341678619383\n",
      "loss 2.294776003211737\n",
      "loss 2.4496583986282348\n",
      "loss 2.6051884452998637\n",
      "loss 2.7567558823525906\n",
      "loss 2.9093361262977124\n",
      "loss 3.063253084719181\n",
      "loss 3.2192227120697496\n",
      "loss 3.3748070269823076\n",
      "loss 3.5260465149581433\n",
      "loss 3.679652794599533\n",
      "loss 3.8377847211062908\n",
      "loss 3.9972540182620286\n",
      "loss 4.149935810789466\n",
      "loss 4.311393974348903\n",
      "loss 4.463993237987161\n",
      "loss 4.621640420854091\n",
      "loss 4.7797483130544425\n",
      "loss 4.93693053945899\n",
      "loss 5.090696852356196\n",
      "loss 5.245338017120957\n",
      "loss 5.398237261027098\n",
      "loss 5.5554820063710215\n",
      "loss 5.715043444111943\n",
      "Epoch:  73\n",
      "training loss =  0.15450391251144624\n",
      "loss 0.15152169704437257\n",
      "loss 0.30501332513988016\n",
      "loss 0.4589983384311199\n",
      "loss 0.6096422991901637\n",
      "loss 0.7628129652142525\n",
      "loss 0.9136831606924534\n",
      "loss 1.0663633058965205\n",
      "loss 1.2133991212397814\n",
      "loss 1.3656066562235356\n",
      "loss 1.5213112246245146\n",
      "loss 1.6758192351460457\n",
      "loss 1.8304433668404818\n",
      "loss 1.9814988654851913\n",
      "loss 2.134392917230725\n",
      "loss 2.285561487227678\n",
      "loss 2.4389229672402144\n",
      "loss 2.598652847111225\n",
      "loss 2.7484187220782044\n",
      "loss 2.904344626814127\n",
      "loss 3.063023827075958\n",
      "loss 3.219200026914477\n",
      "loss 3.371966495960951\n",
      "loss 3.526616784259677\n",
      "loss 3.6841299887746572\n",
      "loss 3.839257782548666\n",
      "loss 3.9938242289423944\n",
      "loss 4.14923476703465\n",
      "loss 4.306750455275178\n",
      "loss 4.462071331813932\n",
      "loss 4.6214546336978675\n",
      "loss 4.775649011731148\n",
      "loss 4.936426591202617\n",
      "loss 5.0922327482700345\n",
      "loss 5.248256427422166\n",
      "loss 5.406036588922143\n",
      "loss 5.561781770512462\n",
      "loss 5.717770971208811\n",
      "Epoch:  74\n",
      "training loss =  0.15451297133413325\n",
      "loss 0.1500600949674845\n",
      "loss 0.2969091707468033\n",
      "loss 0.44531395167112353\n",
      "loss 0.5992538163810969\n",
      "loss 0.7513809572160244\n",
      "loss 0.9001869244873524\n",
      "loss 1.048007456958294\n",
      "loss 1.201373070627451\n",
      "loss 1.3576490789651872\n",
      "loss 1.511850492209196\n",
      "loss 1.6649782017618417\n",
      "loss 1.8196534280478955\n",
      "loss 1.9769641705602408\n",
      "loss 2.1277546517550947\n",
      "loss 2.2844135046005247\n",
      "loss 2.439718782231212\n",
      "loss 2.599098123535514\n",
      "loss 2.75558972209692\n",
      "loss 2.9157188321650027\n",
      "loss 3.069286187291145\n",
      "loss 3.22164125867188\n",
      "loss 3.3744688149541617\n",
      "loss 3.525906260088086\n",
      "loss 3.6817823302000763\n",
      "loss 3.83982335396111\n",
      "loss 3.9942244856804607\n",
      "loss 4.15360316760838\n",
      "loss 4.307133276835084\n",
      "loss 4.465183313786984\n",
      "loss 4.621316147223115\n",
      "loss 4.780198929533363\n",
      "loss 4.934774524718523\n",
      "loss 5.090506705194712\n",
      "loss 5.245558337271214\n",
      "loss 5.403388184681535\n",
      "loss 5.554995210245251\n",
      "loss 5.713339210301638\n",
      "Epoch:  75\n",
      "training loss =  0.15445298079671582\n",
      "loss 0.15339559637010097\n",
      "loss 0.3039087477326393\n",
      "loss 0.45855711579322816\n",
      "loss 0.6088510300964117\n",
      "loss 0.7556985300034285\n",
      "loss 0.9089632086455822\n",
      "loss 1.0644545885920524\n",
      "loss 1.216371003985405\n",
      "loss 1.3653930766880513\n",
      "loss 1.5192602724581956\n",
      "loss 1.6733403856307267\n",
      "loss 1.824472021535039\n",
      "loss 1.9751328690350056\n",
      "loss 2.133525112196803\n",
      "loss 2.2898671336472036\n",
      "loss 2.4447159991413354\n",
      "loss 2.596608673855662\n",
      "loss 2.750649281293154\n",
      "loss 2.901464523598552\n",
      "loss 3.0582759997248647\n",
      "loss 3.2106408677995204\n",
      "loss 3.3683311174064876\n",
      "loss 3.525306626111269\n",
      "loss 3.681254043951631\n",
      "loss 3.836223197504878\n",
      "loss 3.991037129536271\n",
      "loss 4.148288766145706\n",
      "loss 4.304526986181736\n",
      "loss 4.463552166521549\n",
      "loss 4.615905142128468\n",
      "loss 4.770099068656564\n",
      "loss 4.922161000669003\n",
      "loss 5.07898216329515\n",
      "loss 5.2320922312885525\n",
      "loss 5.392173727601767\n",
      "loss 5.550059227496385\n",
      "loss 5.708053507357835\n",
      "Epoch:  76\n",
      "training loss =  0.15426740861498572\n",
      "Validation Loss: 1.4949\tTop 1 Validation Accuracy: 0.7914\t Top 5 Validation Accuracy: 0.8924\n",
      "loss 0.15075551941990853\n",
      "loss 0.3007699689269066\n",
      "loss 0.4532478403300047\n",
      "loss 0.6050080870836974\n",
      "loss 0.756892055645585\n",
      "loss 0.9089227309823036\n",
      "loss 1.0668177967518568\n",
      "loss 1.2185443231463433\n",
      "loss 1.3695852317661048\n",
      "loss 1.5217916994541882\n",
      "loss 1.6708223109692335\n",
      "loss 1.8215084281563758\n",
      "loss 1.9803002588450909\n",
      "loss 2.13538535900414\n",
      "loss 2.2854534436017273\n",
      "loss 2.434768074154854\n",
      "loss 2.5876348044723274\n",
      "loss 2.7381545066833497\n",
      "loss 2.8928370738774536\n",
      "loss 3.045751814395189\n",
      "loss 3.2014891521632673\n",
      "loss 3.3539808637648822\n",
      "loss 3.5018264345824717\n",
      "loss 3.6536285105347632\n",
      "loss 3.8082157461345196\n",
      "loss 3.963379547521472\n",
      "loss 4.119665173888206\n",
      "loss 4.277985582277179\n",
      "loss 4.432658470347524\n",
      "loss 4.586986446604133\n",
      "loss 4.745032735615968\n",
      "loss 4.898151725456119\n",
      "loss 5.053241448998452\n",
      "loss 5.210948835238814\n",
      "loss 5.371015648394823\n",
      "loss 5.5241705641895535\n",
      "loss 5.677017695009709\n",
      "Epoch:  77\n",
      "training loss =  0.15350682681337469\n",
      "loss 0.15329354733228684\n",
      "loss 0.30610538758337497\n",
      "loss 0.45629638366401193\n",
      "loss 0.6059707863628865\n",
      "loss 0.7554778457432986\n",
      "loss 0.904744453728199\n",
      "loss 1.0529609487205744\n",
      "loss 1.2071830841898918\n",
      "loss 1.3599566060304642\n",
      "loss 1.515119120106101\n",
      "loss 1.6661683662980795\n",
      "loss 1.818713815063238\n",
      "loss 1.9722369635850192\n",
      "loss 2.125074485242367\n",
      "loss 2.2804580503702163\n",
      "loss 2.435186319127679\n",
      "loss 2.5938305094838143\n",
      "loss 2.7491071310639383\n",
      "loss 2.9077300741523504\n",
      "loss 3.0611639603972436\n",
      "loss 3.2148763796687128\n",
      "loss 3.367609934285283\n",
      "loss 3.5239287215471267\n",
      "loss 3.6758850666135547\n",
      "loss 3.830054809525609\n",
      "loss 3.988481566235423\n",
      "loss 4.138466092199087\n",
      "loss 4.2898722193390135\n",
      "loss 4.4431515134871\n",
      "loss 4.598086032569409\n",
      "loss 4.750240865349769\n",
      "loss 4.907977635413408\n",
      "loss 5.063297955691814\n",
      "loss 5.216337089315057\n",
      "loss 5.378974001035094\n",
      "loss 5.530111807659268\n",
      "loss 5.685855903998017\n",
      "Epoch:  78\n",
      "training loss =  0.15369979614939108\n",
      "loss 0.1503732381761074\n",
      "loss 0.30296797133982184\n",
      "loss 0.45248571611940863\n",
      "loss 0.6008142434805631\n",
      "loss 0.7539963987469673\n",
      "loss 0.9088409143686295\n",
      "loss 1.0588617089390755\n",
      "loss 1.2099115189909935\n",
      "loss 1.3661519446969033\n",
      "loss 1.52000213958323\n",
      "loss 1.6728215647488833\n",
      "loss 1.8242103881388902\n",
      "loss 1.9757335871458053\n",
      "loss 2.1280687061697243\n",
      "loss 2.2803663224726916\n",
      "loss 2.4348939625173807\n",
      "loss 2.5867213923484087\n",
      "loss 2.737593905925751\n",
      "loss 2.8943805165588854\n",
      "loss 3.051736125573516\n",
      "loss 3.2045079005509614\n",
      "loss 3.3603455927222967\n",
      "loss 3.511337649747729\n",
      "loss 3.666639172360301\n",
      "loss 3.820778133869171\n",
      "loss 3.9808982637524606\n",
      "loss 4.134845018014312\n",
      "loss 4.289077031686902\n",
      "loss 4.442001596838236\n",
      "loss 4.602492974251509\n",
      "loss 4.759542472809553\n",
      "loss 4.913618020787835\n",
      "loss 5.068165334165096\n",
      "loss 5.22569705426693\n",
      "loss 5.384144529402256\n",
      "loss 5.544282815083862\n",
      "loss 5.702681442722678\n",
      "Epoch:  79\n",
      "training loss =  0.15411008128482825\n",
      "loss 0.15109666742384434\n",
      "loss 0.30433639481663705\n",
      "loss 0.4588323102146387\n",
      "loss 0.6077780274301767\n",
      "loss 0.7631475584208965\n",
      "loss 0.9135636544972658\n",
      "loss 1.0682554270327091\n",
      "loss 1.2180875506997109\n",
      "loss 1.378069481998682\n",
      "loss 1.5277967677265405\n",
      "loss 1.6772883404791354\n",
      "loss 1.8305702915042639\n",
      "loss 1.9788841430842876\n",
      "loss 2.1304662209004164\n",
      "loss 2.2824606186151506\n",
      "loss 2.4374173357337714\n",
      "loss 2.5895242957770823\n",
      "loss 2.7420897552371026\n",
      "loss 2.8977795562893154\n",
      "loss 3.053581631332636\n",
      "loss 3.2087832795083524\n",
      "loss 3.362042257934809\n",
      "loss 3.51613518550992\n",
      "loss 3.6733046454936265\n",
      "loss 3.8276217932254077\n",
      "loss 3.985591064542532\n",
      "loss 4.13908952280879\n",
      "loss 4.292925311923027\n",
      "loss 4.446336193308234\n",
      "loss 4.603727215155959\n",
      "loss 4.754137177616358\n",
      "loss 4.905474889278412\n",
      "loss 5.062247154563665\n",
      "loss 5.21811626330018\n",
      "loss 5.377687586769461\n",
      "loss 5.538893037363887\n",
      "loss 5.6978264386206865\n",
      "Epoch:  80\n",
      "training loss =  0.15405709584278016\n",
      "loss 0.14721473217010497\n",
      "loss 0.29729534544050695\n",
      "loss 0.4481938868761063\n",
      "loss 0.6013631229102612\n",
      "loss 0.7515250848978758\n",
      "loss 0.904154596105218\n",
      "loss 1.0583699361979961\n",
      "loss 1.2086235397309064\n",
      "loss 1.3605337247252465\n",
      "loss 1.5105340510606766\n",
      "loss 1.6620945696532727\n",
      "loss 1.8121208433061837\n",
      "loss 1.9621226300299168\n",
      "loss 2.114430230855942\n",
      "loss 2.2693081533908845\n",
      "loss 2.4293791396170854\n",
      "loss 2.573842547535896\n",
      "loss 2.7244429219514132\n",
      "loss 2.8827555152773856\n",
      "loss 3.03180956967175\n",
      "loss 3.189182287752628\n",
      "loss 3.345364369004965\n",
      "loss 3.502282588854432\n",
      "loss 3.6577568063884973\n",
      "loss 3.810543384552002\n",
      "loss 3.960248606428504\n",
      "loss 4.115813041776419\n",
      "loss 4.271494789719582\n",
      "loss 4.427466365471482\n",
      "loss 4.588095912858844\n",
      "loss 4.746476862281561\n",
      "loss 4.904500482976436\n",
      "loss 5.063505773171783\n",
      "loss 5.219027842655778\n",
      "loss 5.375601004213094\n",
      "loss 5.5335865778476\n",
      "loss 5.688892138376832\n",
      "Epoch:  81\n",
      "training loss =  0.15375744968668803\n",
      "loss 0.15085255347192286\n",
      "loss 0.3037117945402861\n",
      "loss 0.45455963715910913\n",
      "loss 0.6079220392554998\n",
      "loss 0.7585320887714624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.9107028257846832\n",
      "loss 1.0628441473096608\n",
      "loss 1.215991049259901\n",
      "loss 1.3699820681661368\n",
      "loss 1.5190169547498227\n",
      "loss 1.6664428175985813\n",
      "loss 1.8187453116476535\n",
      "loss 1.969334817454219\n",
      "loss 2.1221108543872833\n",
      "loss 2.277561332657933\n",
      "loss 2.4302565172314643\n",
      "loss 2.5811625749617817\n",
      "loss 2.7368347331136467\n",
      "loss 2.8915878038108347\n",
      "loss 3.0417533600330353\n",
      "loss 3.196990552023053\n",
      "loss 3.3514173167943953\n",
      "loss 3.5074325907230377\n",
      "loss 3.6645260103791952\n",
      "loss 3.8187488407641648\n",
      "loss 3.973302040100098\n",
      "loss 4.125540791898966\n",
      "loss 4.276174477860332\n",
      "loss 4.4320342655479905\n",
      "loss 4.592623677775264\n",
      "loss 4.749778665676713\n",
      "loss 4.90563898421824\n",
      "loss 5.064485765397548\n",
      "loss 5.219683122783899\n",
      "loss 5.375457850843668\n",
      "loss 5.530375098064542\n",
      "loss 5.689581538811326\n",
      "Epoch:  82\n",
      "training loss =  0.1538188605596185\n",
      "loss 0.15011242538690567\n",
      "loss 0.3031700186431408\n",
      "loss 0.45302725188434123\n",
      "loss 0.6063497342169285\n",
      "loss 0.7582357870787382\n",
      "loss 0.9106510401517153\n",
      "loss 1.058571508154273\n",
      "loss 1.211220958456397\n",
      "loss 1.3601594027131796\n",
      "loss 1.513279967457056\n",
      "loss 1.6701620649546385\n",
      "loss 1.8286389844119548\n",
      "loss 1.979696591347456\n",
      "loss 2.1315238554030658\n",
      "loss 2.287425552085042\n",
      "loss 2.4445206355303526\n",
      "loss 2.59724816955626\n",
      "loss 2.753812028765678\n",
      "loss 2.9155470196902753\n",
      "loss 3.0718854488432408\n",
      "loss 3.2232315479964018\n",
      "loss 3.376417573839426\n",
      "loss 3.528542131707072\n",
      "loss 3.6836622229963543\n",
      "loss 3.840874169021845\n",
      "loss 4.00010021880269\n",
      "loss 4.152341097965836\n",
      "loss 4.304943177998066\n",
      "loss 4.458894371166825\n",
      "loss 4.611326498836279\n",
      "loss 4.768415131866932\n",
      "loss 4.922373260259628\n",
      "loss 5.078168013468384\n",
      "loss 5.23620778888464\n",
      "loss 5.3895573104918\n",
      "loss 5.545603625029326\n",
      "loss 5.698371435180307\n",
      "Epoch:  83\n",
      "training loss =  0.154052671363629\n",
      "loss 0.15219220489263535\n",
      "loss 0.3042665234208107\n",
      "loss 0.45696208834648133\n",
      "loss 0.6114506884664297\n",
      "loss 0.766942867487669\n",
      "loss 0.9149855844676494\n",
      "loss 1.0620807617902757\n",
      "loss 1.2140669085830451\n",
      "loss 1.3649313047528266\n",
      "loss 1.5167663846164943\n",
      "loss 1.6637486051023007\n",
      "loss 1.8207416017353535\n",
      "loss 1.9704484728723763\n",
      "loss 2.126994237676263\n",
      "loss 2.2795445277541875\n",
      "loss 2.4333151323348283\n",
      "loss 2.584871101155877\n",
      "loss 2.7404994621127843\n",
      "loss 2.8939907659590243\n",
      "loss 3.04732506968081\n",
      "loss 3.2061399683356284\n",
      "loss 3.363352131918073\n",
      "loss 3.520604379028082\n",
      "loss 3.6786749593168495\n",
      "loss 3.836397593691945\n",
      "loss 3.9957142405956985\n",
      "loss 4.151311603561044\n",
      "loss 4.304894265383482\n",
      "loss 4.460318616554141\n",
      "loss 4.61713871769607\n",
      "loss 4.776541781201959\n",
      "loss 4.93048224657774\n",
      "loss 5.087163047268986\n",
      "loss 5.243803412988782\n",
      "loss 5.401174306124449\n",
      "loss 5.554998107552528\n",
      "loss 5.713682071343064\n",
      "Epoch:  84\n",
      "training loss =  0.15445327129097425\n",
      "loss 0.14877165503799916\n",
      "loss 0.30208848863840104\n",
      "loss 0.4558573192358017\n",
      "loss 0.6075703878700733\n",
      "loss 0.7598411776125431\n",
      "loss 0.9134845919907093\n",
      "loss 1.0633718901872635\n",
      "loss 1.2186868802458048\n",
      "loss 1.3707240199297666\n",
      "loss 1.5256983920186757\n",
      "loss 1.6766158650815486\n",
      "loss 1.827867943942547\n",
      "loss 1.9835202729701995\n",
      "loss 2.1407856899499893\n",
      "loss 2.289955525621772\n",
      "loss 2.4421549978107215\n",
      "loss 2.593644976839423\n",
      "loss 2.747114290073514\n",
      "loss 2.900670596212149\n",
      "loss 3.060164192765951\n",
      "loss 3.2129235880821945\n",
      "loss 3.3645520531386137\n",
      "loss 3.519428532272577\n",
      "loss 3.675287329927087\n",
      "loss 3.828234714791179\n",
      "loss 3.982073526158929\n",
      "loss 4.132241333052516\n",
      "loss 4.288293079212308\n",
      "loss 4.446378344669938\n",
      "loss 4.599080394580961\n",
      "loss 4.755913226604462\n",
      "loss 4.908559002652765\n",
      "loss 5.060083062127233\n",
      "loss 5.2183163450658325\n",
      "loss 5.3765285924822095\n",
      "loss 5.531499971300364\n",
      "loss 5.689384471699595\n",
      "Epoch:  85\n",
      "training loss =  0.15381384015059194\n",
      "loss 0.15202247023582457\n",
      "loss 0.29965246729552747\n",
      "loss 0.4508889270573854\n",
      "loss 0.6007059451192618\n",
      "loss 0.7532312044501305\n",
      "loss 0.9033103532344103\n",
      "loss 1.0540086387842893\n",
      "loss 1.2077926318347454\n",
      "loss 1.3559852499514817\n",
      "loss 1.5084677536785602\n",
      "loss 1.6602350835502149\n",
      "loss 1.8118128814548253\n",
      "loss 1.9648002874851227\n",
      "loss 2.1161886490881443\n",
      "loss 2.270799780488014\n",
      "loss 2.426327739208937\n",
      "loss 2.5827997847646476\n",
      "loss 2.73303090788424\n",
      "loss 2.890789147093892\n",
      "loss 3.0411397746950386\n",
      "loss 3.194664934054017\n",
      "loss 3.3517400730401277\n",
      "loss 3.5062175142019987\n",
      "loss 3.6580518367886543\n",
      "loss 3.8165390549600122\n",
      "loss 3.975222704038024\n",
      "loss 4.129628763645887\n",
      "loss 4.289380204901099\n",
      "loss 4.4477204787731175\n",
      "loss 4.606457736641168\n",
      "loss 4.762863897383213\n",
      "loss 4.919784388169647\n",
      "loss 5.072251678556204\n",
      "loss 5.226268401220441\n",
      "loss 5.382337515801192\n",
      "loss 5.5433623486757275\n",
      "loss 5.704735967591405\n",
      "Epoch:  86\n",
      "training loss =  0.15421298584198095\n",
      "loss 0.14726214326918124\n",
      "loss 0.2952227804064751\n",
      "loss 0.446292742267251\n",
      "loss 0.5992189137637616\n",
      "loss 0.7502112829685211\n",
      "loss 0.9038264123350381\n",
      "loss 1.0537116903066635\n",
      "loss 1.1998897504806518\n",
      "loss 1.3507006292045116\n",
      "loss 1.5033540479838847\n",
      "loss 1.6485583298653363\n",
      "loss 1.8051491885632276\n",
      "loss 1.95655872002244\n",
      "loss 2.109678249955177\n",
      "loss 2.2635304316133262\n",
      "loss 2.422144950181246\n",
      "loss 2.578499497845769\n",
      "loss 2.731017964556813\n",
      "loss 2.886043916121125\n",
      "loss 3.0412361086159945\n",
      "loss 3.1993692166358234\n",
      "loss 3.356115654408932\n",
      "loss 3.5072232716530563\n",
      "loss 3.661368087157607\n",
      "loss 3.815216363146901\n",
      "loss 3.971831650584936\n",
      "loss 4.126395131722092\n",
      "loss 4.283205607533455\n",
      "loss 4.437910859659314\n",
      "loss 4.593380663469434\n",
      "loss 4.749923304095864\n",
      "loss 4.900890031829476\n",
      "loss 5.058557516857982\n",
      "loss 5.21578418277204\n",
      "loss 5.372779589667917\n",
      "loss 5.5287656311690805\n",
      "loss 5.682241244837642\n",
      "Epoch:  87\n",
      "training loss =  0.15364236075512508\n",
      "loss 0.1496321829408407\n",
      "loss 0.2997723730653524\n",
      "loss 0.4546742593497038\n",
      "loss 0.6074332094937563\n",
      "loss 0.7569922669231892\n",
      "loss 0.9066416874527932\n",
      "loss 1.0582989371567963\n",
      "loss 1.2104830341786146\n",
      "loss 1.3611587625741959\n",
      "loss 1.5155262988060714\n",
      "loss 1.669448895677924\n",
      "loss 1.8215033204108477\n",
      "loss 1.972724296078086\n",
      "loss 2.127397098317742\n",
      "loss 2.281627377793193\n",
      "loss 2.435538415983319\n",
      "loss 2.588660307303071\n",
      "loss 2.7420482416450978\n",
      "loss 2.900438916757703\n",
      "loss 3.0532274569571016\n",
      "loss 3.2034086184203625\n",
      "loss 3.3610813696682453\n",
      "loss 3.5116106989979743\n",
      "loss 3.6677623844891785\n",
      "loss 3.8206332399696112\n",
      "loss 3.9726373948156835\n",
      "loss 4.127992271333933\n",
      "loss 4.286740345433355\n",
      "loss 4.441547894999385\n",
      "loss 4.597583047896624\n",
      "loss 4.7562180039286615\n",
      "loss 4.9097402134537695\n",
      "loss 5.064508490934968\n",
      "loss 5.217378269284963\n",
      "loss 5.3741225420683625\n",
      "loss 5.53140875890851\n",
      "loss 5.685872198343277\n",
      "Epoch:  88\n",
      "training loss =  0.15373480003221612\n",
      "loss 0.1484448356926441\n",
      "loss 0.29312676668167115\n",
      "loss 0.44373745515942575\n",
      "loss 0.5923951363563538\n",
      "loss 0.7400784847140313\n",
      "loss 0.8915775374323129\n",
      "loss 1.0427146316319704\n",
      "loss 1.1945833814889193\n",
      "loss 1.3452569174021483\n",
      "loss 1.4990437489748\n",
      "loss 1.6529242376238107\n",
      "loss 1.8045295447856189\n",
      "loss 1.9592394528537989\n",
      "loss 2.1106761355698107\n",
      "loss 2.263399831429124\n",
      "loss 2.416966862529516\n",
      "loss 2.5672342731803655\n",
      "loss 2.7235828492045404\n",
      "loss 2.8734344583004714\n",
      "loss 3.0281534349918364\n",
      "loss 3.1837541917711496\n",
      "loss 3.3355470859259366\n",
      "loss 3.488921546638012\n",
      "loss 3.641482704728842\n",
      "loss 3.7965623264014723\n",
      "loss 3.9501059571653605\n",
      "loss 4.101466751545668\n",
      "loss 4.254920951128006\n",
      "loss 4.415701338648796\n",
      "loss 4.57379684008658\n",
      "loss 4.725302559807897\n",
      "loss 4.886099668815732\n",
      "loss 5.042506229579448\n",
      "loss 5.200853577926755\n",
      "loss 5.353375793546438\n",
      "loss 5.514251799583435\n",
      "loss 5.672034536227584\n",
      "Epoch:  89\n",
      "training loss =  0.15334898514192252\n",
      "loss 0.1525457099080086\n",
      "loss 0.30524711780250074\n",
      "loss 0.4566021827608347\n",
      "loss 0.6059152414649724\n",
      "loss 0.7591030208021402\n",
      "loss 0.912333425655961\n",
      "loss 1.06006829328835\n",
      "loss 1.210729474723339\n",
      "loss 1.3675453937798738\n",
      "loss 1.517941514775157\n",
      "loss 1.67349738702178\n",
      "loss 1.8248980440944433\n",
      "loss 1.9784974812716245\n",
      "loss 2.132855238169432\n",
      "loss 2.285106699094176\n",
      "loss 2.4349148516356944\n",
      "loss 2.5885351153463123\n",
      "loss 2.742314558029175\n",
      "loss 2.8928053868561983\n",
      "loss 3.04841397061944\n",
      "loss 3.2013075403124094\n",
      "loss 3.354760230332613\n",
      "loss 3.5136361384391783\n",
      "loss 3.667663719430566\n",
      "loss 3.8229782628268003\n",
      "loss 3.9752871934324503\n",
      "loss 4.1334191048145295\n",
      "loss 4.288636651560664\n",
      "loss 4.442767345905304\n",
      "loss 4.597932393178343\n",
      "loss 4.7526642625033855\n",
      "loss 4.903248867318034\n",
      "loss 5.058931098356843\n",
      "loss 5.217181243821979\n",
      "loss 5.3725395963341\n",
      "loss 5.527853070273995\n",
      "loss 5.682518591806293\n",
      "Epoch:  90\n",
      "training loss =  0.15364357957524497\n",
      "loss 0.15011650539934634\n",
      "loss 0.29482961565256116\n",
      "loss 0.44669860146939755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.5948178373277188\n",
      "loss 0.7406240758299828\n",
      "loss 0.8877898471057415\n",
      "loss 1.0351487765461207\n",
      "loss 1.1852265764772891\n",
      "loss 1.3341235259920359\n",
      "loss 1.4831130089610816\n",
      "loss 1.6309335757791996\n",
      "loss 1.7803427877277136\n",
      "loss 1.9297559820115566\n",
      "loss 2.07469307564199\n",
      "loss 2.222675762027502\n",
      "loss 2.3735160394757986\n",
      "loss 2.521510680243373\n",
      "loss 2.6692293187975884\n",
      "loss 2.8189353804290294\n",
      "loss 2.9681291246414183\n",
      "loss 3.1182262459397316\n",
      "loss 3.2641426254063846\n",
      "loss 3.4087606217712163\n",
      "loss 3.5586730621010063\n",
      "loss 3.709466679021716\n",
      "loss 3.860292393565178\n",
      "loss 4.005343318358063\n",
      "loss 4.151535642817617\n",
      "loss 4.29549785874784\n",
      "loss 4.443560472726822\n",
      "loss 4.5907552190124985\n",
      "loss 4.740141266733408\n",
      "loss 4.891629275083542\n",
      "loss 5.041501141041517\n",
      "loss 5.189092596843839\n",
      "loss 5.335192663669586\n",
      "loss 5.48280342809856\n",
      "Epoch:  91\n",
      "training loss =  0.1481661971569029\n",
      "loss 0.14786832965910435\n",
      "loss 0.2959196385741234\n",
      "loss 0.4432438925653696\n",
      "loss 0.5878531485795975\n",
      "loss 0.7333047211170196\n",
      "loss 0.8832049237191677\n",
      "loss 1.0312403394281864\n",
      "loss 1.178027857914567\n",
      "loss 1.3227063436061144\n",
      "loss 1.4709990970045328\n",
      "loss 1.6179696790128946\n",
      "loss 1.7634070955216885\n",
      "loss 1.908505025655031\n",
      "loss 2.058609061166644\n",
      "loss 2.2104873866587877\n",
      "loss 2.3607575559616087\n",
      "loss 2.5093116688728334\n",
      "loss 2.656251862347126\n",
      "loss 2.8018053041398527\n",
      "loss 2.9485574822872875\n",
      "loss 3.097040020376444\n",
      "loss 3.2395014641433955\n",
      "loss 3.3886951557546854\n",
      "loss 3.534903151765466\n",
      "loss 3.6821077224612235\n",
      "loss 3.826967910453677\n",
      "loss 3.9790505433827636\n",
      "loss 4.127047545686364\n",
      "loss 4.274112072661519\n",
      "loss 4.421252143681049\n",
      "loss 4.568084585294128\n",
      "loss 4.713432804346085\n",
      "loss 4.861128802746534\n",
      "loss 5.010031942203641\n",
      "loss 5.1587172537297015\n",
      "loss 5.303522537648678\n",
      "loss 5.453058300986886\n",
      "Epoch:  92\n",
      "training loss =  0.14745482399814497\n",
      "loss 0.14629668481647967\n",
      "loss 0.2950342010706663\n",
      "loss 0.44362253427505494\n",
      "loss 0.5906621253490448\n",
      "loss 0.7367826732248068\n",
      "loss 0.883157717809081\n",
      "loss 1.033398740068078\n",
      "loss 1.1784184455871582\n",
      "loss 1.3204674623161554\n",
      "loss 1.4663451556116343\n",
      "loss 1.6118560697138309\n",
      "loss 1.756935472264886\n",
      "loss 1.90749068364501\n",
      "loss 2.054589958563447\n",
      "loss 2.2031361024826763\n",
      "loss 2.3504580719023944\n",
      "loss 2.4996835526078938\n",
      "loss 2.645678512006998\n",
      "loss 2.7926345673948525\n",
      "loss 2.941256055980921\n",
      "loss 3.081588627025485\n",
      "loss 3.2272048100084065\n",
      "loss 3.3692660544067623\n",
      "loss 3.515940506309271\n",
      "loss 3.6651447851210834\n",
      "loss 3.8120133570581674\n",
      "loss 3.9598638693988324\n",
      "loss 4.106504402086139\n",
      "loss 4.252334998100996\n",
      "loss 4.405543725341558\n",
      "loss 4.557093458175659\n",
      "loss 4.704655557721853\n",
      "loss 4.851158336177468\n",
      "loss 5.000194901302457\n",
      "loss 5.14814425803721\n",
      "loss 5.29203199185431\n",
      "loss 5.440815239176154\n",
      "Epoch:  93\n",
      "training loss =  0.14710152034838953\n",
      "loss 0.14836611084640025\n",
      "loss 0.2894020784646273\n",
      "loss 0.43763940572738647\n",
      "loss 0.5875988452136517\n",
      "loss 0.7358388198912144\n",
      "loss 0.8814713016152382\n",
      "loss 1.0309097887575627\n",
      "loss 1.175691678673029\n",
      "loss 1.3189443364739417\n",
      "loss 1.46663214571774\n",
      "loss 1.6170838648825885\n",
      "loss 1.7674237067252399\n",
      "loss 1.9153125607222319\n",
      "loss 2.0602222215384245\n",
      "loss 2.2085668285936118\n",
      "loss 2.35735326975584\n",
      "loss 2.503426757529378\n",
      "loss 2.6508301646262407\n",
      "loss 2.7958399375528096\n",
      "loss 2.943302810192108\n",
      "loss 3.087023705020547\n",
      "loss 3.2338047224283217\n",
      "loss 3.3850757448375224\n",
      "loss 3.533940577507019\n",
      "loss 3.682256396561861\n",
      "loss 3.8297508316487074\n",
      "loss 3.9754471030831335\n",
      "loss 4.123581203520298\n",
      "loss 4.273449863567948\n",
      "loss 4.420931023880839\n",
      "loss 4.565854525119066\n",
      "loss 4.71540761731565\n",
      "loss 4.860624939724803\n",
      "loss 5.010149810388684\n",
      "loss 5.158421976938843\n",
      "loss 5.303328944742679\n",
      "loss 5.447440849840641\n",
      "Epoch:  94\n",
      "training loss =  0.14726931995294923\n",
      "loss 0.14421290673315526\n",
      "loss 0.2949918116629124\n",
      "loss 0.43991146877408027\n",
      "loss 0.5848741000145674\n",
      "loss 0.7301820934563875\n",
      "loss 0.8730671123415231\n",
      "loss 1.0219001333415507\n",
      "loss 1.1693200588971377\n",
      "loss 1.316395162642002\n",
      "loss 1.4618387277424336\n",
      "loss 1.6103105410188436\n",
      "loss 1.7557809180021287\n",
      "loss 1.9027645179629327\n",
      "loss 2.0461466481536625\n",
      "loss 2.1924773930758237\n",
      "loss 2.337164182886481\n",
      "loss 2.4855747843533753\n",
      "loss 2.6333212165534494\n",
      "loss 2.78217032559216\n",
      "loss 2.9272352319955828\n",
      "loss 3.0747436214983463\n",
      "loss 3.2212350127100944\n",
      "loss 3.371944789290428\n",
      "loss 3.518686716929078\n",
      "loss 3.6665603961795568\n",
      "loss 3.812606766447425\n",
      "loss 3.960995045080781\n",
      "loss 4.108844891637563\n",
      "loss 4.256952274516225\n",
      "loss 4.4023660795390605\n",
      "loss 4.547509834840894\n",
      "loss 4.6919142631441355\n",
      "loss 4.838399354666471\n",
      "loss 4.98834205456078\n",
      "loss 5.133585464954376\n",
      "loss 5.281408252641558\n",
      "loss 5.426752770394087\n",
      "Epoch:  95\n",
      "training loss =  0.1466811821648526\n",
      "loss 0.14731739439070224\n",
      "loss 0.2891591939330101\n",
      "loss 0.4331056857854128\n",
      "loss 0.5779905214905738\n",
      "loss 0.7233370453119278\n",
      "loss 0.8721947195380926\n",
      "loss 1.0189928913116455\n",
      "loss 1.1670783932507038\n",
      "loss 1.3163570702821017\n",
      "loss 1.4604907403886318\n",
      "loss 1.6031743713468314\n",
      "loss 1.7487983716279267\n",
      "loss 1.8954591993242502\n",
      "loss 2.0417715610563754\n",
      "loss 2.1875488882511855\n",
      "loss 2.3354748827964067\n",
      "loss 2.4800772596895695\n",
      "loss 2.6265536144375803\n",
      "loss 2.7737879948318005\n",
      "loss 2.9211567547917365\n",
      "loss 3.0689461381733416\n",
      "loss 3.2139028077572585\n",
      "loss 3.359925725758076\n",
      "loss 3.5074077948927878\n",
      "loss 3.654638494849205\n",
      "loss 3.8021281411498786\n",
      "loss 3.9488129061460495\n",
      "loss 4.097327245548367\n",
      "loss 4.24289075396955\n",
      "loss 4.388149776160717\n",
      "loss 4.539232730269432\n",
      "loss 4.686279996559024\n",
      "loss 4.836284084692597\n",
      "loss 4.985883511677384\n",
      "loss 5.136125818639994\n",
      "loss 5.282125458791852\n",
      "loss 5.4305793438106775\n",
      "Epoch:  96\n",
      "training loss =  0.1467999179094089\n",
      "Validation Loss: 1.4775\tTop 1 Validation Accuracy: 0.7930\t Top 5 Validation Accuracy: 0.8932\n",
      "loss 0.14518414221704007\n",
      "loss 0.2885658058524132\n",
      "loss 0.43412232972681525\n",
      "loss 0.5781816413253545\n",
      "loss 0.7229962909966707\n",
      "loss 0.870198784917593\n",
      "loss 1.0136269836872815\n",
      "loss 1.1584253374487161\n",
      "loss 1.3062627187371254\n",
      "loss 1.450712082386017\n",
      "loss 1.6001130069047214\n",
      "loss 1.7441944804042577\n",
      "loss 1.8897891905903816\n",
      "loss 2.034631945937872\n",
      "loss 2.1832162702083586\n",
      "loss 2.3341487138718366\n",
      "loss 2.4781054873764514\n",
      "loss 2.6266837716847657\n",
      "loss 2.7705395457148554\n",
      "loss 2.918859993889928\n",
      "loss 3.063127771615982\n",
      "loss 3.211562041416764\n",
      "loss 3.356105891764164\n",
      "loss 3.50289634488523\n",
      "loss 3.6530909106880425\n",
      "loss 3.798023048788309\n",
      "loss 3.9433899776637555\n",
      "loss 4.088239014372229\n",
      "loss 4.239970835447312\n",
      "loss 4.388169576227665\n",
      "loss 4.53484010219574\n",
      "loss 4.68159218326211\n",
      "loss 1.7473689449578524\n",
      "loss 1.893261456862092\n",
      "loss 2.042226062789559\n",
      "loss 2.1910164514184\n",
      "loss 2.4848492281138896\n",
      "loss 2.6344428914785385\n",
      "loss 2.7778987690806387\n",
      "loss 2.9192792221903803\n",
      "loss 3.0656604731082915\n",
      "loss 3.2102402697503565\n",
      "loss 3.3597662169486284\n",
      "loss 3.5062897430360316\n",
      "loss 3.6511000706255436\n",
      "loss 3.794849037602544\n",
      "loss 3.942595046982169\n",
      "loss 4.0870288822054865\n",
      "loss 4.234079098924995\n",
      "loss 4.380335350185633\n",
      "loss 4.526615449041128\n",
      "loss 4.6738869705051185\n",
      "loss 4.821569751724601\n",
      "loss 4.966505826488137\n",
      "loss 5.109201287105679\n",
      "loss 5.259230718389153\n",
      "loss 5.4069992845505475\n",
      "Epoch:  98\n",
      "training loss =  0.14615509182512199\n",
      "loss 0.14503741689026356\n",
      "loss 0.2890758916735649\n",
      "loss 0.43430172197520733\n",
      "loss 0.577777204066515\n",
      "loss 0.7185293792188168\n",
      "loss 0.8630574462562799\n",
      "loss 1.006378639638424\n",
      "loss 1.154715191423893\n",
      "loss 1.299033953845501\n",
      "loss 1.4465393460541964\n",
      "loss 1.59226522564888\n",
      "loss 1.740031283646822\n",
      "loss 1.8854950979351996\n",
      "loss 2.0341125153005124\n",
      "loss 2.179060283973813\n",
      "loss 2.3252539147436617\n",
      "loss 2.4733399210125206\n",
      "loss 2.622455447614193\n",
      "loss 2.7716149987280367\n",
      "loss 2.9195725654065607\n",
      "loss 3.0674238409101964\n",
      "loss 3.2122513204813004\n",
      "loss 3.3577856972068547\n",
      "loss 3.5037971933186056\n",
      "loss 3.6483447065204384\n",
      "loss 3.7939930622279645\n",
      "loss 3.9382856056839226\n",
      "loss 4.085155273377896\n",
      "loss 4.230099330693483\n",
      "loss 4.375817536935211\n",
      "loss 4.525300009176135\n",
      "loss 4.671209867447614\n",
      "loss 4.812240524515509\n",
      "loss 4.957772916778922\n",
      "loss 5.104213274493813\n",
      "loss 5.253079003021121\n",
      "loss 5.402716083601117\n",
      "Epoch:  99\n",
      "training loss =  0.1460119864996598\n",
      "loss 0.15078445449471473\n",
      "loss 0.2997732852399349\n",
      "loss 0.44414518609642983\n",
      "loss 0.5883758875727654\n",
      "loss 0.7327523329108954\n",
      "loss 0.8758974390476942\n",
      "loss 1.022007929906249\n",
      "loss 1.164233159571886\n",
      "loss 1.3068305853754283\n",
      "loss 1.4515899788588285\n",
      "loss 1.594728935211897\n",
      "loss 1.7382668061554432\n",
      "loss 1.884800754711032\n",
      "loss 2.0287123653292656\n",
      "loss 2.1753890658915043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.320234564319253\n",
      "loss 2.4637443847209215\n",
      "loss 2.6113341065496205\n",
      "loss 2.7582895012944935\n",
      "loss 2.9014957401156427\n",
      "loss 3.050470738038421\n",
      "loss 3.197352222278714\n",
      "loss 3.340227492898703\n",
      "loss 3.4906456254422666\n",
      "loss 3.6370447777956723\n",
      "loss 3.7815701991319655\n",
      "loss 3.926764774620533\n",
      "loss 4.06954260237515\n",
      "loss 4.215070466846227\n",
      "loss 4.359187062010169\n",
      "loss 4.502245241478086\n",
      "loss 4.645917734578251\n",
      "loss 4.79191465139389\n",
      "loss 4.934772073924542\n",
      "loss 5.082073455601931\n",
      "loss 5.2288584762066606\n",
      "loss 5.374006948247552\n",
      "Epoch:  100\n",
      "training loss =  0.1452473922699714\n",
      "loss 0.1464264427870512\n",
      "loss 0.2924574124068022\n",
      "loss 0.4374022881686688\n",
      "loss 0.5855838909745217\n",
      "loss 0.7322919421643018\n",
      "loss 0.8793919838964939\n",
      "loss 1.0232534839957952\n",
      "loss 1.1644035306572915\n",
      "loss 1.3098620063811541\n",
      "loss 1.4569789159297943\n",
      "loss 1.6021603168547154\n",
      "loss 1.7471358727663755\n",
      "loss 1.895096865221858\n",
      "loss 2.0417094357311725\n",
      "loss 2.1896604904532433\n",
      "loss 2.3339073872566223\n",
      "loss 2.476994948834181\n",
      "loss 2.62079313993454\n",
      "loss 2.7657666479796172\n",
      "loss 2.910354702323675\n",
      "loss 3.0577073888480664\n",
      "loss 3.2043220219016075\n",
      "loss 3.3505182242393494\n",
      "loss 3.503917721807957\n",
      "loss 3.6496246922016145\n",
      "loss 3.7939893358200787\n",
      "loss 3.9425736868381502\n",
      "loss 4.380389153882861\n",
      "loss 4.522718849629164\n",
      "loss 4.670906457155943\n",
      "loss 4.81549311183393\n",
      "loss 4.963775685057044\n",
      "loss 5.112453394830227\n",
      "loss 5.256371506303549\n",
      "loss 5.404080848395824\n",
      "Epoch:  101\n",
      "training loss =  0.14609789727333583\n",
      "loss 0.14323892399668695\n",
      "loss 0.29249250531196597\n",
      "loss 0.43696125283837317\n",
      "loss 0.5795688451081514\n",
      "loss 0.7236670140922069\n",
      "loss 0.8718026480078698\n",
      "loss 1.0199403091520072\n",
      "loss 1.1629686563462018\n",
      "loss 1.3084068866074086\n",
      "loss 1.4523193615674972\n",
      "loss 1.5981466218829155\n",
      "loss 1.7429989948868752\n",
      "loss 1.888904731273651\n",
      "loss 2.0386364833265542\n",
      "loss 2.1825334476679563\n",
      "loss 2.327310265824199\n",
      "loss 2.4735829950124026\n",
      "loss 2.619078542292118\n",
      "loss 2.764270450621843\n",
      "loss 2.912820539548993\n",
      "loss 3.059376080930233\n",
      "loss 3.20946553081274\n",
      "loss 3.355202830955386\n",
      "loss 3.5043449766933916\n",
      "loss 3.6457757168263196\n",
      "loss 3.7914628960192203\n",
      "loss 3.9349940498173237\n",
      "loss 4.078223583549261\n",
      "loss 4.225185450986028\n",
      "loss 4.368900460749865\n",
      "loss 4.516389760226011\n",
      "loss 4.66236816264689\n",
      "loss 4.809590578377247\n",
      "loss 4.955415729656815\n",
      "loss 5.1012214136123655\n",
      "loss 5.248687033057212\n",
      "loss 5.396477127447724\n",
      "Epoch:  102\n",
      "training loss =  0.14589275864897824\n",
      "loss 0.14061467580497264\n",
      "loss 0.28722179122269154\n",
      "loss 0.4280089239776135\n",
      "loss 0.5705740147829056\n",
      "loss 0.7093300831317901\n",
      "loss 0.8522441738098859\n",
      "loss 0.9952899179607629\n",
      "loss 1.140845724567771\n",
      "loss 1.2851102556288243\n",
      "loss 1.4339381613582374\n",
      "loss 1.5809305258095265\n",
      "loss 1.7244598533213138\n",
      "loss 1.8708741319924593\n",
      "loss 2.017966615781188\n",
      "loss 2.163285249099135\n",
      "loss 2.309609016776085\n",
      "loss 2.4564770679175854\n",
      "loss 2.6030321776866914\n",
      "loss 2.7479898519814014\n",
      "loss 2.889378706291318\n",
      "loss 3.038178203031421\n",
      "loss 3.1841919911652803\n",
      "loss 3.3299929199367764\n",
      "loss 3.4782260378450154\n",
      "loss 3.627289357483387\n",
      "loss 3.774989017173648\n",
      "loss 3.9243530520796774\n",
      "loss 4.0668484541773795\n",
      "loss 4.216042546480894\n",
      "loss 4.358695853874087\n",
      "loss 4.507993467599153\n",
      "loss 4.654112592339516\n",
      "loss 4.8033441391587255\n",
      "loss 4.950940590128303\n",
      "loss 5.097946824356914\n",
      "loss 5.245595629066229\n",
      "loss 5.395844206139445\n",
      "Epoch:  103\n",
      "training loss =  0.1458634939622551\n",
      "loss 0.14199237793684005\n",
      "loss 0.2851066851615906\n",
      "loss 0.427976800352335\n",
      "loss 0.5722537377476692\n",
      "loss 0.7143480720371008\n",
      "loss 0.8586241225898266\n",
      "loss 1.0049321698397398\n",
      "loss 1.1476813551783562\n",
      "loss 1.293601714298129\n",
      "loss 1.437807149812579\n",
      "loss 1.5811773347854614\n",
      "loss 1.7232788816839457\n",
      "loss 1.8691696704924106\n",
      "loss 2.017126291319728\n",
      "loss 2.1603057835251094\n",
      "loss 2.3069843557476997\n",
      "loss 2.4514442109316588\n",
      "loss 2.596754127070308\n",
      "loss 2.74180772729218\n",
      "loss 2.8912938831001522\n",
      "loss 3.0387979293614626\n",
      "loss 3.1844445964694024\n",
      "loss 3.3286686303466557\n",
      "loss 3.470499943420291\n",
      "loss 3.61834718413651\n",
      "loss 3.762708845287561\n",
      "loss 3.9129694207012653\n",
      "loss 4.0570902979373935\n",
      "loss 4.208374465182423\n",
      "loss 4.35422881603241\n",
      "loss 4.505736085996031\n",
      "loss 4.657268398180604\n",
      "loss 4.80521864823997\n",
      "loss 4.9494451258331535\n",
      "loss 5.09630936704576\n",
      "loss 5.2427884147316215\n",
      "loss 5.38692662216723\n",
      "Epoch:  104\n",
      "training loss =  0.14558401531789836\n",
      "loss 0.1417882761359215\n",
      "loss 0.2849699629098177\n",
      "loss 0.43299160704016687\n",
      "loss 0.5783007012307644\n",
      "loss 0.7236309972405434\n",
      "loss 0.8690930698812008\n",
      "loss 1.0138058923184872\n",
      "loss 1.159690776914358\n",
      "loss 1.301878896728158\n",
      "loss 1.4489101575314998\n",
      "loss 1.5997269605845212\n",
      "loss 1.7412505668401719\n",
      "loss 1.8827941148728131\n",
      "loss 2.0267644663900137\n",
      "loss 2.171530184596777\n",
      "loss 2.3124906489998103\n",
      "loss 2.462955328449607\n",
      "loss 2.6108601310104134\n",
      "loss 2.7605594795942308\n",
      "loss 2.9035559257864954\n",
      "loss 3.047186872139573\n",
      "loss 3.1976886478066446\n",
      "loss 3.3404222115129234\n",
      "loss 3.485933564901352\n",
      "loss 3.631951438561082\n",
      "loss 3.779414604157209\n",
      "loss 3.927412574514747\n",
      "loss 4.07501274779439\n",
      "loss 4.215105288997292\n",
      "loss 4.360347936078906\n",
      "loss 4.509388064444065\n",
      "loss 4.654349593818187\n",
      "loss 4.798969807550311\n",
      "loss 4.9412183436751365\n",
      "loss 5.087242223098874\n",
      "loss 5.235508570745587\n",
      "loss 5.386827596947551\n",
      "Epoch:  105\n",
      "training loss =  0.14561956356341607\n",
      "loss 0.14562132574617861\n",
      "loss 0.288702359944582\n",
      "loss 0.4355166468024254\n",
      "loss 0.5827736242115498\n",
      "loss 0.729627947807312\n",
      "loss 0.8793110331892967\n",
      "loss 1.0296873480081559\n",
      "loss 1.173259816095233\n",
      "loss 1.3166184016317128\n",
      "loss 1.4626449819654226\n",
      "loss 1.6098068915307522\n",
      "loss 1.7524717674404382\n",
      "loss 1.8984540572017432\n",
      "loss 2.0407702923566102\n",
      "loss 2.1884056769311426\n",
      "loss 2.3316566845029594\n",
      "loss 2.4717837127298115\n",
      "loss 2.618527346923947\n",
      "loss 2.7649247657507656\n",
      "loss 2.9083978850394487\n",
      "loss 3.05340114697814\n",
      "loss 3.197952353730798\n",
      "loss 3.346421800851822\n",
      "loss 3.488893067613244\n",
      "loss 3.6374096301943064\n",
      "loss 3.782337790131569\n",
      "loss 3.931137699782848\n",
      "loss 4.07612282037735\n",
      "loss 4.2190912802517415\n",
      "loss 4.36693648532033\n",
      "loss 4.513509507998824\n",
      "loss 4.654212164580822\n",
      "loss 4.7971647087484595\n",
      "loss 4.942942532226443\n",
      "loss 5.089032426327467\n",
      "loss 5.2322016596049075\n",
      "loss 5.374537458345294\n",
      "Epoch:  106\n",
      "training loss =  0.14526322643599937\n",
      "loss 0.1467011286318302\n",
      "loss 0.2917746437340975\n",
      "loss 0.43643725767731667\n",
      "loss 0.5821868312358857\n",
      "loss 0.7252852950245142\n",
      "loss 0.8740961181372404\n",
      "loss 1.01893504075706\n",
      "loss 1.1635291404277086\n",
      "loss 1.3123115701973438\n",
      "loss 1.4577254072576762\n",
      "loss 1.5962465457618236\n",
      "loss 1.7441233402490617\n",
      "loss 1.8900556695461272\n",
      "loss 2.0314866410940886\n",
      "loss 2.176131192818284\n",
      "loss 2.3235059474408626\n",
      "loss 2.470366898328066\n",
      "loss 2.613896691724658\n",
      "loss 2.7580082888156174\n",
      "loss 2.900405412092805\n",
      "loss 3.0425059025734664\n",
      "loss 3.186694200411439\n",
      "loss 3.3319867377728225\n",
      "loss 3.4808514338731764\n",
      "loss 3.630024677067995\n",
      "loss 3.7746154464781285\n",
      "loss 3.921731194779277\n",
      "loss 4.06888671964407\n",
      "loss 4.216259542927146\n",
      "loss 4.3641595659405\n",
      "loss 4.5110181726515295\n",
      "loss 4.6556108781695364\n",
      "loss 4.79991986207664\n",
      "loss 4.95117675870657\n",
      "loss 5.098483394011855\n",
      "loss 5.2432916413992645\n",
      "loss 5.390222586840391\n",
      "Epoch:  107\n",
      "training loss =  0.14570858863958427\n",
      "loss 0.14669130355119706\n",
      "loss 0.2956806369125843\n",
      "loss 0.44403053529560566\n",
      "loss 0.5852770706266165\n",
      "loss 0.7337609188258648\n",
      "loss 0.8790368507057429\n",
      "loss 1.0242942455410957\n",
      "loss 1.1676113763451577\n",
      "loss 1.3147337018698453\n",
      "loss 1.4580164931714534\n",
      "loss 1.600830370336771\n",
      "loss 1.7499499917030334\n",
      "loss 1.8906557538360358\n",
      "loss 2.035589075535536\n",
      "loss 2.1784764824807645\n",
      "loss 2.3246333198994398\n",
      "loss 2.471728992983699\n",
      "loss 2.6151732616126537\n",
      "loss 2.7575981555879117\n",
      "loss 2.9054516427963972\n",
      "loss 3.0489747843891384\n",
      "loss 3.196652360782027\n",
      "loss 3.341658411771059\n",
      "loss 3.4878831689059733\n",
      "loss 3.629302456229925\n",
      "loss 3.7767353536188604\n",
      "loss 3.925415738672018\n",
      "loss 4.07010500587523\n",
      "loss 4.2145208806544545\n",
      "loss 4.365494530573487\n",
      "loss 4.512196082770824\n",
      "loss 4.653660573363304\n",
      "loss 4.800223572403192\n",
      "loss 4.946254853233695\n",
      "loss 5.092757493332028\n",
      "loss 5.239242195934057\n",
      "loss 5.385782372802496\n",
      "Epoch:  108\n",
      "training loss =  0.1455813117982533\n",
      "loss 0.14465577095746995\n",
      "loss 0.2873222533613443\n",
      "loss 0.43308068871498107\n",
      "loss 0.5826802212744951\n",
      "loss 0.7315883154422045\n",
      "loss 0.8781808100640773\n",
      "loss 1.029071338251233\n",
      "loss 1.178705851584673\n",
      "loss 1.3247230859100818\n",
      "loss 1.4677862744033336\n",
      "loss 1.612785387188196\n",
      "loss 1.7592370058596134\n",
      "loss 1.9071769195795059\n",
      "loss 2.0514806858450174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.1957432712614535\n",
      "loss 2.336894762814045\n",
      "loss 2.48303425706923\n",
      "loss 2.6294858043640854\n",
      "loss 2.777762033045292\n",
      "loss 2.9242395881563423\n",
      "loss 3.0691613382846117\n",
      "loss 3.2132343860715626\n",
      "loss 3.356097894087434\n",
      "loss 3.499559233263135\n",
      "loss 3.641158530935645\n",
      "loss 3.7852479539066555\n",
      "loss 3.9290644263476135\n",
      "loss 4.076686114147305\n",
      "loss 4.223961908146739\n",
      "loss 4.66461874268949\n",
      "loss 4.811051576733589\n",
      "loss 4.95643229611218\n",
      "loss 5.098663999512792\n",
      "loss 5.244237293824553\n",
      "loss 5.389251304864883\n",
      "Epoch:  109\n",
      "training loss =  0.14564384175763478\n",
      "loss 0.14552015393972398\n",
      "loss 0.2878163132816553\n",
      "loss 0.42822190530598164\n",
      "loss 0.5735831865668297\n",
      "loss 0.7190479693561792\n",
      "loss 0.8637972718477249\n",
      "loss 1.0084073204547166\n",
      "loss 1.1537326642125845\n",
      "loss 1.3005656941980124\n",
      "loss 1.448780653104186\n",
      "loss 1.596806765049696\n",
      "loss 1.741872677281499\n",
      "loss 1.8885312653332949\n",
      "loss 2.033632073029876\n",
      "loss 2.181970821991563\n",
      "loss 2.3239343336969616\n",
      "loss 2.468638234585524\n",
      "loss 2.609807977229357\n",
      "loss 2.760267184376717\n",
      "loss 2.9060191145539283\n",
      "loss 3.0533090936392546\n",
      "loss 3.196283915936947\n",
      "loss 3.34436518676579\n",
      "loss 3.4901004789769647\n",
      "loss 3.6360337238013742\n",
      "loss 3.7800853903591634\n",
      "loss 3.923612959831953\n",
      "loss 4.0696349681913855\n",
      "loss 4.217977816835046\n",
      "loss 4.361651255041361\n",
      "loss 4.506292889490724\n",
      "loss 4.652388688847423\n",
      "loss 4.794168623015285\n",
      "loss 4.940260330662131\n",
      "loss 5.09131179139018\n",
      "loss 5.234570653364062\n",
      "loss 5.379744945764542\n",
      "Epoch:  110\n",
      "training loss =  0.1454287217972669\n",
      "loss 0.1419008170813322\n",
      "loss 0.2857438345998526\n",
      "loss 0.4322635663300753\n",
      "loss 0.5745645077526569\n",
      "loss 0.7212299252301455\n",
      "loss 0.8720874194800854\n",
      "loss 1.0178456961363553\n",
      "loss 1.162254543453455\n",
      "loss 1.3044755020737648\n",
      "loss 1.4506205397844314\n",
      "loss 1.5892810017615557\n",
      "loss 1.7348358474671841\n",
      "loss 1.8784996064007282\n",
      "loss 2.025809500515461\n",
      "loss 2.1658278758078815\n",
      "loss 2.3103517626225947\n",
      "loss 2.4533778309077023\n",
      "loss 2.5976448260992764\n",
      "loss 2.7452637426555158\n",
      "loss 2.8894765169173477\n",
      "loss 3.0353999703377483\n",
      "loss 3.1788051182031634\n",
      "loss 3.3282838644832373\n",
      "loss 3.475263091921806\n",
      "loss 3.623514589369297\n",
      "loss 3.7752969200909137\n",
      "loss 3.9171005415171383\n",
      "loss 4.06313985042274\n",
      "loss 4.210012896284461\n",
      "loss 4.35485109873116\n",
      "loss 4.501126791834832\n",
      "loss 4.647272580936551\n",
      "loss 4.793897133618593\n",
      "loss 4.939492451399564\n",
      "loss 5.084023392796516\n",
      "loss 5.2320728035271165\n",
      "loss 5.378311027139425\n",
      "Epoch:  111\n",
      "training loss =  0.1454040373323547\n",
      "loss 0.1477128217369318\n",
      "loss 0.28857767283916474\n",
      "loss 0.7289526111632586\n",
      "loss 0.8682740293443203\n",
      "loss 1.0144199312478304\n",
      "loss 1.1589768516272307\n",
      "loss 1.3055597146600484\n",
      "loss 1.4536474814265967\n",
      "loss 1.6002759259194135\n",
      "loss 1.7436948751658201\n",
      "loss 1.8878035175800323\n",
      "loss 2.0285379952192306\n",
      "loss 2.1712682708352804\n",
      "loss 2.315768011137843\n",
      "loss 2.46001761905849\n",
      "loss 2.604488771036267\n",
      "loss 2.7490759114176035\n",
      "loss 2.8919221536815165\n",
      "loss 3.033696734160185\n",
      "loss 3.179109870120883\n",
      "loss 3.3256349328905346\n",
      "loss 3.4701885674893855\n",
      "loss 3.617004157155752\n",
      "loss 3.7684344563633205\n",
      "loss 3.9108927482366562\n",
      "loss 4.054860849529505\n",
      "loss 4.202167405262589\n",
      "loss 4.350666095167399\n",
      "loss 4.494922960326075\n",
      "loss 4.642288404628634\n",
      "loss 4.7912395764142275\n",
      "loss 4.935497730001807\n",
      "loss 5.0809031443297865\n",
      "loss 5.222266130596399\n",
      "loss 5.370252768695354\n",
      "Epoch:  112\n",
      "training loss =  0.1451667804127277\n",
      "loss 0.1436393765360117\n",
      "loss 0.28495522163808346\n",
      "loss 0.427318300306797\n",
      "loss 0.5768351800739765\n",
      "loss 0.7192919805645943\n",
      "loss 0.8661825184524059\n",
      "loss 1.0094653914868832\n",
      "loss 1.150641563758254\n",
      "loss 1.2941526259481906\n",
      "loss 1.4396608325839042\n",
      "loss 1.5858369871973992\n",
      "loss 1.7293641965836286\n",
      "loss 1.8774711740016938\n",
      "loss 2.0249244960397483\n",
      "loss 2.1719591673463583\n",
      "loss 2.3188651932030915\n",
      "loss 2.4616202553361655\n",
      "loss 2.606933600306511\n",
      "loss 2.7555160809308292\n",
      "loss 2.898178490921855\n",
      "loss 3.037501266375184\n",
      "loss 3.1858114428818225\n",
      "loss 3.3324675973504783\n",
      "loss 3.4807530410587786\n",
      "loss 3.6222292894124983\n",
      "loss 3.766287036985159\n",
      "loss 3.912086985781789\n",
      "loss 4.0586689131706954\n",
      "loss 4.203831198289991\n",
      "loss 4.348168013393879\n",
      "loss 4.496723897010088\n",
      "loss 4.639405834525824\n",
      "loss 4.7816822797060015\n",
      "loss 4.927032963261008\n",
      "loss 5.07437984496355\n",
      "loss 5.2188394074141975\n",
      "loss 5.36405781969428\n",
      "Epoch:  113\n",
      "training loss =  0.14499210050952122\n",
      "loss 0.14354132376611234\n",
      "loss 0.28832434125244616\n",
      "loss 0.4354643231630325\n",
      "loss 0.5877376538515091\n",
      "loss 0.7364245045185089\n",
      "loss 0.8827321018278599\n",
      "loss 1.027446137368679\n",
      "loss 1.1676467556506396\n",
      "loss 1.3112358389049767\n",
      "loss 1.457078579366207\n",
      "loss 1.6015918832272291\n",
      "loss 1.7478338423371316\n",
      "loss 1.892150940746069\n",
      "loss 2.037402730882168\n",
      "loss 2.1819517248868943\n",
      "loss 2.3313612980395555\n",
      "loss 2.4832536675035954\n",
      "loss 2.630181997194886\n",
      "loss 2.77616939291358\n",
      "loss 2.918600163012743\n",
      "loss 3.0619300507754086\n",
      "loss 3.207557251304388\n",
      "loss 3.352939354777336\n",
      "loss 3.4928260061144827\n",
      "loss 3.6352853555232287\n",
      "loss 3.77634650349617\n",
      "loss 3.925286875367165\n",
      "loss 4.0656501320749525\n",
      "loss 4.211856859847903\n",
      "loss 4.350900731384754\n",
      "loss 4.494448374435305\n",
      "loss 4.6395983413606885\n",
      "loss 4.784846016466617\n",
      "loss 4.933500431925058\n",
      "loss 5.077001408115029\n",
      "loss 5.221043579503894\n",
      "loss 5.363599229305983\n",
      "Epoch:  114\n",
      "training loss =  0.14497628834149828\n",
      "loss 0.1442116355150938\n",
      "loss 0.2922841528058052\n",
      "loss 0.4380602636188269\n",
      "loss 0.5789280711114406\n",
      "loss 0.722431770414114\n",
      "loss 0.8659217632561922\n",
      "loss 1.010870292261243\n",
      "loss 1.1588683822005987\n",
      "loss 1.3029093217104672\n",
      "loss 1.4459535314142704\n",
      "loss 1.5888004510104656\n",
      "loss 1.7346991366893052\n",
      "loss 1.8778229062259197\n",
      "loss 2.0220969419181345\n",
      "loss 2.1677116826176643\n",
      "loss 2.3123659288883207\n",
      "loss 2.454765727892518\n",
      "loss 2.6009084817022083\n",
      "loss 2.748190536201\n",
      "loss 2.8941568621993063\n",
      "loss 3.039444163441658\n",
      "loss 3.184833855777979\n",
      "loss 3.331595003157854\n",
      "loss 3.480755415484309\n",
      "loss 3.9181710091233253\n",
      "loss 4.060918971672654\n",
      "loss 4.205350082144141\n",
      "loss 4.3506755284219985\n",
      "loss 4.493476881235838\n",
      "loss 4.639254590421915\n",
      "loss 4.780667241737246\n",
      "loss 4.926321630999446\n",
      "loss 5.071802324876189\n",
      "loss 5.216413459777832\n",
      "loss 5.359105500131846\n",
      "Epoch:  115\n",
      "training loss =  0.1448883584464114\n",
      "loss 0.1464533744752407\n",
      "loss 0.286747178658843\n",
      "loss 0.4296523955464363\n",
      "loss 0.5732605344802141\n",
      "loss 0.716033496260643\n",
      "loss 0.8621532253921032\n",
      "loss 1.0045410464704037\n",
      "loss 1.1495777574181556\n",
      "loss 1.3010776444524526\n",
      "loss 1.4452179319411516\n",
      "loss 1.5929114017635584\n",
      "loss 1.737821084484458\n",
      "loss 1.8849794052541256\n",
      "loss 2.0329844419658185\n",
      "loss 2.1794834076613188\n",
      "loss 2.32353589206934\n",
      "loss 2.4685807353258133\n",
      "loss 2.61494291216135\n",
      "loss 2.7581001434475185\n",
      "loss 2.900979142934084\n",
      "loss 3.042664326354861\n",
      "loss 3.1915174701064823\n",
      "loss 3.3360907024890185\n",
      "loss 3.4842214952409267\n",
      "loss 3.628907490596175\n",
      "loss 3.7760937752574684\n",
      "loss 3.9270215930789707\n",
      "loss 4.067279526516796\n",
      "loss 4.2120979777723555\n",
      "loss 4.357067367658019\n",
      "loss 4.500469351783395\n",
      "loss 4.646577850431203\n",
      "loss 4.791232746690512\n",
      "loss 4.936172164157033\n",
      "loss 5.078282553702593\n",
      "loss 5.220184585750103\n",
      "loss 5.367142905592918\n",
      "Epoch:  116\n",
      "training loss =  0.14510275279017257\n",
      "loss 0.14334161147475244\n",
      "loss 0.2897965458780527\n",
      "loss 0.4343155966699123\n",
      "loss 0.5795462823659182\n",
      "loss 0.7238695556670427\n",
      "loss 0.8659648711234331\n",
      "loss 1.015117651373148\n",
      "loss 1.1622624701261521\n",
      "loss 1.304300913065672\n",
      "loss 1.4479378216713668\n",
      "loss 1.5938420009613037\n",
      "loss 1.739662485793233\n",
      "loss 1.8850014159083366\n",
      "loss 2.030204850062728\n",
      "loss 2.17759318575263\n",
      "loss 2.323153930604458\n",
      "loss 2.4710080595314503\n",
      "loss 2.616748421564698\n",
      "loss 2.7610838048905135\n",
      "loss 2.9065131233632564\n",
      "loss 3.050953573808074\n",
      "loss 3.1961610260605813\n",
      "loss 3.3379435832053423\n",
      "loss 3.4790902799367904\n",
      "loss 3.620260329321027\n",
      "loss 3.771553738117218\n",
      "loss 3.9167432699352505\n",
      "loss 4.060581046491861\n",
      "loss 4.205274426192045\n",
      "loss 4.3480936104804275\n",
      "loss 4.49443656027317\n",
      "loss 4.635927090421319\n",
      "loss 4.779570861905813\n",
      "loss 4.9256199754029515\n",
      "loss 5.072927089184523\n",
      "loss 5.218771247342229\n",
      "loss 5.365744199082255\n",
      "Epoch:  117\n",
      "training loss =  0.14503055453372832\n",
      "loss 0.14802900120615958\n",
      "loss 0.29559661865234377\n",
      "loss 0.43818233497440817\n",
      "loss 0.5819303473085164\n",
      "loss 0.7244052507728338\n",
      "loss 0.8630709487944841\n",
      "loss 1.0087436268478631\n",
      "loss 1.150263909548521\n",
      "loss 1.2904858934134245\n",
      "loss 1.4352183093130588\n",
      "loss 1.5805419480055571\n",
      "loss 1.726842354312539\n",
      "loss 1.8691174154728651\n",
      "loss 2.0193115355819464\n",
      "loss 2.1642433712631464\n",
      "loss 2.3090660899877546\n",
      "loss 2.4546435545384884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 2.601665861532092\n",
      "loss 2.748570570498705\n",
      "loss 2.89619537897408\n",
      "loss 3.0404009366035463\n",
      "loss 3.1874407927691935\n",
      "loss 3.3303110478818416\n",
      "loss 3.4743074468523263\n",
      "loss 3.618799766972661\n",
      "loss 3.765964159891009\n",
      "loss 3.9118186365813017\n",
      "loss 4.054118996933102\n",
      "loss 4.198862951770425\n",
      "loss 4.345696912109852\n",
      "loss 4.486634963676334\n",
      "loss 4.629607694745064\n",
      "loss 4.769662273004651\n",
      "loss 4.914984390586614\n",
      "loss 5.060490246787667\n",
      "loss 5.2041925232112405\n",
      "loss 5.350745811089873\n",
      "Epoch:  118\n",
      "training loss =  0.14464505814520343\n",
      "loss 0.14609684586524962\n",
      "loss 0.2919485978037119\n",
      "loss 0.43982272371649744\n",
      "loss 0.5828959207981825\n",
      "loss 0.7262066801637411\n",
      "loss 0.8739999016374349\n",
      "loss 1.016682099327445\n",
      "loss 1.1590346924960613\n",
      "loss 1.3002948114275932\n",
      "loss 1.4447877063602208\n",
      "loss 1.5920300460606813\n",
      "loss 1.73716973900795\n",
      "loss 1.8801751619577407\n",
      "loss 2.0237797944247724\n",
      "loss 2.1725644730776548\n",
      "loss 2.31429494895041\n",
      "loss 2.4586272870749237\n",
      "loss 2.6008247376233338\n",
      "loss 2.745375006720424\n",
      "loss 2.8869598414748907\n",
      "loss 3.0350754484534264\n",
      "loss 3.1811182048916815\n",
      "loss 3.323049567118287\n",
      "loss 3.4691204872727393\n",
      "loss 3.611657196357846\n",
      "loss 3.753054389059544\n",
      "loss 3.9037189073860645\n",
      "loss 4.045519493222237\n",
      "loss 4.191538591086864\n",
      "loss 4.33802055388689\n",
      "loss 4.485317324772478\n",
      "loss 4.626008738130331\n",
      "loss 4.771857066676021\n",
      "loss 4.920190264508128\n",
      "loss 5.066761848106981\n",
      "loss 5.213842344507575\n",
      "loss 5.359379159584641\n",
      "Epoch:  119\n",
      "training loss =  0.1448956134045481\n",
      "loss 0.13821238048374654\n",
      "loss 0.28493631139397624\n",
      "loss 0.4286902392655611\n",
      "loss 0.575797072276473\n",
      "loss 0.7160429348051548\n",
      "loss 0.8621775536984205\n",
      "loss 1.0053033673018217\n",
      "loss 1.1496894905716182\n",
      "loss 1.2988013106584548\n",
      "loss 1.4438438688218593\n",
      "loss 1.5871564476937055\n",
      "loss 1.7308031407743691\n",
      "loss 1.8749546052515507\n",
      "loss 2.020151531249285\n",
      "loss 2.167171443030238\n",
      "loss 2.3117413660883903\n",
      "loss 2.457485013008118\n",
      "loss 2.604277803897858\n",
      "loss 2.751464044675231\n",
      "loss 2.894140562266111\n",
      "loss 3.0359825721383094\n",
      "loss 3.1819553408771752\n",
      "loss 3.324349658563733\n",
      "loss 3.4701434732228518\n",
      "loss 3.6150679896771907\n",
      "loss 3.756410559862852\n",
      "loss 3.8953936733305454\n",
      "loss 4.039964394643903\n",
      "loss 4.182912862375378\n",
      "loss 4.327221703454852\n",
      "loss 4.47266698859632\n",
      "loss 4.6177031327039\n",
      "loss 4.758338116556406\n",
      "loss 4.904102445244789\n",
      "loss 5.049155859053135\n",
      "loss 5.19608689032495\n",
      "loss 5.342144900336861\n",
      "Epoch:  120\n",
      "training loss =  0.14439711575643824\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, validation_dataloader, criterion, optimizer, lr_scheduler, modelpath, device, epochs = num_Epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Validation_Loss_List'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b99916db78aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#### Load saved model from checkpoint  #####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/abhishek/AliProducts/Helper/Load_model.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(modelpath, model, optimizer, lr_scheduler)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Training_Loss_List'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mv_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Validation_Loss_List'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mv_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Validation_Accuracy_List'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Validation_Loss_List'"
     ]
    }
   ],
   "source": [
    "#### Load saved model from checkpoint  #####\n",
    "model, optimizer, lr_scheduler, train_loss, v_loss, v_acc, epoch = load(modelpath, model, optimizer, lr_scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-32863ce17df6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#### Plot Loss Curves ####/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Autoaugment_Cutout_Resnet50'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplot_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epoch' is not defined"
     ]
    }
   ],
   "source": [
    "#### Plot Loss Curves ####/\n",
    "plot_loss(epoch, train_loss, v_loss, title = 'Autoaugment_Cutout_Resnet50')\n",
    "plot_acc(epoch, v_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.4860\tTop 1 Training Accuracy: 0.8849\t Top 5 Training Accuracy: 0.9747\n"
     ]
    }
   ],
   "source": [
    "t_loss,top1_t_acc, top5_t_acc =test_classify(model, train_dataloader, criterion, device)\n",
    "print('Training Loss: {:.4f}\\tTop 1 Training Accuracy: {:.4f}\\t Top 5 Training Accuracy: {:.4f}'.format(t_loss, top1_t_acc, top5_t_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.4769\tTop 1 Validation Accuracy: 0.7929\n",
      "Accuracy:defaultdict(<class 'int'>, {'Top 1 Accuracy': 79.29395913272513, 'Top 5 Accuracy': 89.31768459332126, 'Top 10 Accuracy': 89.80188226493657, 'Top 20 Accuracy': 90.15404650911279, 'Top 30 Accuracy': 90.33677536517607, 'Top 50 Accuracy': 90.56591870255752, 'Top 100 Accuracy': 90.95548490740761})\t\n"
     ]
    }
   ],
   "source": [
    "v_loss, top1_acc, accuracy_dict= eval_classify(model, validation_dataloader, criterion, device)\n",
    "print('Validation Loss: {:.4f}\\tTop 1 Validation Accuracy: {:.4f}\\nAccuracy:{}\\t'.format(v_loss, top1_acc, accuracy_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443827"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "948822"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
