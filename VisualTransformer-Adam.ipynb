{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 28 10:37:15 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 42%   65C    P2   279W / 280W |  22094MiB / 24220MiB |     98%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 91%   88C    P2   264W / 280W |  17046MiB / 24220MiB |     89%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "|100%   88C    P2   203W / 280W |  16826MiB / 24220MiB |     88%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN RTX           Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "|100%   88C    P2   214W / 280W |  16936MiB / 24220MiB |     84%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  TITAN RTX           Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 41%   26C    P8     2W / 280W |   6773MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  TITAN RTX           Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 41%   33C    P8    32W / 280W |  10323MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  TITAN RTX           Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 41%   29C    P8    20W / 280W |   5713MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  TITAN RTX           Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 41%   26C    P8    14W / 280W |   3362MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      1311      C   .../anaconda3/envs/shayeree_env/bin/python   859MiB |\n",
      "|    0     12969      C   .../anaconda3/envs/shayeree_env/bin/python   859MiB |\n",
      "|    0     17842      C   .../anaconda3/envs/shayeree_env/bin/python   859MiB |\n",
      "|    0     20988      C   .../anaconda3/envs/abhishek_env/bin/python   965MiB |\n",
      "|    0     28313      C   .../anaconda3/envs/abhishek_env/bin/python 18475MiB |\n",
      "|    1     28313      C   .../anaconda3/envs/abhishek_env/bin/python 16979MiB |\n",
      "|    2     28313      C   .../anaconda3/envs/abhishek_env/bin/python 16759MiB |\n",
      "|    3     28313      C   .../anaconda3/envs/abhishek_env/bin/python 16869MiB |\n",
      "|    4      1311      C   .../anaconda3/envs/shayeree_env/bin/python  1641MiB |\n",
      "|    4     12969      C   .../anaconda3/envs/shayeree_env/bin/python  5121MiB |\n",
      "|    5      1311      C   .../anaconda3/envs/shayeree_env/bin/python  9187MiB |\n",
      "|    5     20988      C   .../anaconda3/envs/abhishek_env/bin/python  1115MiB |\n",
      "|    6     17842      C   .../anaconda3/envs/shayeree_env/bin/python  3187MiB |\n",
      "|    7      1311      C   .../anaconda3/envs/shayeree_env/bin/python   947MiB |\n",
      "|    7     12969      C   .../anaconda3/envs/shayeree_env/bin/python  1533MiB |\n",
      "|    7     17842      C   .../anaconda3/envs/shayeree_env/bin/python   871MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### IMPORTING NECESSARY MODULES #########\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.append('/home/ironman/abhishek/AliProducts/architectures/')\n",
    "sys.path.append('/home/ironman/abhishek/AliProducts/Helper/')\n",
    "\n",
    "from dataloader import mydataset, create_prime_dict \n",
    "from trainer import train, test_classify, eval_classify\n",
    "from Load_model import load\n",
    "\n",
    "\n",
    "\n",
    "from vit_pytorch import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:4\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:4' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataloading Scheme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlist = '/home/ironman/abhishek/AliProducts/Newlist/NEW_train_list1.txt'\n",
    "validlist = '/home/ironman/abhishek/AliProducts/Newlist/NEW_valid_list1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes =  50030\n"
     ]
    }
   ],
   "source": [
    "prime_dict = create_prime_dict(trainlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train Dataloader #### \n",
    "train_dataset = mydataset(trainlist, prime_dict, name='train')          \n",
    "train_dataloader = data.DataLoader(train_dataset, shuffle= True, batch_size = 1024, num_workers=16,pin_memory=True)\n",
    "\n",
    "\n",
    "#### Validation Dataloader #### \n",
    "validation_dataset = mydataset(validlist, prime_dict, name='valid')         \n",
    "validation_dataloader = data.DataLoader(validation_dataset, shuffle=False, batch_size = 128, num_workers=16,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ViT(\n",
       "    (patch_to_embedding): Linear(in_features=3072, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (transformer): Transformer(\n",
       "      (layers): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                  (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "                  (4): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                  (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "                  (4): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                  (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "                  (4): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                  (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "                  (4): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): ModuleList(\n",
       "          (0): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                  (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "                  (4): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): ModuleList(\n",
       "          (0): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                  (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "                  (4): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (to_cls_token): Identity()\n",
       "    (mlp_head): Sequential(\n",
       "      (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (2): GELU()\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=2048, out_features=50030, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ViT(\n",
    "    image_size = 256,\n",
    "    patch_size = 32,\n",
    "    num_classes = 50030,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1\n",
    ")\n",
    "\n",
    "\n",
    "model = nn.DataParallel(model,device_ids=[4,5,6,7]).to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Epochs\n",
    "num_Epochs = 120\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 30, gamma = 0.1)\n",
    "\n",
    "#Cutmix\n",
    "# beta = 1\n",
    "# cutmix_prob = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'ViT_adam'\n",
    "modelpath = '/home/ironman/abhishek/saved_model_checkpoints/AliProducts/' + modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 10.827429780960083\n",
      "loss 21.624833335876463\n",
      "loss 32.40389916419983\n",
      "loss 43.15905951499939\n",
      "loss 53.89399312973023\n",
      "loss 64.61359502792358\n",
      "loss 75.31556436538696\n",
      "loss 86.01247138977051\n",
      "loss 96.66827885627747\n",
      "loss 107.27454155921936\n",
      "loss 117.84358242988587\n",
      "Epoch:  1\n",
      "training loss =  10.71115497033373\n",
      "Validation Loss: 10.6433\tTop 1 Validation Accuracy: 0.0001\t Top 5 Validation Accuracy: 0.0005\n",
      "loss 10.442194557189941\n",
      "loss 20.838954887390138\n",
      "loss 31.198494682312013\n",
      "loss 41.524763383865356\n",
      "loss 51.835889406204224\n",
      "loss 62.17466708183289\n",
      "loss 72.44980776786804\n",
      "loss 82.74271814346314\n",
      "loss 92.95467862129212\n",
      "loss 103.20975544929505\n",
      "loss 113.40744176864624\n",
      "Epoch:  2\n",
      "training loss =  10.308512283743715\n",
      "Validation Loss: 10.3504\tTop 1 Validation Accuracy: 0.0003\t Top 5 Validation Accuracy: 0.0014\n",
      "loss 10.061445512771606\n",
      "loss 20.112768449783324\n",
      "loss 30.153789119720457\n",
      "loss 40.20015948295593\n",
      "loss 50.24918898582459\n",
      "loss 60.31516764640808\n",
      "loss 70.36110998153687\n",
      "loss 80.3927788734436\n",
      "loss 90.41658785820007\n",
      "loss 100.44965105056762\n",
      "loss 110.53986929893493\n",
      "Epoch:  3\n",
      "training loss =  10.05111462092228\n",
      "Validation Loss: 10.4048\tTop 1 Validation Accuracy: 0.0004\t Top 5 Validation Accuracy: 0.0013\n",
      "loss 10.022116107940674\n",
      "loss 20.056622228622437\n",
      "loss 30.07705044746399\n",
      "loss 40.08019805908203\n",
      "loss 50.084167041778564\n",
      "loss 60.036463747024534\n",
      "loss 70.03838276863098\n",
      "loss 80.00469365119935\n",
      "loss 89.9486198425293\n",
      "loss 99.87060870170593\n",
      "loss 109.7821420288086\n",
      "Epoch:  4\n",
      "training loss =  9.979591422801395\n",
      "Validation Loss: 10.1214\tTop 1 Validation Accuracy: 0.0008\t Top 5 Validation Accuracy: 0.0032\n",
      "loss 9.819243125915527\n",
      "loss 19.630556182861326\n",
      "loss 29.44336443901062\n",
      "loss 39.30948076248169\n",
      "loss 49.172022562026974\n",
      "loss 59.013173723220824\n",
      "loss 68.91369242668152\n",
      "loss 78.89341114997863\n",
      "loss 88.86899307250977\n",
      "loss 98.75830658912659\n",
      "loss 108.62183171272278\n",
      "Epoch:  5\n",
      "training loss =  9.874562332956053\n",
      "Validation Loss: 10.1016\tTop 1 Validation Accuracy: 0.0008\t Top 5 Validation Accuracy: 0.0036\n",
      "loss 9.745939903259277\n",
      "loss 19.48330318450928\n",
      "loss 29.21902424812317\n",
      "loss 38.994807434082034\n",
      "loss 48.805211763381955\n",
      "loss 58.65202411651612\n",
      "loss 68.42933554649353\n",
      "loss 78.17162275314331\n",
      "loss 87.90926869392395\n",
      "loss 97.71413353919984\n",
      "loss 107.4571663570404\n",
      "Epoch:  6\n",
      "training loss =  9.768497397573732\n",
      "Validation Loss: 10.0240\tTop 1 Validation Accuracy: 0.0013\t Top 5 Validation Accuracy: 0.0049\n",
      "loss 9.581383543014526\n",
      "loss 19.15871968269348\n",
      "loss 28.732722568511964\n",
      "loss 38.322115640640256\n",
      "loss 47.960649976730345\n",
      "loss 67.31529786109924\n",
      "loss 76.95078548431397\n",
      "loss 86.62660442352295\n",
      "loss 96.29918250083924\n",
      "loss 105.93488965034484\n",
      "Epoch:  7\n",
      "training loss =  9.630535488506014\n",
      "Validation Loss: 9.9584\tTop 1 Validation Accuracy: 0.0015\t Top 5 Validation Accuracy: 0.0057\n",
      "loss 9.534393100738525\n",
      "loss 19.02284677505493\n",
      "loss 28.506809453964234\n",
      "loss 38.042250080108644\n",
      "loss 47.54941261291504\n",
      "loss 57.07767124176026\n",
      "loss 66.62304640769959\n",
      "loss 76.13180746078491\n",
      "loss 85.59792942047119\n",
      "loss 95.03378019332885\n",
      "loss 104.52933170318603\n",
      "Epoch:  8\n",
      "training loss =  9.502431180837343\n",
      "Validation Loss: 9.8804\tTop 1 Validation Accuracy: 0.0021\t Top 5 Validation Accuracy: 0.0072\n",
      "loss 9.2928671169281\n",
      "loss 18.811335582733154\n",
      "loss 28.35450629234314\n",
      "loss 37.86771137237549\n",
      "loss 47.32448202133179\n",
      "loss 56.74879769325256\n",
      "loss 66.13877778053283\n",
      "loss 75.52045768737793\n",
      "loss 84.88858138084412\n",
      "loss 94.29530588150024\n",
      "loss 103.6823771095276\n",
      "Epoch:  9\n",
      "training loss =  9.424830570495386\n",
      "Validation Loss: 9.7952\tTop 1 Validation Accuracy: 0.0024\t Top 5 Validation Accuracy: 0.0086\n",
      "loss 9.266243257522582\n",
      "loss 18.508346490859985\n",
      "loss 27.768067131042482\n",
      "loss 37.29162875175476\n",
      "loss 46.80226643562317\n",
      "loss 56.21614423751831\n",
      "loss 65.64001782417297\n",
      "loss 74.99855293273926\n",
      "loss 84.35558281898498\n",
      "loss 93.65870450019837\n",
      "loss 102.97846329689025\n",
      "Epoch:  10\n",
      "training loss =  9.360616179678937\n",
      "Validation Loss: 9.8605\tTop 1 Validation Accuracy: 0.0025\t Top 5 Validation Accuracy: 0.0079\n",
      "loss 9.152898454666138\n",
      "loss 18.298385915756224\n",
      "loss 27.44656749725342\n",
      "loss 36.66482525825501\n",
      "loss 45.873155708312986\n",
      "loss 55.107723236083984\n",
      "loss 64.33898824691772\n",
      "loss 73.59320401191711\n",
      "loss 82.81525910377502\n",
      "loss 92.03434888839722\n",
      "loss 101.25792860984802\n",
      "Epoch:  11\n",
      "training loss =  9.205356895494804\n",
      "Validation Loss: 9.7845\tTop 1 Validation Accuracy: 0.0027\t Top 5 Validation Accuracy: 0.0090\n",
      "loss 9.033822917938233\n",
      "loss 18.09527557373047\n",
      "loss 27.201668605804443\n",
      "loss 36.331266994476316\n",
      "loss 45.552281665802\n",
      "loss 54.83574676513672\n",
      "loss 64.0308462047577\n",
      "loss 73.20231924057006\n",
      "loss 82.38304357528686\n",
      "loss 91.55990216255188\n",
      "loss 100.78816696166992\n",
      "Epoch:  12\n",
      "training loss =  9.163509019844824\n",
      "Validation Loss: 9.8443\tTop 1 Validation Accuracy: 0.0023\t Top 5 Validation Accuracy: 0.0074\n",
      "loss 9.058015727996827\n",
      "loss 18.136554231643675\n",
      "loss 27.197847595214842\n",
      "loss 36.2650887298584\n",
      "loss 45.34904693603516\n",
      "loss 54.40995112419128\n",
      "loss 63.466352434158324\n",
      "loss 72.52694604873658\n",
      "loss 81.59452861785888\n",
      "loss 90.6561012840271\n",
      "loss 99.7384082698822\n",
      "Epoch:  13\n",
      "training loss =  9.067458078157987\n",
      "Validation Loss: 9.7461\tTop 1 Validation Accuracy: 0.0031\t Top 5 Validation Accuracy: 0.0102\n",
      "loss 8.92250220298767\n",
      "loss 17.90217911720276\n",
      "loss 26.862567882537842\n",
      "loss 35.802469177246095\n",
      "loss 44.76874966621399\n",
      "loss 53.73877583503723\n",
      "loss 62.70496760368347\n",
      "loss 71.70407446861267\n",
      "loss 80.70002822875976\n",
      "loss 89.66736946105956\n",
      "loss 98.67838088035583\n",
      "Epoch:  14\n",
      "training loss =  8.971209985746754\n",
      "Validation Loss: 9.7240\tTop 1 Validation Accuracy: 0.0037\t Top 5 Validation Accuracy: 0.0115\n",
      "loss 8.804050321578979\n",
      "loss 17.629280967712404\n",
      "loss 26.44060154914856\n",
      "loss 35.31492560386658\n",
      "loss 44.16055161476135\n",
      "loss 52.99722074508667\n",
      "loss 61.860978002548215\n",
      "loss 70.72064953804016\n",
      "loss 79.58239382743835\n",
      "loss 88.44016318321228\n",
      "loss 97.31307192802429\n",
      "Epoch:  15\n",
      "training loss =  8.847133621895056\n",
      "Validation Loss: 9.6704\tTop 1 Validation Accuracy: 0.0040\t Top 5 Validation Accuracy: 0.0130\n",
      "loss 8.702735090255738\n",
      "loss 17.43527669906616\n",
      "loss 26.170044298171998\n",
      "loss 34.89873692512512\n",
      "loss 43.62293484687805\n",
      "loss 61.15269721984863\n",
      "loss 69.88875683784485\n",
      "loss 78.63795794487\n",
      "loss 87.41645512580871\n",
      "loss 96.24090846061706\n",
      "Epoch:  16\n",
      "training loss =  8.75005799832104\n",
      "Validation Loss: 9.6622\tTop 1 Validation Accuracy: 0.0045\t Top 5 Validation Accuracy: 0.0145\n",
      "loss 8.604335622787476\n",
      "loss 17.213536796569823\n",
      "loss 25.8719553565979\n",
      "loss 34.565966291427614\n",
      "loss 43.24696807861328\n",
      "loss 51.90755760192871\n",
      "loss 60.588263816833496\n",
      "loss 69.28518027305603\n",
      "loss 77.96688758850098\n",
      "loss 86.64168075561524\n",
      "loss 95.32961964607239\n",
      "Epoch:  17\n",
      "training loss =  8.666600161319156\n",
      "Validation Loss: 9.6117\tTop 1 Validation Accuracy: 0.0050\t Top 5 Validation Accuracy: 0.0165\n",
      "loss 8.504289350509644\n",
      "loss 17.05369080543518\n",
      "loss 25.619096956253053\n",
      "loss 34.16933846473694\n",
      "loss 42.70969648361206\n",
      "loss 51.24222075462341\n",
      "loss 59.80724606513977\n",
      "loss 68.4443528842926\n",
      "loss 77.22026000022888\n",
      "loss 85.98142627716065\n",
      "loss 94.82836553573608\n",
      "Epoch:  18\n",
      "training loss =  8.623989870222353\n",
      "Validation Loss: 9.7188\tTop 1 Validation Accuracy: 0.0044\t Top 5 Validation Accuracy: 0.0132\n",
      "loss 8.767506723403931\n",
      "loss 17.489172134399414\n",
      "loss 26.23023295402527\n",
      "loss 34.98261589050293\n",
      "loss 43.69476195335388\n",
      "loss 52.467208814620975\n",
      "loss 61.20565653800964\n",
      "loss 69.9619271659851\n",
      "loss 78.67701131820678\n",
      "loss 87.41875250816345\n",
      "loss 96.14261858940125\n",
      "Epoch:  19\n",
      "training loss =  8.740181781405168\n",
      "Validation Loss: 9.7257\tTop 1 Validation Accuracy: 0.0043\t Top 5 Validation Accuracy: 0.0138\n",
      "loss 8.550521640777587\n",
      "loss 17.07240433692932\n",
      "loss 25.656330194473266\n",
      "loss 34.18634920120239\n",
      "loss 42.714357175827026\n",
      "loss 51.241614780426026\n",
      "loss 59.770095100402834\n",
      "loss 68.38108615875244\n",
      "loss 77.01568654060364\n",
      "loss 85.7575329208374\n",
      "loss 94.56156916618347\n",
      "Epoch:  20\n",
      "training loss =  8.598558613722274\n",
      "Validation Loss: 9.6979\tTop 1 Validation Accuracy: 0.0041\t Top 5 Validation Accuracy: 0.0132\n",
      "loss 8.675736474990845\n",
      "loss 17.33103895187378\n",
      "loss 25.994458427429198\n",
      "loss 34.62203372955322\n",
      "loss 43.35363380432129\n",
      "loss 52.12175414085388\n",
      "loss 60.824906768798826\n",
      "loss 69.48311438560486\n",
      "loss 78.13200077056885\n",
      "loss 86.77885526657104\n",
      "loss 95.42630281448365\n",
      "Epoch:  21\n",
      "training loss =  8.674308845465132\n",
      "Validation Loss: 9.6541\tTop 1 Validation Accuracy: 0.0056\t Top 5 Validation Accuracy: 0.0177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 8.638602533340453\n",
      "loss 17.197217836380005\n",
      "loss 25.771636514663697\n",
      "loss 34.386673097610476\n",
      "loss 43.09919241905212\n",
      "loss 51.74867656707764\n",
      "loss 60.371345596313475\n",
      "loss 68.98691084861755\n",
      "loss 77.69519494056702\n",
      "loss 86.40499710083007\n",
      "loss 95.09026183128357\n",
      "Epoch:  22\n",
      "training loss =  8.644797807974781\n",
      "Validation Loss: 9.7223\tTop 1 Validation Accuracy: 0.0044\t Top 5 Validation Accuracy: 0.0145\n",
      "loss 8.511324834823608\n",
      "loss 17.03416223526001\n",
      "loss 25.539327058792114\n",
      "loss 34.01605225563049\n",
      "loss 42.524116086959836\n",
      "loss 51.057267837524414\n",
      "loss 59.77351448059082\n",
      "loss 68.57384805679321\n",
      "loss 77.32869032859803\n",
      "loss 86.03371976852416\n",
      "loss 94.72514276504516\n",
      "Epoch:  23\n",
      "training loss =  8.611895626397441\n",
      "Validation Loss: 9.7750\tTop 1 Validation Accuracy: 0.0040\t Top 5 Validation Accuracy: 0.0130\n",
      "loss 8.482422122955322\n",
      "loss 16.951132469177246\n",
      "loss 25.42479681968689\n",
      "loss 33.928729124069214\n",
      "loss 42.43674903869629\n",
      "loss 50.937898273468015\n",
      "loss 59.44325297355652\n",
      "loss 67.98518974304199\n",
      "loss 76.56659707069397\n",
      "loss 85.17132678985595\n",
      "loss 93.76718899726868\n",
      "Epoch:  24\n",
      "training loss =  8.525068989760584\n",
      "Validation Loss: 9.7867\tTop 1 Validation Accuracy: 0.0041\t Top 5 Validation Accuracy: 0.0136\n",
      "loss 8.434343070983887\n",
      "loss 16.910811595916748\n",
      "loss 25.39008355140686\n",
      "loss 33.88674251556397\n",
      "loss 42.36928816795349\n",
      "loss 50.84579225540161\n",
      "loss 59.325301523208616\n",
      "loss 67.82340000152588\n",
      "loss 76.3534339427948\n",
      "loss 84.85983587265015\n",
      "loss 93.37351034164429\n",
      "Epoch:  25\n",
      "training loss =  8.488917207546372\n",
      "Validation Loss: 9.7590\tTop 1 Validation Accuracy: 0.0052\t Top 5 Validation Accuracy: 0.0156\n",
      "loss 8.327096672058106\n",
      "loss 16.669041986465455\n",
      "loss 25.17400281906128\n",
      "loss 33.6195890045166\n",
      "loss 42.033784313201906\n",
      "loss 50.450921268463134\n",
      "loss 58.903488121032716\n",
      "loss 67.35834443092347\n",
      "loss 75.87477374076843\n",
      "loss 84.3629466342926\n",
      "loss 93.1014232635498\n",
      "Epoch:  26\n",
      "training loss =  8.466070658869024\n",
      "Validation Loss: 9.8426\tTop 1 Validation Accuracy: 0.0040\t Top 5 Validation Accuracy: 0.0124\n",
      "loss 8.50374189376831\n",
      "loss 16.957772378921508\n",
      "loss 25.423329029083252\n",
      "loss 33.84934917449951\n",
      "loss 42.26962533950805\n",
      "loss 50.826902084350586\n",
      "loss 59.380527849197385\n",
      "loss 67.908581199646\n",
      "loss 76.40684123039246\n",
      "loss 84.90698950767518\n",
      "loss 93.39496884346008\n",
      "Epoch:  27\n",
      "training loss =  8.490313960493898\n",
      "Validation Loss: 9.8028\tTop 1 Validation Accuracy: 0.0053\t Top 5 Validation Accuracy: 0.0154\n",
      "loss 8.30608633995056\n",
      "loss 16.639790840148926\n",
      "loss 24.9691725063324\n",
      "loss 33.32799898147583\n",
      "loss 41.667446784973144\n",
      "loss 49.99263625144958\n",
      "loss 58.30643634796142\n",
      "loss 66.7112603187561\n",
      "loss 75.06239414215088\n",
      "loss 83.42430830001831\n",
      "loss 91.78191480636596\n",
      "Epoch:  28\n",
      "training loss =  8.34389797989413\n",
      "Validation Loss: 9.7613\tTop 1 Validation Accuracy: 0.0055\t Top 5 Validation Accuracy: 0.0170\n",
      "loss 8.425221300125122\n",
      "loss 16.821575593948364\n",
      "loss 25.22171669960022\n",
      "loss 33.617236881256105\n",
      "loss 42.063666362762454\n",
      "loss 50.49064012527466\n",
      "loss 58.89593895912171\n",
      "loss 67.28995839118957\n",
      "loss 75.66811046600341\n",
      "loss 84.03083770751954\n",
      "loss 92.40533506393433\n",
      "Epoch:  29\n",
      "training loss =  8.400076586565525\n",
      "Validation Loss: 9.8438\tTop 1 Validation Accuracy: 0.0046\t Top 5 Validation Accuracy: 0.0145\n",
      "loss 8.180822925567627\n",
      "loss 16.38883442878723\n",
      "loss 24.633577432632446\n",
      "loss 32.87853615760803\n",
      "loss 41.103770885467526\n",
      "loss 49.339333868026735\n",
      "loss 57.59071715354919\n",
      "loss 65.8344179058075\n",
      "loss 74.05813659667969\n",
      "loss 82.28400545120239\n",
      "loss 90.59653985023499\n",
      "Epoch:  30\n",
      "training loss =  8.237492774030288\n",
      "Validation Loss: 9.8007\tTop 1 Validation Accuracy: 0.0055\t Top 5 Validation Accuracy: 0.0167\n",
      "loss 8.125506377220153\n",
      "loss 16.219604091644285\n",
      "loss 24.308549375534056\n",
      "loss 32.37400661468506\n",
      "loss 40.43643393039704\n",
      "loss 48.48812751770019\n",
      "loss 56.53571223735809\n",
      "loss 64.58341178894042\n",
      "loss 72.62835669994354\n",
      "loss 80.65889773368835\n",
      "loss 88.69499151229859\n",
      "Epoch:  31\n",
      "training loss =  8.063212798224937\n",
      "Validation Loss: 9.8254\tTop 1 Validation Accuracy: 0.0063\t Top 5 Validation Accuracy: 0.0185\n",
      "loss 8.003211569786071\n",
      "loss 16.011486845016478\n",
      "loss 24.0169753408432\n",
      "loss 32.0168390750885\n",
      "loss 40.00533719539642\n",
      "loss 48.005019822120666\n",
      "loss 56.001965975761415\n",
      "loss 63.99861588478088\n",
      "loss 71.99629666805268\n",
      "loss 79.9918239068985\n",
      "loss 87.99127090454101\n",
      "Epoch:  32\n",
      "training loss =  7.9992164763615285\n",
      "Validation Loss: 9.8163\tTop 1 Validation Accuracy: 0.0067\t Top 5 Validation Accuracy: 0.0194\n",
      "loss 7.970077238082886\n",
      "loss 15.931878314018249\n",
      "loss 23.885225186347963\n",
      "loss 31.84857801437378\n",
      "loss 39.806487116813656\n",
      "loss 47.78003555297852\n",
      "loss 55.7483675289154\n",
      "loss 63.718013229370115\n",
      "loss 71.68922347068786\n",
      "loss 79.66704941749573\n",
      "loss 87.64217272758484\n",
      "Epoch:  33\n",
      "training loss =  7.967199455919883\n",
      "Validation Loss: 9.8217\tTop 1 Validation Accuracy: 0.0067\t Top 5 Validation Accuracy: 0.0192\n",
      "loss 7.949345498085022\n",
      "loss 15.88974901676178\n",
      "loss 23.839560871124267\n",
      "loss 31.772187447547914\n",
      "loss 39.71516484260559\n",
      "loss 47.650135169029234\n",
      "loss 55.590022230148314\n",
      "loss 63.54153178691864\n",
      "loss 71.48440290927887\n",
      "loss 79.42187252998352\n",
      "loss 87.36530253410339\n",
      "Epoch:  34\n",
      "training loss =  7.942000743725317\n",
      "Validation Loss: 9.8093\tTop 1 Validation Accuracy: 0.0070\t Top 5 Validation Accuracy: 0.0200\n",
      "loss 7.90325620174408\n",
      "loss 15.809681415557861\n",
      "loss 23.715936732292175\n",
      "loss 31.62180655479431\n",
      "loss 39.53660686969757\n",
      "loss 47.4512035036087\n",
      "loss 55.35702231884002\n",
      "loss 63.259634947776796\n",
      "loss 71.17099667072296\n",
      "loss 79.09783877372742\n",
      "loss 87.0030837583542\n",
      "Epoch:  35\n",
      "training loss =  7.90952623447926\n",
      "Validation Loss: 9.8009\tTop 1 Validation Accuracy: 0.0069\t Top 5 Validation Accuracy: 0.0200\n",
      "loss 7.876541090011597\n",
      "loss 15.758349237442017\n",
      "loss 23.640170335769653\n",
      "loss 31.525451312065126\n",
      "loss 39.415076775550844\n",
      "loss 47.30251564979553\n",
      "loss 55.19252784252167\n",
      "loss 63.07957422733307\n",
      "loss 70.97590498924255\n",
      "loss 78.86980401992798\n",
      "loss 86.77743738651276\n",
      "Epoch:  36\n",
      "training loss =  7.888558387756348\n",
      "Validation Loss: 9.8004\tTop 1 Validation Accuracy: 0.0073\t Top 5 Validation Accuracy: 0.0209\n",
      "loss 7.865072746276855\n",
      "loss 15.721344728469848\n",
      "loss 23.586241903305055\n",
      "loss 31.45466160297394\n",
      "loss 39.315495419502255\n",
      "loss 47.18827703475952\n",
      "loss 55.06655002117157\n",
      "loss 62.93670433521271\n",
      "loss 70.8022633934021\n",
      "loss 78.67046557426453\n",
      "loss 86.55412819385529\n",
      "Epoch:  37\n",
      "training loss =  7.8687088729666295\n",
      "Validation Loss: 9.8276\tTop 1 Validation Accuracy: 0.0072\t Top 5 Validation Accuracy: 0.0209\n",
      "loss 7.83723650932312\n",
      "loss 15.687063374519347\n",
      "loss 23.5247367477417\n",
      "loss 31.368701529502868\n",
      "loss 39.217373986244205\n",
      "loss 47.06695786952972\n",
      "loss 54.91415551185608\n",
      "loss 62.76766266822815\n",
      "loss 70.62623304367065\n",
      "loss 78.49296207904816\n",
      "loss 86.35142401218414\n",
      "Epoch:  38\n",
      "training loss =  7.8502661667281775\n",
      "Validation Loss: 9.7973\tTop 1 Validation Accuracy: 0.0074\t Top 5 Validation Accuracy: 0.0218\n",
      "loss 7.812571034431458\n",
      "loss 15.628096461296082\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(modelname)\n",
    "\n",
    "train(model, train_dataloader, validation_dataloader, criterion, optimizer, lr_scheduler, modelpath, writer, device, epochs = num_Epochs)\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load saved model from checkpoint\n",
    "'''\n",
    "\n",
    "model, optimizer, lr_scheduler, train_loss, v_loss, v_acc, epoch = load(modelpath, model, optimizer, lr_scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6577\tTop 1 Validation Accuracy: 0.8654\n",
      "Accuracy:defaultdict(<class 'int'>, {'Top 1 Accuracy': 86.54392178672833, 'Top 5 Accuracy': 96.05128355238122, 'Top 10 Accuracy': 97.26604806369464, 'Top 20 Accuracy': 98.00954248748647, 'Top 30 Accuracy': 98.32860111816878, 'Top 50 Accuracy': 98.66814975265639, 'Top 100 Accuracy': 99.03404267775078})\t\n"
     ]
    }
   ],
   "source": [
    "v_loss, top1_acc, accuracy_dict= eval_classify(model, validation_dataloader, criterion, device)\n",
    "print('Validation Loss: {:.4f}\\tTop 1 Validation Accuracy: {:.4f}\\nAccuracy:{}\\t'.format(v_loss, top1_acc, accuracy_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
