{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 26 01:40:34 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  TITAN RTX           Off  | 00000000:04:00.0 Off |                  N/A |\r\n",
      "| 41%   45C    P0    71W / 280W |     11MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  TITAN RTX           Off  | 00000000:05:00.0 Off |                  N/A |\r\n",
      "| 53%   63C    P8    32W / 280W |     11MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  TITAN RTX           Off  | 00000000:08:00.0 Off |                  N/A |\r\n",
      "| 62%   72C    P8    37W / 280W |     11MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  TITAN RTX           Off  | 00000000:09:00.0 Off |                  N/A |\r\n",
      "| 57%   67C    P8    27W / 280W |     11MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   4  TITAN RTX           Off  | 00000000:84:00.0 Off |                  N/A |\r\n",
      "| 41%   29C    P8     3W / 280W |     11MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   5  TITAN RTX           Off  | 00000000:85:00.0 Off |                  N/A |\r\n",
      "| 41%   33C    P8    33W / 280W |     11MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   6  TITAN RTX           Off  | 00000000:88:00.0 Off |                  N/A |\r\n",
      "| 41%   30C    P8    19W / 280W |   2526MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   7  TITAN RTX           Off  | 00000000:89:00.0 Off |                  N/A |\r\n",
      "| 41%   26C    P8    13W / 280W |     11MiB / 24220MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### IMPORTING NECESSARY MODULES #########\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "sys.path.append('/home/ironman/abhishek/AliProducts/architectures/')\n",
    "sys.path.append('/home/ironman/abhishek/AliProducts/Helper/')\n",
    "\n",
    "from dataloader import mydataset, create_prime_dict \n",
    "from trainer import train, test_classify, eval_classify\n",
    "from Load_model import load\n",
    "\n",
    "\n",
    "\n",
    "from vit_pytorch import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataloading Scheme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlist = '/home/ironman/abhishek/AliProducts/Newlist/NEW_train_list1.txt'\n",
    "validlist = '/home/ironman/abhishek/AliProducts/Newlist/NEW_valid_list1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes =  50030\n"
     ]
    }
   ],
   "source": [
    "prime_dict = create_prime_dict(trainlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train Dataloader #### \n",
    "train_dataset = mydataset(trainlist, prime_dict, name='train')          \n",
    "train_dataloader = data.DataLoader(train_dataset, shuffle= True, batch_size = 2048, num_workers=16,pin_memory=True)\n",
    "\n",
    "\n",
    "#### Validation Dataloader #### \n",
    "validation_dataset = mydataset(validlist, prime_dict, name='valid')         \n",
    "validation_dataloader = data.DataLoader(validation_dataset, shuffle=False, batch_size = 256, num_workers=16,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ViT(\n",
       "    (patch_to_embedding): Linear(in_features=3072, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (transformer): Transformer(\n",
       "      (layers): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                  (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "                  (4): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                  (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "                  (4): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                  (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "                  (4): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                  (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "                  (4): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): ModuleList(\n",
       "          (0): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                  (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "                  (4): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): ModuleList(\n",
       "          (0): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): Attention(\n",
       "                (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "                (to_out): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (1): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): Residual(\n",
       "            (fn): PreNorm(\n",
       "              (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (fn): FeedForward(\n",
       "                (net): Sequential(\n",
       "                  (0): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "                  (1): GELU()\n",
       "                  (2): Dropout(p=0.1, inplace=False)\n",
       "                  (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "                  (4): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (to_cls_token): Identity()\n",
       "    (mlp_head): Sequential(\n",
       "      (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (2): GELU()\n",
       "      (3): Dropout(p=0.1, inplace=False)\n",
       "      (4): Linear(in_features=2048, out_features=50030, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ViT(\n",
    "    image_size = 256,\n",
    "    patch_size = 32,\n",
    "    num_classes = 50030,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1\n",
    ")\n",
    "\n",
    "\n",
    "model = nn.DataParallel(model,device_ids=[0,1,2,3]).to(device)\n",
    "model\n",
    "\n",
    "# preds = v(img, mask = mask) # (1, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4, momentum=0.9)\n",
    "\n",
    "\n",
    "# Epochs\n",
    "num_Epochs = 120\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 30, gamma = 0.1)\n",
    "\n",
    "#Cutmix\n",
    "# beta = 1\n",
    "# cutmix_prob = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'ViT'\n",
    "modelpath = '/home/ironman/abhishek/saved_model_checkpoints/AliProducts/' + modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 10.822515144348145\n",
      "loss 21.597200241088867\n",
      "loss 32.23590029716492\n",
      "loss 42.71700489997864\n",
      "loss 52.991988554000855\n",
      "Epoch:  1\n",
      "training loss =  10.549524871565454\n",
      "Validation Loss: 10.0993\tTop 1 Validation Accuracy: 0.0006\t Top 5 Validation Accuracy: 0.0021\n",
      "loss 9.9066588306427\n",
      "loss 19.672726259231567\n",
      "loss 38.660869722366336\n",
      "loss 47.85664821624756\n",
      "Epoch:  2\n",
      "training loss =  9.517297350245414\n",
      "Validation Loss: 9.0108\tTop 1 Validation Accuracy: 0.0045\t Top 5 Validation Accuracy: 0.0159\n",
      "loss 8.733815441131592\n",
      "loss 17.328718528747558\n",
      "loss 25.772779321670534\n",
      "loss 34.03513367652893\n",
      "loss 42.118423409461975\n",
      "Epoch:  3\n",
      "training loss =  8.376714614655475\n",
      "Validation Loss: 7.8984\tTop 1 Validation Accuracy: 0.0244\t Top 5 Validation Accuracy: 0.0687\n",
      "loss 7.53102397441864\n",
      "loss 14.948071246147157\n",
      "loss 22.23593794822693\n",
      "loss 29.378154759407042\n",
      "loss 36.36968928813934\n",
      "Epoch:  4\n",
      "training loss =  7.237522326785026\n",
      "Validation Loss: 6.9290\tTop 1 Validation Accuracy: 0.0680\t Top 5 Validation Accuracy: 0.1555\n",
      "loss 6.409135508537292\n",
      "loss 12.767364602088929\n",
      "loss 19.051996850967406\n",
      "loss 25.273854637145995\n",
      "loss 31.37019289970398\n",
      "Epoch:  5\n",
      "training loss =  6.250139040912655\n",
      "Validation Loss: 6.1249\tTop 1 Validation Accuracy: 0.1230\t Top 5 Validation Accuracy: 0.2518\n",
      "loss 5.615085830688477\n",
      "loss 11.396433296203613\n",
      "loss 16.897296915054323\n",
      "loss 22.3367542552948\n",
      "loss 27.834817266464235\n",
      "Epoch:  6\n",
      "training loss =  5.548944995557662\n",
      "Validation Loss: 5.6370\tTop 1 Validation Accuracy: 0.1682\t Top 5 Validation Accuracy: 0.3190\n",
      "loss 4.795299162864685\n",
      "loss 9.942855696678162\n",
      "loss 14.810677056312562\n",
      "loss 19.66667230129242\n",
      "loss 24.469686579704284\n",
      "Epoch:  7\n",
      "training loss =  4.8840754906908215\n",
      "Validation Loss: 5.2322\tTop 1 Validation Accuracy: 0.2088\t Top 5 Validation Accuracy: 0.3777\n",
      "loss 4.216844348907471\n",
      "loss 8.925359344482422\n",
      "loss 13.263529748916627\n",
      "loss 17.628353991508483\n",
      "loss 21.941284070014955\n",
      "Epoch:  8\n",
      "training loss =  4.379612903800799\n",
      "Validation Loss: 4.9245\tTop 1 Validation Accuracy: 0.2450\t Top 5 Validation Accuracy: 0.4242\n",
      "loss 3.7139963912963867\n",
      "loss 7.809248120784759\n",
      "loss 11.680767602920533\n",
      "loss 15.56072895526886\n",
      "loss 19.454518649578095\n",
      "Epoch:  9\n",
      "training loss =  3.892226965736142\n",
      "Validation Loss: 4.6962\tTop 1 Validation Accuracy: 0.2747\t Top 5 Validation Accuracy: 0.4614\n",
      "loss 3.2813345766067505\n",
      "loss 6.9332867217063905\n",
      "loss 10.401410529613495\n",
      "loss 13.899052760601045\n",
      "loss 17.42535542011261\n",
      "Epoch:  10\n",
      "training loss =  3.510132544332271\n",
      "Validation Loss: 4.5881\tTop 1 Validation Accuracy: 0.2940\t Top 5 Validation Accuracy: 0.4828\n",
      "loss 2.9164351654052734\n",
      "loss 6.96785660982132\n",
      "loss 10.73167564868927\n",
      "loss 14.005176937580108\n",
      "loss 17.226907954216003\n",
      "Epoch:  11\n",
      "training loss =  3.423042292646367\n",
      "Validation Loss: 4.4663\tTop 1 Validation Accuracy: 0.3136\t Top 5 Validation Accuracy: 0.5031\n",
      "loss 2.617009301185608\n",
      "loss 5.329627070426941\n",
      "loss 8.286054871082307\n",
      "loss 11.152957561016082\n",
      "loss 14.075269434452057\n",
      "Epoch:  12\n",
      "training loss =  2.8267868680062054\n",
      "Validation Loss: 4.3658\tTop 1 Validation Accuracy: 0.3308\t Top 5 Validation Accuracy: 0.5224\n",
      "loss 2.2775585627555848\n",
      "loss 5.218195843696594\n",
      "loss 7.763859021663666\n",
      "loss 10.572985541820525\n",
      "loss 13.535177075862885\n",
      "Epoch:  13\n",
      "training loss =  2.706910391505674\n",
      "Validation Loss: 4.4438\tTop 1 Validation Accuracy: 0.3297\t Top 5 Validation Accuracy: 0.5192\n",
      "loss 2.0511061465740204\n",
      "loss 4.544750939607621\n",
      "loss 6.816334186792374\n",
      "loss 9.166474279165268\n",
      "loss 11.57606684088707\n",
      "Epoch:  14\n",
      "training loss =  2.3297034276903963\n",
      "Validation Loss: 4.3904\tTop 1 Validation Accuracy: 0.3428\t Top 5 Validation Accuracy: 0.5342\n",
      "loss 1.7847757530212403\n",
      "loss 3.7078222322463987\n",
      "loss 5.752138079404831\n",
      "loss 7.855290803909302\n",
      "loss 10.025091450214386\n",
      "Epoch:  15\n",
      "training loss =  2.0267494136480977\n",
      "Validation Loss: 4.3972\tTop 1 Validation Accuracy: 0.3475\t Top 5 Validation Accuracy: 0.5370\n",
      "loss 1.5854586100578307\n",
      "loss 3.2837330257892607\n",
      "loss 6.441532692909241\n",
      "loss 8.666398295164107\n",
      "loss 10.697097852230073\n",
      "Epoch:  16\n",
      "training loss =  2.1463820867830044\n",
      "Validation Loss: 5.1404\tTop 1 Validation Accuracy: 0.2825\t Top 5 Validation Accuracy: 0.4591\n",
      "loss 1.5515741002559662\n",
      "loss 3.136489293575287\n",
      "loss 4.797273343801498\n",
      "loss 6.54179294347763\n",
      "loss 8.356655279397964\n",
      "Epoch:  17\n",
      "training loss =  1.6914517677945198\n",
      "Validation Loss: 4.4888\tTop 1 Validation Accuracy: 0.3526\t Top 5 Validation Accuracy: 0.5374\n",
      "loss 1.2954431974887848\n",
      "loss 3.5347608959674837\n",
      "loss 5.13931680560112\n",
      "loss 6.764153943061829\n",
      "loss 8.438134540319442\n",
      "Epoch:  18\n",
      "training loss =  1.6928860761707636\n",
      "Validation Loss: 4.5312\tTop 1 Validation Accuracy: 0.3548\t Top 5 Validation Accuracy: 0.5398\n",
      "loss 1.1797422695159911\n",
      "loss 2.4500571370124815\n",
      "loss 4.4686145281791685\n",
      "loss 5.972208338975906\n",
      "loss 7.526079598665238\n",
      "Epoch:  19\n",
      "training loss =  1.5158142335980915\n",
      "Validation Loss: 4.6177\tTop 1 Validation Accuracy: 0.3559\t Top 5 Validation Accuracy: 0.5402\n",
      "loss 1.080961235165596\n",
      "loss 2.314908867478371\n",
      "loss 4.836501560807228\n",
      "loss 6.37217878639698\n",
      "loss 7.842220606207848\n",
      "Epoch:  20\n",
      "training loss =  1.5619015941302554\n",
      "Validation Loss: 4.5038\tTop 1 Validation Accuracy: 0.3632\t Top 5 Validation Accuracy: 0.5481\n",
      "loss 1.014524801969528\n",
      "loss 2.11684059381485\n",
      "loss 3.295087460279465\n",
      "loss 4.635375479459762\n",
      "loss 7.248290648460388\n",
      "Epoch:  21\n",
      "training loss =  1.4548662607189562\n",
      "Validation Loss: 4.6427\tTop 1 Validation Accuracy: 0.3533\t Top 5 Validation Accuracy: 0.5363\n",
      "loss 0.99987175822258\n",
      "loss 2.05730193734169\n",
      "loss 3.1852039659023283\n",
      "loss 4.378764793872834\n",
      "loss 5.638856217861176\n",
      "Epoch:  22\n",
      "training loss =  1.1437601845899075\n",
      "Validation Loss: 4.6319\tTop 1 Validation Accuracy: 0.3600\t Top 5 Validation Accuracy: 0.5427\n",
      "loss 0.8883040028810502\n",
      "loss 1.8497737276554107\n",
      "loss 3.504529499411583\n",
      "loss 4.693881310820579\n",
      "loss 5.904929832816124\n",
      "Epoch:  23\n",
      "training loss =  1.189227629372542\n",
      "Validation Loss: 4.6189\tTop 1 Validation Accuracy: 0.3646\t Top 5 Validation Accuracy: 0.5471\n",
      "loss 0.853304762840271\n",
      "loss 1.772248986363411\n",
      "loss 2.761971790790558\n",
      "loss 5.180902866721153\n",
      "loss 7.016968645453453\n",
      "Epoch:  24\n",
      "training loss =  1.3962761587161812\n",
      "Validation Loss: 4.7390\tTop 1 Validation Accuracy: 0.3508\t Top 5 Validation Accuracy: 0.5318\n",
      "loss 0.873621353507042\n",
      "loss 1.7894126802682877\n",
      "loss 2.77566126704216\n",
      "loss 3.827881635427475\n",
      "loss 4.921810979247093\n",
      "Epoch:  25\n",
      "training loss =  1.002000420535211\n",
      "Validation Loss: 4.6527\tTop 1 Validation Accuracy: 0.3645\t Top 5 Validation Accuracy: 0.5464\n",
      "loss 0.7734848749637604\n",
      "loss 1.6160823917388916\n",
      "loss 2.5346254658699037\n",
      "loss 3.5213906854391097\n",
      "loss 4.57312770307064\n",
      "Epoch:  26\n",
      "training loss =  0.9325651308829835\n",
      "Validation Loss: 4.7504\tTop 1 Validation Accuracy: 0.3619\t Top 5 Validation Accuracy: 0.5434\n",
      "loss 0.7540573954582215\n",
      "loss 1.5754639959335328\n",
      "loss 2.4425903445482255\n",
      "loss 5.786654706597329\n",
      "loss 7.748090520501137\n",
      "Epoch:  27\n",
      "training loss =  1.5156294099932952\n",
      "Validation Loss: 4.7495\tTop 1 Validation Accuracy: 0.3557\t Top 5 Validation Accuracy: 0.5348\n",
      "loss 0.795089328289032\n",
      "loss 1.6301628345251082\n",
      "loss 2.517920096516609\n",
      "loss 3.4658999878168104\n",
      "loss 4.4747757428884505\n",
      "Epoch:  28\n",
      "training loss =  1.084688911013466\n",
      "Validation Loss: 5.4593\tTop 1 Validation Accuracy: 0.2800\t Top 5 Validation Accuracy: 0.4497\n",
      "loss 0.9885422319173813\n",
      "loss 1.8250603479146958\n",
      "loss 2.7126738584041594\n",
      "loss 3.650768226981163\n",
      "loss 4.640197069644928\n",
      "Epoch:  29\n",
      "training loss =  0.9479816538824452\n",
      "Validation Loss: 4.8683\tTop 1 Validation Accuracy: 0.3469\t Top 5 Validation Accuracy: 0.5249\n",
      "loss 0.7238429301977157\n",
      "loss 1.4683962631225587\n",
      "loss 2.268387954831123\n",
      "loss 3.1306813549995423\n",
      "loss 4.78976768374443\n",
      "Epoch:  30\n",
      "training loss =  0.9765353169587019\n",
      "Validation Loss: 4.8197\tTop 1 Validation Accuracy: 0.3570\t Top 5 Validation Accuracy: 0.5360\n",
      "loss 0.5926496902108193\n",
      "loss 1.104966336786747\n",
      "loss 1.5811018338799476\n",
      "loss 2.0366459754109383\n",
      "loss 2.471681134402752\n",
      "Epoch:  31\n",
      "training loss =  0.48826155087930695\n",
      "Validation Loss: 4.5522\tTop 1 Validation Accuracy: 0.3997\t Top 5 Validation Accuracy: 0.5758\n",
      "loss 0.3723282080888748\n",
      "loss 0.7510437929630279\n",
      "loss 1.1329502686858177\n",
      "loss 1.5082105833292008\n",
      "loss 1.8823788887262345\n",
      "Epoch:  32\n",
      "training loss =  0.3754684601327498\n",
      "Validation Loss: 4.5260\tTop 1 Validation Accuracy: 0.4068\t Top 5 Validation Accuracy: 0.5818\n",
      "loss 0.3353724333643913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.6680206391215324\n",
      "loss 1.0040175610780715\n",
      "loss 1.3411113026738166\n",
      "loss 1.6800301298499107\n",
      "Epoch:  33\n",
      "training loss =  0.33647634608925675\n",
      "Validation Loss: 4.5044\tTop 1 Validation Accuracy: 0.4088\t Top 5 Validation Accuracy: 0.5856\n",
      "loss 0.30627839744091034\n",
      "loss 0.612277209609747\n",
      "loss 0.9245934142172336\n",
      "loss 1.237934525758028\n",
      "loss 1.5506626169383526\n",
      "Epoch:  34\n",
      "training loss =  0.3106356358035005\n",
      "Validation Loss: 4.4921\tTop 1 Validation Accuracy: 0.4105\t Top 5 Validation Accuracy: 0.5868\n",
      "loss 0.28877111107110975\n",
      "loss 0.5790776017308236\n",
      "loss 0.86720927760005\n",
      "loss 1.16431432813406\n",
      "loss 1.4614444233477115\n",
      "Epoch:  35\n",
      "training loss =  0.29208808652252605\n",
      "Validation Loss: 4.5115\tTop 1 Validation Accuracy: 0.4111\t Top 5 Validation Accuracy: 0.5871\n",
      "loss 0.273321919888258\n",
      "loss 0.5496798089146614\n",
      "loss 0.8253349187970161\n",
      "loss 1.1069909557700157\n",
      "loss 1.3861771747469902\n",
      "Epoch:  36\n",
      "training loss =  0.2778615283665897\n",
      "Validation Loss: 4.5078\tTop 1 Validation Accuracy: 0.4112\t Top 5 Validation Accuracy: 0.5872\n",
      "loss 0.2598495350778103\n",
      "loss 0.5212943242490291\n",
      "loss 0.7902472318708896\n",
      "loss 1.0580610725283623\n",
      "loss 1.3273370955884456\n",
      "Epoch:  37\n",
      "training loss =  0.26545117205853086\n",
      "Validation Loss: 4.4778\tTop 1 Validation Accuracy: 0.4138\t Top 5 Validation Accuracy: 0.5899\n",
      "loss 0.2508281992375851\n",
      "loss 0.5041785033047199\n",
      "loss 0.7642390315234661\n",
      "loss 1.020656577795744\n",
      "loss 1.2790550783276557\n",
      "Epoch:  38\n",
      "training loss =  0.25660180951729955\n",
      "Validation Loss: 4.4916\tTop 1 Validation Accuracy: 0.4132\t Top 5 Validation Accuracy: 0.5888\n",
      "loss 0.2365066699683666\n",
      "loss 0.4828475688397884\n",
      "loss 0.7301288402080536\n",
      "loss 0.9792303518950939\n",
      "loss 1.231889695674181\n",
      "Epoch:  39\n",
      "training loss =  0.24761541809538284\n",
      "Validation Loss: 4.4681\tTop 1 Validation Accuracy: 0.4140\t Top 5 Validation Accuracy: 0.5902\n",
      "loss 0.23514914080500604\n",
      "loss 0.4696353390812874\n",
      "loss 0.7095998957753181\n",
      "loss 0.9513349866867066\n",
      "loss 1.1961811317503452\n",
      "Epoch:  40\n",
      "training loss =  0.23990375773726608\n",
      "Validation Loss: 4.4722\tTop 1 Validation Accuracy: 0.4146\t Top 5 Validation Accuracy: 0.5901\n",
      "loss 0.2266744776070118\n",
      "loss 0.45716375231742856\n",
      "loss 0.6903831937909126\n",
      "loss 0.9287779089808464\n",
      "loss 1.1674389031529426\n",
      "Epoch:  41\n",
      "training loss =  0.23460414006019667\n",
      "Validation Loss: 4.4629\tTop 1 Validation Accuracy: 0.4150\t Top 5 Validation Accuracy: 0.5903\n",
      "loss 0.2202507098019123\n",
      "loss 0.44298446729779245\n",
      "loss 0.6734601029753685\n",
      "loss 0.9073638600111008\n",
      "loss 1.1417065632343293\n",
      "Epoch:  42\n",
      "training loss =  0.22893412697979873\n",
      "Validation Loss: 4.4673\tTop 1 Validation Accuracy: 0.4158\t Top 5 Validation Accuracy: 0.5900\n",
      "loss 0.21981215998530387\n",
      "loss 0.43819665148854253\n",
      "loss 0.6616216279566288\n",
      "loss 0.8869337105751037\n",
      "loss 1.1158597466349602\n",
      "Epoch:  43\n",
      "training loss =  0.22400783988640463\n",
      "Validation Loss: 4.4531\tTop 1 Validation Accuracy: 0.4150\t Top 5 Validation Accuracy: 0.5901\n",
      "loss 0.21140687689185142\n",
      "loss 0.4303321725130081\n",
      "loss 0.6474712404608727\n",
      "loss 0.869099083095789\n",
      "loss 1.0935091811418534\n",
      "Epoch:  44\n",
      "training loss =  0.21906506141527093\n",
      "Validation Loss: 4.4421\tTop 1 Validation Accuracy: 0.4160\t Top 5 Validation Accuracy: 0.5916\n",
      "loss 0.20702796801924706\n",
      "loss 0.42077683329582216\n",
      "loss 0.6376357859373093\n",
      "loss 0.8540885178744793\n",
      "loss 1.0767025865614415\n",
      "Epoch:  45\n",
      "training loss =  0.21524089722217415\n",
      "Validation Loss: 4.4344\tTop 1 Validation Accuracy: 0.4171\t Top 5 Validation Accuracy: 0.5922\n",
      "loss 0.20330336302518845\n",
      "loss 0.4140953513979912\n",
      "loss 0.6237522983551025\n",
      "loss 0.8393789200484753\n",
      "loss 1.0545736399292946\n",
      "Epoch:  46\n",
      "training loss =  0.21122247055708934\n",
      "Validation Loss: 4.4352\tTop 1 Validation Accuracy: 0.4162\t Top 5 Validation Accuracy: 0.5911\n",
      "loss 0.20146164074540138\n",
      "loss 0.40549695447087286\n",
      "loss 0.6132548446953296\n",
      "loss 0.8213566714525222\n",
      "loss 1.0333572618663311\n",
      "Epoch:  47\n",
      "training loss =  0.20756874664974728\n",
      "Validation Loss: 4.4191\tTop 1 Validation Accuracy: 0.4164\t Top 5 Validation Accuracy: 0.5916\n",
      "loss 0.19830750539898873\n",
      "loss 0.40168252572417257\n",
      "loss 0.6039637735486031\n",
      "loss 0.8101682080328465\n",
      "loss 1.018559927493334\n",
      "Epoch:  48\n",
      "training loss =  0.2041724384527841\n",
      "Validation Loss: 4.4140\tTop 1 Validation Accuracy: 0.4166\t Top 5 Validation Accuracy: 0.5924\n",
      "loss 0.19284963548183442\n",
      "loss 0.3892007359862328\n",
      "loss 0.5895040057599544\n",
      "loss 0.7913096037507057\n",
      "loss 0.9993648037314415\n",
      "Epoch:  49\n",
      "training loss =  0.20071771030696176\n",
      "Validation Loss: 4.4135\tTop 1 Validation Accuracy: 0.4170\t Top 5 Validation Accuracy: 0.5925\n",
      "loss 0.1901082557439804\n",
      "loss 0.38205922722816466\n",
      "loss 0.5809210966527462\n",
      "loss 0.7832419790327549\n",
      "loss 0.9857219141721726\n",
      "Epoch:  50\n",
      "training loss =  0.19790172402700074\n",
      "Validation Loss: 4.4103\tTop 1 Validation Accuracy: 0.4165\t Top 5 Validation Accuracy: 0.5920\n",
      "loss 0.1876896046102047\n",
      "loss 0.3822829358279705\n",
      "loss 0.578860980272293\n",
      "loss 0.7755091290175915\n",
      "loss 0.9785304366052151\n",
      "Epoch:  51\n",
      "training loss =  0.19622377067697133\n",
      "Validation Loss: 4.4065\tTop 1 Validation Accuracy: 0.4165\t Top 5 Validation Accuracy: 0.5922\n",
      "loss 0.18477887079119681\n",
      "loss 0.37565145701169966\n",
      "loss 0.5692783738672733\n",
      "loss 0.7658513751626015\n",
      "loss 0.9631263725459576\n",
      "Epoch:  52\n",
      "training loss =  0.19318933734040467\n",
      "Validation Loss: 4.3932\tTop 1 Validation Accuracy: 0.4179\t Top 5 Validation Accuracy: 0.5928\n",
      "loss 0.18412864625453948\n",
      "loss 0.37309192955493925\n",
      "loss 0.5616196112334728\n",
      "loss 0.7528698216378689\n",
      "loss 0.9476603080332279\n",
      "Epoch:  53\n",
      "training loss =  0.19015542216759793\n",
      "Validation Loss: 4.3796\tTop 1 Validation Accuracy: 0.4177\t Top 5 Validation Accuracy: 0.5933\n",
      "loss 0.18093979299068452\n",
      "loss 0.3659339460730553\n",
      "loss 0.5522301894426346\n",
      "loss 0.7418734674155713\n",
      "loss 0.9359385533630848\n",
      "Epoch:  54\n",
      "training loss =  0.18783600092363015\n",
      "Validation Loss: 4.3977\tTop 1 Validation Accuracy: 0.4166\t Top 5 Validation Accuracy: 0.5920\n",
      "loss 0.1804266482591629\n",
      "loss 0.3635421821475029\n",
      "loss 0.5513008445501327\n",
      "loss 0.9275892934203148\n",
      "Epoch:  55\n",
      "training loss =  0.1863248371552649\n",
      "Validation Loss: 4.3811\tTop 1 Validation Accuracy: 0.4171\t Top 5 Validation Accuracy: 0.5928\n",
      "loss 0.17775073647499084\n",
      "loss 0.35801912665367125\n",
      "loss 0.5429657007753849\n",
      "loss 0.7303684936463832\n",
      "loss 0.9195796537399292\n",
      "Epoch:  56\n",
      "training loss =  0.1846615936633923\n",
      "Validation Loss: 4.3789\tTop 1 Validation Accuracy: 0.4174\t Top 5 Validation Accuracy: 0.5931\n",
      "loss 0.17561811923980714\n",
      "loss 0.3549556039273739\n",
      "loss 0.5386982822418213\n",
      "loss 0.7268723964691162\n",
      "loss 0.9156957955658436\n",
      "Epoch:  57\n",
      "training loss =  0.18361666241138103\n",
      "Validation Loss: 4.3614\tTop 1 Validation Accuracy: 0.4174\t Top 5 Validation Accuracy: 0.5929\n",
      "loss 0.17475387170910836\n",
      "loss 0.3542703779041767\n",
      "loss 0.5361061349511147\n",
      "loss 0.720155328810215\n",
      "loss 0.9029294620454311\n",
      "Epoch:  58\n",
      "training loss =  0.18119169361621357\n",
      "Validation Loss: 4.3736\tTop 1 Validation Accuracy: 0.4170\t Top 5 Validation Accuracy: 0.5934\n",
      "loss 0.17003024131059646\n",
      "loss 0.34535042822360995\n",
      "loss 0.5223451772332192\n",
      "loss 0.699352076202631\n",
      "loss 0.8851678320765495\n",
      "Epoch:  59\n",
      "training loss =  0.17795544549179593\n",
      "Validation Loss: 4.3672\tTop 1 Validation Accuracy: 0.4177\t Top 5 Validation Accuracy: 0.5927\n",
      "loss 0.17040433540940284\n",
      "loss 0.34499641343951226\n",
      "loss 0.5208663080632686\n",
      "loss 0.7042181842029095\n",
      "loss 0.8876445160806179\n",
      "Epoch:  60\n",
      "training loss =  0.17836497882180077\n",
      "Validation Loss: 4.3480\tTop 1 Validation Accuracy: 0.4184\t Top 5 Validation Accuracy: 0.5947\n",
      "loss 0.16473776549100877\n",
      "loss 0.32763941869139673\n",
      "loss 0.48989285103976726\n",
      "loss 0.653095832541585\n",
      "loss 0.8164799753576517\n",
      "Epoch:  61\n",
      "training loss =  0.16309388004672185\n",
      "Validation Loss: 4.3592\tTop 1 Validation Accuracy: 0.4193\t Top 5 Validation Accuracy: 0.5951\n",
      "loss 0.16119887664914131\n",
      "loss 0.3206376120448112\n",
      "loss 0.4824194426834583\n",
      "loss 0.6426256158202887\n",
      "loss 0.8035963145643472\n",
      "Epoch:  62\n",
      "training loss =  0.1610207843507151\n",
      "Validation Loss: 4.3511\tTop 1 Validation Accuracy: 0.4199\t Top 5 Validation Accuracy: 0.5957\n",
      "loss 0.1582988914847374\n",
      "loss 0.31706403359770774\n",
      "loss 0.4733115167915821\n",
      "loss 0.6304303567111492\n",
      "loss 0.7898719701170921\n",
      "Epoch:  63\n",
      "training loss =  0.1580814244292623\n",
      "Validation Loss: 4.3517\tTop 1 Validation Accuracy: 0.4206\t Top 5 Validation Accuracy: 0.5959\n",
      "loss 0.15751405403017998\n",
      "loss 0.31523764967918394\n",
      "loss 0.4732819853723049\n",
      "loss 0.6334552302956581\n",
      "loss 0.7880048047006131\n",
      "Epoch:  64\n",
      "training loss =  0.1575178426000283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 4.3566\tTop 1 Validation Accuracy: 0.4200\t Top 5 Validation Accuracy: 0.5957\n",
      "loss 0.3103577707707882\n",
      "loss 0.4672184452414513\n",
      "loss 0.6241054435819388\n",
      "loss 0.7790831629186868\n",
      "Epoch:  65\n",
      "training loss =  0.15591441382982318\n",
      "Validation Loss: 4.3528\tTop 1 Validation Accuracy: 0.4205\t Top 5 Validation Accuracy: 0.5961\n",
      "loss 0.15593709394335747\n",
      "loss 0.3116811175644398\n",
      "loss 0.46599105320870876\n",
      "loss 0.62258535631001\n",
      "loss 0.7783322159945965\n",
      "Epoch:  66\n",
      "training loss =  0.15589404090059747\n",
      "Validation Loss: 4.3487\tTop 1 Validation Accuracy: 0.4208\t Top 5 Validation Accuracy: 0.5966\n",
      "loss 0.1555816727131605\n",
      "loss 0.311201825812459\n",
      "loss 0.4666702013462782\n",
      "loss 0.6206740867346525\n",
      "loss 0.7764394406229258\n",
      "Epoch:  67\n",
      "training loss =  0.15551955861260566\n",
      "Validation Loss: 4.3479\tTop 1 Validation Accuracy: 0.4211\t Top 5 Validation Accuracy: 0.5965\n",
      "loss 0.15232408449053764\n",
      "loss 0.30744159646332264\n",
      "loss 0.4601302193850279\n",
      "loss 0.6129221346229314\n",
      "loss 0.7668746693432331\n",
      "Epoch:  68\n",
      "training loss =  0.15320341951019473\n",
      "Validation Loss: 4.3505\tTop 1 Validation Accuracy: 0.4206\t Top 5 Validation Accuracy: 0.5964\n",
      "loss 0.15344954267144204\n",
      "loss 0.306642941981554\n",
      "loss 0.612861836925149\n",
      "loss 0.7682268492877483\n",
      "Epoch:  69\n",
      "training loss =  0.1538820859688006\n",
      "Validation Loss: 4.3503\tTop 1 Validation Accuracy: 0.4209\t Top 5 Validation Accuracy: 0.5964\n",
      "loss 0.15429520227015017\n",
      "loss 0.3075910805910826\n",
      "loss 0.4621621961146593\n",
      "loss 0.6166298354417086\n",
      "Epoch:  70\n",
      "training loss =  0.15388998694771486\n",
      "Validation Loss: 4.3432\tTop 1 Validation Accuracy: 0.4218\t Top 5 Validation Accuracy: 0.5972\n",
      "loss 0.1531418679654598\n",
      "loss 0.307374594733119\n",
      "loss 0.46022337950766085\n",
      "loss 0.6131015273183584\n",
      "loss 0.7640785208344459\n",
      "Epoch:  71\n",
      "training loss =  0.1532156367471321\n",
      "Validation Loss: 4.3493\tTop 1 Validation Accuracy: 0.4211\t Top 5 Validation Accuracy: 0.5965\n",
      "loss 0.1534856876730919\n",
      "loss 0.3065886087715626\n",
      "loss 0.4603054661303759\n",
      "loss 0.6115823340415955\n",
      "loss 0.7649864844977856\n",
      "Epoch:  72\n",
      "training loss =  0.15300631079581573\n",
      "Validation Loss: 4.3463\tTop 1 Validation Accuracy: 0.4213\t Top 5 Validation Accuracy: 0.5963\n",
      "loss 0.1486423484236002\n",
      "loss 0.3010961500555277\n",
      "loss 0.4540382272750139\n",
      "loss 0.6085812202095986\n",
      "loss 0.7633029583841562\n",
      "Epoch:  73\n",
      "training loss =  0.15279276181253598\n",
      "Validation Loss: 4.3475\tTop 1 Validation Accuracy: 0.4209\t Top 5 Validation Accuracy: 0.5965\n",
      "loss 0.15091934591531753\n",
      "loss 0.30532514400780203\n",
      "loss 0.4542639321088791\n",
      "loss 0.6063319912552834\n",
      "loss 0.7597246623039245\n",
      "Epoch:  74\n",
      "training loss =  0.15215017404005254\n",
      "Validation Loss: 4.3487\tTop 1 Validation Accuracy: 0.4211\t Top 5 Validation Accuracy: 0.5964\n",
      "loss 0.1489429958164692\n",
      "loss 0.29984264969825747\n",
      "loss 0.45056559301912785\n",
      "loss 0.6034604456275702\n",
      "loss 0.7580273235589265\n",
      "Epoch:  75\n",
      "training loss =  0.1520444800769039\n",
      "Validation Loss: 4.3447\tTop 1 Validation Accuracy: 0.4213\t Top 5 Validation Accuracy: 0.5969\n",
      "loss 0.15102526418864726\n",
      "loss 0.30349018149077894\n",
      "loss 0.4530621176958084\n",
      "loss 0.6043419659137725\n",
      "loss 0.7550262290984392\n",
      "Epoch:  76\n",
      "training loss =  0.15103839106000155\n",
      "Validation Loss: 4.3434\tTop 1 Validation Accuracy: 0.4217\t Top 5 Validation Accuracy: 0.5972\n",
      "loss 0.1497787619382143\n",
      "loss 0.3003902270644903\n",
      "loss 0.4519907872378826\n",
      "loss 0.6038427601009607\n",
      "loss 0.7558182018995285\n",
      "Epoch:  77\n",
      "training loss =  0.15134824792311774\n",
      "Validation Loss: 4.3447\tTop 1 Validation Accuracy: 0.4213\t Top 5 Validation Accuracy: 0.5967\n",
      "loss 0.14987542487680913\n",
      "loss 0.3004172400385141\n",
      "loss 0.45274271443486214\n",
      "loss 0.6038663411140441\n",
      "loss 0.7557930840551853\n",
      "Epoch:  78\n",
      "training loss =  0.1511715521111334\n",
      "Validation Loss: 4.3431\tTop 1 Validation Accuracy: 0.4217\t Top 5 Validation Accuracy: 0.5970\n",
      "loss 0.1501308660954237\n",
      "loss 0.30055017851293087\n",
      "loss 0.45066980734467504\n",
      "loss 0.601515716612339\n",
      "loss 0.750334889665246\n",
      "Epoch:  79\n",
      "training loss =  0.15030919458958314\n",
      "Validation Loss: 4.3446\tTop 1 Validation Accuracy: 0.4215\t Top 5 Validation Accuracy: 0.5970\n",
      "loss 0.14762028351426124\n",
      "loss 0.2987115839868784\n",
      "loss 0.4498838917165995\n",
      "loss 0.5984025354683399\n",
      "loss 0.7464870531857014\n",
      "Epoch:  80\n",
      "training loss =  0.14939896719490023\n",
      "Validation Loss: 4.3421\tTop 1 Validation Accuracy: 0.4218\t Top 5 Validation Accuracy: 0.5971\n",
      "loss 0.1489734783768654\n",
      "loss 0.29810246340930463\n",
      "loss 0.44967842780053613\n",
      "loss 0.6011472366005183\n",
      "loss 0.7537367824465037\n",
      "Epoch:  81\n",
      "training loss =  0.151059511070736\n",
      "Validation Loss: 4.3387\tTop 1 Validation Accuracy: 0.4214\t Top 5 Validation Accuracy: 0.5970\n",
      "loss 0.15105202227830886\n",
      "loss 0.30116514235734937\n",
      "loss 0.45047222390770914\n",
      "loss 0.5989067071676254\n",
      "loss 0.7489204657077789\n",
      "Epoch:  82\n",
      "training loss =  0.1496316134768853\n",
      "Validation Loss: 4.3407\tTop 1 Validation Accuracy: 0.4216\t Top 5 Validation Accuracy: 0.5970\n",
      "loss 0.15037362664937973\n",
      "loss 0.3002818141132593\n",
      "loss 0.4482903529703617\n",
      "loss 0.5982296553999186\n",
      "loss 0.7488563349843025\n",
      "Epoch:  83\n",
      "training loss =  0.14994992307729002\n",
      "Validation Loss: 4.3407\tTop 1 Validation Accuracy: 0.4216\t Top 5 Validation Accuracy: 0.5968\n",
      "loss 0.14937422260642053\n",
      "loss 0.2969908507168293\n",
      "loss 0.4482624077796936\n",
      "loss 0.5959741574525833\n",
      "loss 0.747131228595972\n",
      "Epoch:  84\n",
      "training loss =  0.1495274075394054\n",
      "Validation Loss: 4.3338\tTop 1 Validation Accuracy: 0.4221\t Top 5 Validation Accuracy: 0.5975\n",
      "loss 0.14904772348701953\n",
      "loss 0.2978075254708529\n",
      "loss 0.44541249714791775\n",
      "loss 0.5949586108326912\n",
      "loss 0.7414566607773304\n",
      "Epoch:  85\n",
      "training loss =  0.1484130169499478\n",
      "Validation Loss: 4.3445\tTop 1 Validation Accuracy: 0.4216\t Top 5 Validation Accuracy: 0.5967\n",
      "loss 0.14936678245663643\n",
      "loss 0.2969334039092064\n",
      "loss 0.44776614852249624\n",
      "loss 0.5973617354780436\n",
      "loss 0.7457810966670513\n",
      "Epoch:  86\n",
      "training loss =  0.14934152600576553\n",
      "Validation Loss: 4.3375\tTop 1 Validation Accuracy: 0.4221\t Top 5 Validation Accuracy: 0.5974\n",
      "loss 0.1492718555033207\n",
      "loss 0.29639368124306203\n",
      "loss 0.4452265365421772\n",
      "loss 0.5959344778954982\n",
      "loss 0.7448327562212944\n",
      "Epoch:  87\n",
      "training loss =  0.1489578555438587\n",
      "Validation Loss: 4.3373\tTop 1 Validation Accuracy: 0.4215\t Top 5 Validation Accuracy: 0.5968\n",
      "loss 0.14662896789610386\n",
      "loss 0.29523911513388157\n",
      "loss 0.44325511157512665\n",
      "loss 0.5922767540812492\n",
      "loss 0.7422177568078041\n",
      "Epoch:  88\n",
      "training loss =  0.14857111128864528\n",
      "Validation Loss: 4.3415\tTop 1 Validation Accuracy: 0.4214\t Top 5 Validation Accuracy: 0.5969\n",
      "loss 0.14755838848650454\n",
      "loss 0.29613858230412005\n",
      "loss 0.4443079122900963\n",
      "loss 0.5941694519668818\n",
      "loss 0.7447826285660267\n",
      "Epoch:  89\n",
      "training loss =  0.14905154860491376\n",
      "Validation Loss: 4.3382\tTop 1 Validation Accuracy: 0.4214\t Top 5 Validation Accuracy: 0.5970\n",
      "loss 0.1460791788995266\n",
      "loss 0.2953249081224203\n",
      "loss 0.44018462859094143\n",
      "loss 0.5886814860254526\n",
      "loss 0.7352523774653673\n",
      "Epoch:  90\n",
      "training loss =  0.14705765907980983\n",
      "Validation Loss: 4.3385\tTop 1 Validation Accuracy: 0.4213\t Top 5 Validation Accuracy: 0.5974\n",
      "loss 0.14812914721667766\n",
      "loss 0.2937628158181906\n",
      "loss 0.4403811313211918\n",
      "loss 0.5868299613147974\n",
      "loss 0.7330788987129927\n",
      "Epoch:  91\n",
      "training loss =  0.1468351775606116\n",
      "Validation Loss: 4.3379\tTop 1 Validation Accuracy: 0.4214\t Top 5 Validation Accuracy: 0.5975\n",
      "loss 0.1452875756472349\n",
      "loss 0.2935393211990595\n",
      "loss 0.43866290114820006\n",
      "loss 0.5833757963776588\n",
      "loss 0.7289114275574684\n",
      "Epoch:  92\n",
      "training loss =  0.14582959125689465\n",
      "Validation Loss: 4.3383\tTop 1 Validation Accuracy: 0.4216\t Top 5 Validation Accuracy: 0.5973\n",
      "loss 0.14521866001188755\n",
      "loss 0.2926078740507364\n",
      "loss 0.4404857963323593\n",
      "loss 0.5871318691968918\n",
      "loss 0.7346841707825661\n",
      "Epoch:  93\n",
      "training loss =  0.14686609808650378\n",
      "Validation Loss: 4.3378\tTop 1 Validation Accuracy: 0.4216\t Top 5 Validation Accuracy: 0.5974\n",
      "loss 0.14809445425868034\n",
      "loss 0.29538206428289415\n",
      "loss 0.4428223703801632\n",
      "loss 0.5908435110002757\n",
      "loss 0.7353253046423197\n",
      "Epoch:  94\n",
      "training loss =  0.14693973545762276\n",
      "Validation Loss: 4.3384\tTop 1 Validation Accuracy: 0.4217\t Top 5 Validation Accuracy: 0.5973\n",
      "loss 0.14941726103425026\n",
      "loss 0.2967915336787701\n",
      "loss 0.4420759093761444\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-62ad8ad2c41f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_Epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/abhishek/AliProducts/Helper/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, test_loader, criterion, optimizer, lr_scheduler, modelpath, writer, device, epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_num\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m99\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(modelname)\n",
    "\n",
    "train(model, train_dataloader, validation_dataloader, criterion, optimizer, lr_scheduler, modelpath, writer, device, epochs = num_Epochs)\n",
    "\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load saved model from checkpoint  #####\n",
    "model, optimizer, lr_scheduler, train_loss, v_loss, v_acc, epoch = load(modelpath, model, optimizer, lr_scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6577\tTop 1 Validation Accuracy: 0.8654\n",
      "Accuracy:defaultdict(<class 'int'>, {'Top 1 Accuracy': 86.54392178672833, 'Top 5 Accuracy': 96.05128355238122, 'Top 10 Accuracy': 97.26604806369464, 'Top 20 Accuracy': 98.00954248748647, 'Top 30 Accuracy': 98.32860111816878, 'Top 50 Accuracy': 98.66814975265639, 'Top 100 Accuracy': 99.03404267775078})\t\n"
     ]
    }
   ],
   "source": [
    "v_loss, top1_acc, accuracy_dict= eval_classify(model, validation_dataloader, criterion, device)\n",
    "print('Validation Loss: {:.4f}\\tTop 1 Validation Accuracy: {:.4f}\\nAccuracy:{}\\t'.format(v_loss, top1_acc, accuracy_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
