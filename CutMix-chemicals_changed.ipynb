{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul 10 19:26:05 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.39       Driver Version: 418.39       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 41%   26C    P8    15W / 280W |   2321MiB / 24190MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 60%   74C    P2    68W / 280W |  12167MiB / 24190MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:08:00.0 Off |                  N/A |\n",
      "| 74%   82C    P2    88W / 280W |  11959MiB / 24190MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN RTX           Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 41%   32C    P8    15W / 280W |     10MiB / 24190MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  TITAN RTX           Off  | 00000000:84:00.0 Off |                  N/A |\n",
      "| 86%   86C    P2   137W / 280W |  13627MiB / 24190MiB |     95%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  TITAN RTX           Off  | 00000000:85:00.0 Off |                  N/A |\n",
      "| 67%   84C    P2   193W / 280W |  12169MiB / 24190MiB |     90%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  TITAN RTX           Off  | 00000000:88:00.0 Off |                  N/A |\n",
      "| 50%   68C    P2   220W / 280W |  12171MiB / 24190MiB |     87%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  TITAN RTX           Off  | 00000000:89:00.0 Off |                  N/A |\n",
      "| 68%   84C    P2    99W / 280W |  12169MiB / 24190MiB |     85%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     14477      C   python                                       841MiB |\n",
      "|    0     29194      C   ...shek/anaconda3/envs/Abhishek/bin/python   723MiB |\n",
      "|    0     29573      C   ...shek/anaconda3/envs/Abhishek/bin/python   723MiB |\n",
      "|    1     29194      C   ...shek/anaconda3/envs/Abhishek/bin/python 12153MiB |\n",
      "|    2     29194      C   ...shek/anaconda3/envs/Abhishek/bin/python 11945MiB |\n",
      "|    4     29573      C   ...shek/anaconda3/envs/Abhishek/bin/python 13599MiB |\n",
      "|    5     29573      C   ...shek/anaconda3/envs/Abhishek/bin/python 12141MiB |\n",
      "|    6     29573      C   ...shek/anaconda3/envs/Abhishek/bin/python 12141MiB |\n",
      "|    7     29573      C   ...shek/anaconda3/envs/Abhishek/bin/python 12141MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### IMPORTING NECESSARY MODULES #########\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import transforms, datasets, models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataloading Scheme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlist = '/home/sreena/shayeree/training/trainlatest.txt'\n",
    "validlist ='/home/sreena/shayeree/training/validlatest.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of Unique product Ids to Labels(0 to 31127 classes)\n",
    "# output = dictionary containing mapping of each upc to a label from (0 to 31127)  \n",
    "\n",
    "with open(validlist, mode = 'r') as f:\n",
    "    \n",
    "    Y=[]\n",
    "    for line in f:\n",
    "        path, UPC = line[:-1].split(',')\n",
    "\n",
    "        Y.append(UPC)\n",
    "        \n",
    "prime_number_list = sorted(set(Y))\n",
    "\n",
    "prime_number_dict = { prime_number_list[i] :i for i in range(0, len(prime_number_list) ) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1983"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prime_number_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydataset():    \n",
    "\n",
    "    def __init__(self, classification_list, prime_number_dict, name):\n",
    "\n",
    "        super(mydataset).__init__()\n",
    "        \n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        \n",
    "        with open(classification_list, mode = 'r') as f:\n",
    "            \n",
    "            for line in f:\n",
    "                path, Prime_Number = line[:-1].split(',')\n",
    "\n",
    "                self.X.append(path)\n",
    "                self.Y.append(prime_number_dict[Prime_Number])\n",
    "        \n",
    "\n",
    "        if name == 'valid':\n",
    "            self.transform = transforms.Compose([   transforms.Resize(256),\n",
    "                                                    transforms.CenterCrop(224),\n",
    "                                                    transforms.ToTensor(),\n",
    "                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                    std=[0.229, 0.224, 0.225])\n",
    "                                                ])\n",
    "        else:\n",
    "            self.transform = transforms.Compose([transforms.RandomResizedCrop(221,127),\n",
    "                                                transforms.RandomHorizontalFlip(),\n",
    "                                                transforms.ToTensor(),\n",
    "                                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                    std=[0.229, 0.224, 0.225])])\n",
    "            \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        image = self.X[index]        \n",
    "        label = float(self.Y[index])\n",
    "        \n",
    "        image = (Image.open(image))\n",
    "               \n",
    "        image = self.transform(image)\n",
    "        \n",
    "        return image, torch.as_tensor(label).long()\n",
    "        \n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Train Dataloader #### \n",
    "train_dataset = mydataset(trainlist, prime_number_dict, name='train')          \n",
    "train_dataloader = data.DataLoader(train_dataset, shuffle= True, batch_size = 128, num_workers=16,pin_memory=True)\n",
    "\n",
    "\n",
    "#### Validation Dataloader ##\n",
    "validation_dataset = mydataset(validlist, prime_number_dict, name='valid')         \n",
    "validation_dataloader = data.DataLoader(validation_dataset, shuffle=True, batch_size = 128, num_workers=16,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESNET Architecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * Bottleneck.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * Bottleneck.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, depth, num_classes, bottleneck=False):\n",
    "        super(ResNet, self).__init__()        \n",
    "        \n",
    "        \n",
    "        blocks ={18: BasicBlock, 34: BasicBlock, 50: Bottleneck, 101: Bottleneck, 152: Bottleneck, 200: Bottleneck}\n",
    "        layers ={18: [2, 2, 2, 2], 34: [3, 4, 6, 3], 50: [3, 4, 6, 3], 101: [3, 4, 23, 3], 152: [3, 8, 36, 3], 200: [3, 24, 36, 3]}\n",
    "        assert layers[depth], 'invalid detph for ResNet (depth should be one of 18, 34, 50, 101, 152, and 200)'\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(blocks[depth], 64, layers[depth][0])\n",
    "        self.layer2 = self._make_layer(blocks[depth], 128, layers[depth][1], stride=2)\n",
    "        self.layer3 = self._make_layer(blocks[depth], 256, layers[depth][2], stride=2)\n",
    "        self.layer4 = self._make_layer(blocks[depth], 512, layers[depth][3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7) \n",
    "        self.fc = nn.Linear(512 * blocks[depth].expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "    \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
       "    (fc): Linear(in_features=2048, out_features=1983, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(depth = 50, num_classes = 1983)\n",
    "model = nn.DataParallel(model,device_ids=[0,3]).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper function for Cutmix\n",
    "https://arxiv.org/pdf/1905.04899v2.pdf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2]\n",
    "    H = size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sreena/abhishek/anaconda3/envs/Abhishek/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/sreena/abhishek/anaconda3/envs/Abhishek/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sreena/abhishek/anaconda3/envs/Abhishek/lib/python3.7/site-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/sreena/abhishek/anaconda3/envs/Abhishek/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/sreena/abhishek/anaconda3/envs/Abhishek/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\", line 294, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/sreena/abhishek/anaconda3/envs/Abhishek/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/sreena/abhishek/anaconda3/envs/Abhishek/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/sreena/abhishek/anaconda3/envs/Abhishek/lib/python3.7/multiprocessing/connection.py\", line 492, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/home/sreena/abhishek/anaconda3/envs/Abhishek/lib/python3.7/multiprocessing/connection.py\", line 619, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d2151cd2b34d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/abhishek/anaconda3/envs/Abhishek/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/abhishek/anaconda3/envs/Abhishek/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/abhishek/anaconda3/envs/Abhishek/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/abhishek/anaconda3/envs/Abhishek/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/abhishek/anaconda3/envs/Abhishek/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/abhishek/anaconda3/envs/Abhishek/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch_num, (feats, target) in enumerate(train_dataloader):\n",
    "    print(batch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, test_loader,beta, cutmix_prob, epochs):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        avg_loss = 0.0\n",
    "                \n",
    "        \n",
    "        for batch_num, (feats, target) in enumerate(data_loader):\n",
    "            feats, target = feats.to(device), target.to(device)\n",
    "            \n",
    "            \n",
    "            r = np.random.rand(1)\n",
    "            if beta > 0 and r < cutmix_prob:\n",
    "                # generate mixed sample\n",
    "                lam = np.random.beta(beta, beta)\n",
    "                rand_index = torch.randperm(feats.size()[0]).to(device)\n",
    "                target_a = target\n",
    "                target_b = target[rand_index]\n",
    "                bbx1, bby1, bbx2, bby2 = rand_bbox(feats.size(), lam)\n",
    "                feats[:, :, bbx1:bbx2, bby1:bby2] = feats[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "                # adjust lambda to exactly match pixel ratio\n",
    "                lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (feats.size()[-1] * feats.size()[-2]))\n",
    "                # compute output\n",
    "                output = model(feats)\n",
    "                loss = criterion(output, target_a) * lam + criterion(output, target_b) * (1. - lam)\n",
    "            else:\n",
    "                # compute output\n",
    "                output = model(feats)\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "\n",
    "                                  \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            avg_loss += loss.item()\n",
    "\n",
    "            if batch_num % 100 == 99:\n",
    "                print('loss', avg_loss/100)\n",
    "\n",
    "            del feats\n",
    "            del target\n",
    "            del loss\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        print('Epoch: ', epoch+90)\n",
    "\n",
    "        print('training loss = ', avg_loss/len(data_loader))\n",
    "        train_loss.append(avg_loss/len(data_loader))\n",
    "\n",
    "        ## Check performance on validation set after an Epoch\n",
    "        valid_loss, valid_acc = test_classify(model, test_loader)\n",
    "        print('Val Loss: {:.4f}\\tVal Accuracy: {:.4f}'.format(valid_loss, valid_acc))\n",
    "        v_loss.append(valid_loss)\n",
    "        v_acc.append(valid_acc)\n",
    "\n",
    "        #########save model checkpoint #########\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'Training_Loss_List':train_loss,\n",
    "            'Validation_Loss_List':v_loss,\n",
    "            'Validation_Accuracy_List': v_acc,\n",
    "            'Epoch':epoch,\n",
    "            'lr_scheduler': lr_scheduler.state_dict() \n",
    "\n",
    "            }, 'saved_model_checkpoints/cutmix_check')\n",
    "\n",
    "\n",
    "def test_classify(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    accuracy = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_num, (feats, labels) in enumerate(test_loader):\n",
    "        feats, labels = feats.to(device), labels.to(device)\n",
    "        outputs = model(feats)\n",
    "        \n",
    "        _, pred_labels = torch.max(F.softmax(outputs, dim=1), 1)\n",
    "        pred_labels = pred_labels.view(-1)\n",
    "        \n",
    "        loss = criterion(outputs, labels.long())\n",
    "        \n",
    "        accuracy += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "        total += len(labels)\n",
    "        test_loss.extend([loss.item()]*feats.size()[0])\n",
    "        del feats\n",
    "        del labels\n",
    "\n",
    "    model.train()\n",
    "    return np.mean(test_loss), accuracy/total\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loss Function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, weight_decay=1e-4, momentum=0.9)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 30, gamma = 0.1)\n",
    "\n",
    "\n",
    "# Epochs\n",
    "num_Epochs = 120\n",
    "\n",
    "beta=1\n",
    "\n",
    "cutmix_prob = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss= []\n",
    "v_loss = []\n",
    "v_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 7.2148092031478885\n",
      "loss 14.341025700569153\n",
      "loss 21.35782360076904\n",
      "loss 28.257205891609193\n",
      "loss 35.088924446105956\n",
      "loss 41.80571895122528\n",
      "loss 48.489325423240665\n",
      "loss 55.0381794166565\n",
      "Epoch:  90\n",
      "training loss =  6.8777213658647565\n",
      "Val Loss: 5.8826\tVal Accuracy: 0.0435\n",
      "loss 6.468389601707458\n",
      "loss 12.847163124084473\n",
      "loss 19.149465851783752\n",
      "loss 25.35991680622101\n",
      "loss 31.47093258857727\n",
      "loss 37.551034955978395\n",
      "loss 43.54356248378754\n",
      "loss 49.40811885356903\n",
      "Epoch:  91\n",
      "training loss =  6.1712828960371375\n",
      "Val Loss: 4.7943\tVal Accuracy: 0.1479\n",
      "loss 5.777833337783814\n",
      "loss 11.431666040420533\n",
      "loss 17.064396457672117\n",
      "loss 22.720531458854676\n",
      "loss 28.303070406913758\n",
      "loss 33.73212287425995\n",
      "loss 39.121845555305484\n",
      "loss 44.39937112808227\n",
      "Epoch:  92\n",
      "training loss =  5.5489184501449165\n",
      "Val Loss: 3.9860\tVal Accuracy: 0.2513\n",
      "loss 5.362016921043396\n",
      "loss 10.597388741970063\n",
      "loss 15.76799123287201\n",
      "loss 20.884542260169983\n",
      "loss 26.058606629371642\n",
      "loss 31.122168023586273\n",
      "loss 36.202241876125335\n",
      "loss 41.25563972234726\n",
      "Epoch:  93\n",
      "training loss =  5.158275240112475\n",
      "Val Loss: 3.6432\tVal Accuracy: 0.3349\n",
      "loss 4.904887351989746\n",
      "loss 9.7934965133667\n",
      "loss 14.617730951309204\n",
      "loss 19.38022302389145\n",
      "loss 24.174970920085908\n",
      "loss 28.854400424957277\n",
      "loss 33.54215079069137\n",
      "loss 38.29410965442658\n",
      "Epoch:  94\n",
      "training loss =  4.787525145646656\n",
      "Val Loss: 3.0605\tVal Accuracy: 0.4105\n",
      "loss 4.722575399875641\n",
      "loss 9.42393718957901\n",
      "loss 14.064502851963043\n",
      "loss 18.71915711402893\n",
      "loss 23.35298169851303\n",
      "loss 27.95342205286026\n",
      "loss 32.464756808280946\n",
      "loss 37.024561820030215\n",
      "Epoch:  95\n",
      "training loss =  4.626859775843751\n",
      "Val Loss: 3.1173\tVal Accuracy: 0.3987\n",
      "loss 4.482578341960907\n",
      "loss 8.942148509025573\n",
      "loss 13.386979155540466\n",
      "loss 17.93610848903656\n",
      "loss 22.37414578437805\n",
      "loss 26.769485504627227\n",
      "loss 31.200834422111512\n",
      "loss 35.60749360084534\n",
      "Epoch:  96\n",
      "training loss =  4.4470553930580765\n",
      "Val Loss: 2.9745\tVal Accuracy: 0.4718\n",
      "loss 4.345373647212982\n",
      "loss 8.656207020282745\n",
      "loss 12.988136372566224\n",
      "loss 17.29975620985031\n",
      "loss 21.471049649715425\n",
      "loss 25.702243797779083\n",
      "loss 29.91413164138794\n",
      "loss 34.22631605148315\n",
      "Epoch:  97\n",
      "training loss =  4.279180681735055\n",
      "Val Loss: 2.6432\tVal Accuracy: 0.4919\n",
      "loss 4.236194255352021\n",
      "loss 8.357052836418152\n",
      "loss 12.478894629478454\n",
      "loss 16.62114342927933\n",
      "loss 20.770645673274995\n",
      "loss 24.956751613616944\n",
      "loss 29.080480511188508\n",
      "loss 33.25215234994889\n",
      "Epoch:  98\n",
      "training loss =  4.156835704820032\n",
      "Val Loss: 2.5541\tVal Accuracy: 0.4996\n",
      "loss 4.093222057819366\n",
      "loss 8.203427498340607\n",
      "loss 12.263890902996064\n",
      "loss 16.351731510162352\n",
      "loss 20.328663260936736\n",
      "loss 24.327321164608\n",
      "loss 28.390519745349884\n",
      "loss 32.43095825433731\n",
      "Epoch:  99\n",
      "training loss =  4.055978920264516\n",
      "Val Loss: 2.5697\tVal Accuracy: 0.5146\n",
      "loss 3.9999935126304624\n",
      "loss 7.941459991931915\n",
      "loss 11.909673147201538\n",
      "loss 15.970168097019195\n",
      "Val Loss: 2.4942\tVal Accuracy: 0.5286\n",
      "loss 3.962342405319214\n",
      "loss 7.915352849960327\n",
      "loss 11.937916502952575\n",
      "loss 15.932271456718444\n",
      "loss 19.85367299079895\n",
      "loss 23.792485423088074\n",
      "loss 27.72785328388214\n",
      "loss 31.6502068400383\n",
      "Epoch:  101\n",
      "training loss =  3.9531508722612934\n",
      "Val Loss: 2.3621\tVal Accuracy: 0.5422\n",
      "loss 3.869176254272461\n",
      "loss 7.7132496166229245\n",
      "loss 11.63369300365448\n",
      "loss 15.616567368507384\n",
      "loss 19.546650621891022\n",
      "loss 23.43974886894226\n",
      "loss 27.223853509426117\n",
      "loss 31.03117956638336\n",
      "Epoch:  102\n",
      "training loss =  3.879490624290542\n",
      "Val Loss: 2.6918\tVal Accuracy: 0.5129\n",
      "loss 3.8247058463096617\n",
      "loss 7.577130935192108\n",
      "loss 11.377154812812805\n",
      "loss 15.224075083732606\n",
      "loss 19.047656571865083\n",
      "loss 22.871020011901855\n",
      "loss 26.702155253887177\n",
      "loss 30.535452284812926\n",
      "Epoch:  103\n",
      "training loss =  3.8147897746959334\n",
      "Val Loss: 2.3629\tVal Accuracy: 0.5361\n",
      "loss 3.787094621658325\n",
      "loss 7.494992537498474\n",
      "loss 11.210386319160461\n",
      "loss 14.979699459075928\n",
      "loss 18.721236107349394\n",
      "loss 22.497115435600282\n",
      "loss 26.28522254228592\n",
      "loss 30.110061378479003\n",
      "Epoch:  104\n",
      "training loss =  3.762198186985612\n",
      "Val Loss: 2.4321\tVal Accuracy: 0.5420\n",
      "loss 3.7816713643074036\n",
      "loss 7.500866658687592\n",
      "loss 11.237051565647125\n",
      "loss 14.914075595140456\n",
      "loss 18.6847303378582\n",
      "loss 22.298478125333787\n",
      "loss 26.026042162179948\n",
      "loss 29.676529253721238\n",
      "Epoch:  105\n",
      "training loss =  3.711284442959589\n",
      "Val Loss: 2.3070\tVal Accuracy: 0.5576\n",
      "loss 3.5910275912284852\n",
      "loss 7.236446940898896\n",
      "loss 10.880678737163544\n",
      "loss 14.596263210773468\n",
      "loss 18.28275933265686\n",
      "loss 21.985552849769594\n",
      "loss 25.639300816059112\n",
      "loss 29.334400792121887\n",
      "Epoch:  106\n",
      "training loss =  3.6695092339669504\n",
      "Val Loss: 2.3469\tVal Accuracy: 0.5430\n",
      "loss 3.617736897468567\n",
      "loss 7.233616030216217\n",
      "loss 10.854198241233826\n",
      "loss 14.440686733722687\n",
      "loss 18.0782231259346\n",
      "loss 21.674051930904387\n",
      "loss 25.28703600168228\n",
      "loss 28.92536199092865\n",
      "Epoch:  107\n",
      "training loss =  3.61502297551697\n",
      "Val Loss: 2.2755\tVal Accuracy: 0.5545\n",
      "loss 3.592569954395294\n",
      "loss 7.187395520210266\n",
      "loss 10.76290378332138\n",
      "loss 14.38298344373703\n",
      "loss 18.005383958816527\n",
      "loss 21.643176395893096\n",
      "loss 25.259316775798798\n",
      "loss 28.847976417541503\n",
      "Epoch:  108\n",
      "training loss =  3.6079767877351556\n",
      "Val Loss: 2.2363\tVal Accuracy: 0.5554\n",
      "loss 3.5945120453834534\n",
      "loss 7.16662092924118\n",
      "loss 10.704250750541688\n",
      "loss 14.299365783929824\n",
      "loss 17.89880777478218\n",
      "loss 21.464982830286026\n",
      "loss 25.002570322752\n",
      "loss 28.598881837129593\n",
      "Epoch:  109\n",
      "training loss =  3.5756865120111563\n",
      "Val Loss: 2.2986\tVal Accuracy: 0.5639\n",
      "loss 3.566017153263092\n",
      "loss 7.060880637168884\n",
      "loss 10.545387754440307\n",
      "loss 14.018652377128602\n",
      "loss 17.484347021579744\n",
      "loss 21.042416615486147\n",
      "loss 24.645079498291015\n",
      "loss 28.129411747455595\n",
      "Epoch:  110\n",
      "training loss =  3.51707637369189\n",
      "Val Loss: 2.2866\tVal Accuracy: 0.5578\n",
      "loss 3.4830586743354797\n",
      "loss 6.960361154079437\n",
      "loss 10.491106350421905\n",
      "loss 13.961284158229828\n",
      "loss 17.411009442806243\n",
      "loss 20.907850563526154\n",
      "loss 24.376618485450745\n",
      "loss 27.886050119400025\n",
      "Epoch:  111\n",
      "training loss =  3.4878601743920563\n",
      "Val Loss: 2.3375\tVal Accuracy: 0.5438\n",
      "loss 3.4977100133895873\n",
      "loss 6.953304543495178\n",
      "loss 10.429754860401154\n",
      "loss 13.90290111064911\n",
      "loss 17.37086154937744\n",
      "loss 20.812444055080412\n",
      "loss 24.24763254880905\n",
      "loss 27.59300368309021\n",
      "Epoch:  112\n",
      "training loss =  3.4514654898466013\n",
      "Val Loss: 2.2010\tVal Accuracy: 0.5693\n",
      "loss 3.3629455304145814\n",
      "loss 6.7647798013687135\n",
      "loss 10.226415038108826\n",
      "loss 13.637919838428497\n",
      "loss 17.04598378419876\n",
      "loss 20.404956595897673\n",
      "loss 23.95109506845474\n",
      "loss 27.45642135858536\n",
      "Epoch:  113\n",
      "training loss =  3.4315556894165113\n",
      "Val Loss: 2.1726\tVal Accuracy: 0.5738\n",
      "loss 3.355375694036484\n",
      "loss 6.742168802022934\n",
      "loss 10.233647609949111\n",
      "loss 13.688435174226761\n",
      "loss 17.07165276646614\n",
      "loss 20.52013730406761\n",
      "loss 23.93260763525963\n",
      "loss 10.164609878063201\n",
      "loss 13.52601112127304\n",
      "loss 16.958298614025114\n",
      "loss 20.398872542381287\n",
      "loss 23.81604708433151\n",
      "loss 27.24247492313385\n",
      "Epoch:  115\n",
      "training loss =  3.4030065498044415\n",
      "Val Loss: 2.2347\tVal Accuracy: 0.5607\n",
      "loss 3.3183308351039886\n",
      "loss 6.7127546322345735\n",
      "loss 10.045963407754899\n",
      "loss 13.442082909345627\n",
      "loss 16.789023097753525\n",
      "loss 20.117618807554244\n",
      "loss 23.472835739850996\n",
      "loss 26.87845491528511\n",
      "Epoch:  116\n",
      "training loss =  3.3625877041083116\n",
      "Val Loss: 2.1531\tVal Accuracy: 0.5720\n",
      "loss 3.2643829023838045\n",
      "loss 6.59201446890831\n",
      "loss 9.937256516218186\n",
      "loss 13.323605297803878\n",
      "loss 16.75023157477379\n",
      "loss 20.13028585791588\n",
      "loss 23.45600257873535\n",
      "loss 26.855731415748597\n",
      "Epoch:  117\n",
      "training loss =  3.356956514176305\n",
      "Val Loss: 2.0987\tVal Accuracy: 0.5837\n",
      "loss 3.2554551112651824\n",
      "loss 6.640901902914047\n",
      "loss 9.99194576740265\n",
      "loss 13.304162704944611\n",
      "loss 16.67108162641525\n",
      "loss 20.076870291233064\n",
      "loss 23.406807667016984\n",
      "loss 26.742265528440477\n",
      "Epoch:  118\n",
      "training loss =  3.343416179232207\n",
      "Val Loss: 2.2716\tVal Accuracy: 0.5601\n",
      "loss 3.3388343822956084\n",
      "loss 6.5935438692569734\n",
      "loss 9.914746090173722\n",
      "loss 13.23312820315361\n",
      "loss 16.57761257648468\n",
      "loss 19.77652462363243\n",
      "loss 23.18704379081726\n",
      "loss 26.58864122390747\n",
      "Epoch:  119\n",
      "training loss =  3.3219182355232335\n",
      "Val Loss: 2.0961\tVal Accuracy: 0.5792\n",
      "loss 3.0501501142978666\n",
      "loss 5.984282771348953\n",
      "loss 8.904222476482392\n",
      "loss 11.804748471975326\n",
      "loss 14.692939578294753\n",
      "loss 17.592276463508608\n",
      "loss 20.47676979660988\n",
      "loss 23.382259500026702\n",
      "Epoch:  120\n",
      "training loss =  2.9208324981978158\n",
      "Val Loss: 1.8777\tVal Accuracy: 0.6352\n",
      "loss 2.8824634206295014\n",
      "loss 5.689845403432846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 8.577195950746535\n",
      "loss 11.397340859174728\n",
      "loss 14.217380722761154\n",
      "loss 17.048788912296295\n",
      "loss 19.819331021308898\n",
      "loss 22.675104615688323\n",
      "Epoch:  121\n",
      "training loss =  2.8340303471898913\n",
      "Val Loss: 1.8595\tVal Accuracy: 0.6398\n",
      "loss 2.7192617297172545\n",
      "loss 5.469751622676849\n",
      "loss 8.264502367973328\n",
      "loss 11.05053168296814\n",
      "loss 13.835636205673218\n",
      "loss 16.61535187244415\n",
      "loss 19.348664740324022\n",
      "loss 22.152438806295393\n",
      "Epoch:  122\n",
      "training loss =  2.767621714631026\n",
      "Val Loss: 1.8431\tVal Accuracy: 0.6448\n",
      "loss 2.754331647157669\n",
      "loss 5.472481881380081\n",
      "loss 8.175870994329452\n",
      "loss 10.861743577718734\n",
      "loss 13.682652022838592\n",
      "loss 16.537261724472046\n",
      "loss 19.327142775058746\n",
      "loss 22.01894266605377\n",
      "Epoch:  123\n",
      "training loss =  2.750700879037824\n",
      "Val Loss: 1.8355\tVal Accuracy: 0.6422\n",
      "loss 2.727191789150238\n",
      "loss 5.464715194702149\n",
      "loss 8.19333613872528\n",
      "loss 10.956606801748276\n",
      "loss 13.738449296951295\n",
      "loss 16.44236946105957\n",
      "loss 19.041466143131256\n",
      "loss 21.693695114850996\n",
      "Epoch:  124\n",
      "training loss =  2.71208065008703\n",
      "Val Loss: 1.8267\tVal Accuracy: 0.6446\n",
      "loss 2.750569406747818\n",
      "loss 5.44110788822174\n",
      "loss 8.094254065752029\n",
      "loss 10.802974116802215\n",
      "loss 13.534707390069961\n",
      "loss 16.16937675356865\n",
      "loss 18.924016391038894\n",
      "loss 21.70870785832405\n",
      "Epoch:  125\n",
      "training loss =  2.7138239386359753\n",
      "Val Loss: 1.8310\tVal Accuracy: 0.6436\n",
      "loss 2.6444853174686433\n",
      "loss 5.2849052095413205\n",
      "loss 7.985591431856156\n",
      "loss 10.755419058799744\n",
      "loss 13.48397163748741\n",
      "loss 16.13156450867653\n",
      "loss 18.87064316749573\n",
      "loss 21.557392340898513\n",
      "Epoch:  126\n",
      "training loss =  2.692656598079293\n",
      "Val Loss: 1.8263\tVal Accuracy: 0.6461\n",
      "loss 2.6500630414485933\n",
      "loss 5.342088047266007\n",
      "loss 8.103864285945892\n",
      "loss 10.765596915483474\n",
      "loss 13.509767135381699\n",
      "loss 16.186375861167907\n",
      "loss 18.857053459882735\n",
      "loss 21.509900184869768\n",
      "Epoch:  127\n",
      "training loss =  2.6887091293228473\n",
      "Val Loss: 1.8201\tVal Accuracy: 0.6445\n",
      "loss 2.668302289247513\n",
      "loss 5.2573731946945195\n",
      "loss 7.938080377578736\n",
      "loss 10.606500177383422\n",
      "loss 13.241008929014207\n",
      "loss 15.895528663396835\n",
      "loss 18.58992733359337\n",
      "loss 21.290394814014434\n",
      "Epoch:  128\n",
      "training loss =  2.6623590093096787\n",
      "Val Loss: 1.8039\tVal Accuracy: 0.6498\n",
      "loss 2.657546739578247\n",
      "loss 5.272071019411087\n",
      "loss 7.940217608213425\n",
      "loss 10.675852497816086\n",
      "loss 13.353709816932678\n",
      "loss 16.02971033215523\n",
      "loss 18.675138107538224\n",
      "loss 21.359345380067825\n",
      "Epoch:  129\n",
      "training loss =  2.6707374095620944\n",
      "Val Loss: 1.8029\tVal Accuracy: 0.6490\n",
      "loss 2.66048210144043\n",
      "loss 5.306539672613144\n",
      "loss 7.941496683359146\n",
      "loss 10.632229818105698\n",
      "loss 13.271560492515563\n",
      "loss 15.927082082033158\n",
      "loss 18.607676944732667\n",
      "loss 21.276775557994842\n",
      "Epoch:  130\n",
      "training loss =  2.661403517569265\n",
      "Val Loss: 1.8069\tVal Accuracy: 0.6453\n",
      "loss 2.608342823982239\n",
      "loss 5.175096909999848\n",
      "loss 7.845688760280609\n",
      "loss 10.506208890676499\n",
      "loss 13.152585536241531\n",
      "loss 15.785215034484864\n",
      "loss 18.451251875162125\n",
      "loss 7.954196094274521\n",
      "loss 10.541312946081161\n",
      "loss 13.16631680727005\n",
      "loss 15.835419178009033\n",
      "loss 18.445749074220657\n",
      "loss 21.07375309944153\n",
      "Epoch:  132\n",
      "training loss =  2.6349288497314265\n",
      "Val Loss: 1.8007\tVal Accuracy: 0.6475\n",
      "loss 2.640056798458099\n",
      "loss 5.267249808311463\n",
      "loss 7.84655303478241\n",
      "loss 10.445322047472\n",
      "loss 13.0161723613739\n",
      "loss 15.615853905677795\n",
      "loss 18.240823920965195\n",
      "loss 20.844410803318024\n",
      "Epoch:  133\n",
      "training loss =  2.603151707288349\n",
      "Val Loss: 1.7960\tVal Accuracy: 0.6498\n",
      "loss 2.5643881380558016\n",
      "loss 5.1635261452198025\n",
      "loss 7.8138369524478914\n",
      "loss 10.504874168634414\n",
      "loss 13.12953686594963\n",
      "loss 15.7236141705513\n",
      "loss 18.367614787817\n",
      "loss 20.956424176692963\n",
      "Epoch:  134\n",
      "training loss =  2.6206673552321442\n",
      "Val Loss: 1.7978\tVal Accuracy: 0.6491\n",
      "loss 2.524242550134659\n",
      "loss 5.102364087104798\n",
      "loss 7.730287615060806\n",
      "loss 10.350760537385941\n",
      "loss 12.887210643291473\n",
      "loss 15.502797278165817\n",
      "loss 18.13180767774582\n",
      "loss 20.73249343276024\n",
      "Epoch:  135\n",
      "training loss =  2.5906619698770585\n",
      "Val Loss: 1.7902\tVal Accuracy: 0.6500\n",
      "loss 2.5601543021202087\n",
      "loss 5.140002108812332\n",
      "loss 7.706648683547973\n",
      "loss 10.284410901069641\n",
      "loss 12.80556980252266\n",
      "loss 15.434345220327378\n",
      "loss 18.04436861872673\n",
      "loss 20.684806652069092\n",
      "Epoch:  136\n",
      "training loss =  2.5855002243524745\n",
      "Val Loss: 1.7884\tVal Accuracy: 0.6491\n",
      "loss 2.574860305786133\n",
      "loss 5.096346957683563\n",
      "loss 7.700316904783249\n",
      "loss 10.29989104628563\n",
      "loss 12.900976032018661\n",
      "loss 15.440766917467117\n",
      "loss 18.03510074019432\n",
      "loss 20.638573861122133\n",
      "Epoch:  137\n",
      "training loss =  2.58038231723066\n",
      "Val Loss: 1.7913\tVal Accuracy: 0.6498\n",
      "loss 2.429505511522293\n",
      "loss 4.949727084636688\n",
      "loss 7.4810050833225255\n",
      "loss 10.004758536815643\n",
      "loss 12.59453130364418\n",
      "loss 15.172296068668366\n",
      "loss 17.743195172548294\n",
      "loss 20.326697165966035\n",
      "Epoch:  138\n",
      "training loss =  2.541265754486728\n",
      "Val Loss: 1.7860\tVal Accuracy: 0.6498\n",
      "loss 2.5850544500350954\n",
      "loss 5.067268444299698\n",
      "loss 7.601610071659088\n",
      "loss 10.15674125790596\n",
      "loss 12.695823516845703\n",
      "loss 15.211445688009261\n",
      "loss 17.826024310588835\n",
      "loss 20.388947862386704\n",
      "Epoch:  139\n",
      "training loss =  2.5487926358324717\n",
      "Val Loss: 1.7773\tVal Accuracy: 0.6510\n",
      "loss 2.4788991665840148\n",
      "loss 5.067261021137238\n",
      "loss 7.689022904634475\n",
      "loss 10.201514444351197\n",
      "loss 12.740942460298537\n",
      "loss 15.337684198617936\n",
      "loss 17.917851557731627\n",
      "loss 20.491513861417772\n",
      "Epoch:  140\n",
      "training loss =  2.561378159239038\n",
      "Val Loss: 1.7780\tVal Accuracy: 0.6547\n",
      "loss 2.501457939147949\n",
      "loss 5.082917597293854\n",
      "loss 7.660881354808807\n",
      "loss 10.213467885255813\n",
      "loss 12.735247420072556\n",
      "loss 15.322648921012878\n",
      "loss 17.937239832878113\n",
      "loss 20.50874240398407\n",
      "Epoch:  141\n",
      "training loss =  2.5653619896389412\n",
      "Val Loss: 1.7729\tVal Accuracy: 0.6528\n",
      "loss 2.4697921574115753\n",
      "loss 5.004772019386292\n",
      "loss 7.600161358118057\n",
      "loss 10.093225960731507\n",
      "loss 12.674073625802993\n",
      "loss 15.173884245157241\n",
      "loss 17.69301250576973\n",
      "loss 20.269255254268646\n",
      "Epoch:  142\n",
      "training loss =  2.5342183027314786\n",
      "Val Loss: 1.7782\tVal Accuracy: 0.6500\n",
      "loss 2.5445851147174836\n",
      "loss 5.077701541185379\n",
      "loss 7.636567006111145\n",
      "loss 10.124489458799362\n",
      "loss 12.724665699005127\n",
      "loss 15.294727144241334\n",
      "loss 17.850444679260253\n",
      "loss 20.403280766010283\n",
      "Epoch:  143\n",
      "training loss =  2.5498370182129646\n",
      "Val Loss: 1.7820\tVal Accuracy: 0.6485\n",
      "loss 2.514057755470276\n",
      "loss 5.012745991945267\n",
      "loss 7.548104420900345\n",
      "loss 10.094233675003052\n",
      "loss 12.636986793279648\n",
      "loss 15.150932179689407\n",
      "loss 17.73485220193863\n",
      "loss 20.312508813142777\n",
      "Epoch:  144\n",
      "training loss =  2.5390772829872206\n",
      "Val Loss: 1.7669\tVal Accuracy: 0.6534\n",
      "loss 2.4946823787689207\n",
      "loss 4.962794890403748\n",
      "loss 7.499516007900238\n",
      "loss 10.008133813142777\n",
      "loss 12.524057190418244\n",
      "loss 15.029591631889343\n",
      "loss 17.563288699388504\n",
      "loss 20.107773946523665\n",
      "Epoch:  145\n",
      "training loss =  2.5117549594519453\n",
      "Val Loss: 1.7796\tVal Accuracy: 0.6510\n",
      "loss 2.542725691795349\n",
      "loss 5.0285138213634495\n",
      "loss 7.518613340854645\n",
      "loss 10.029721330404282\n",
      "loss 12.542174711227418\n",
      "loss 15.071101497411728\n",
      "loss 17.542241842746733\n",
      "loss 20.111328415870666\n",
      "Epoch:  146\n",
      "training loss =  2.51424629250472\n",
      "Val Loss: 1.7786\tVal Accuracy: 0.6472\n",
      "loss 2.542958298921585\n",
      "loss 5.091530190706253\n",
      "loss 7.588092331886291\n",
      "loss 10.095464334487914\n",
      "loss 12.623997696638106\n",
      "loss 15.09430683851242\n",
      "loss 17.631907942295076\n",
      "loss 20.138240506649016\n",
      "Epoch:  147\n",
      "training loss =  2.518338370559825\n",
      "Val Loss: 1.7774\tVal Accuracy: 0.6486\n",
      "loss 2.466605234146118\n",
      "loss 4.976942058801651\n",
      "loss 7.426490058898926\n",
      "loss 9.936034209728241\n",
      "loss 12.446584244966507\n",
      "loss 15.040664319992066\n",
      "loss 17.59473932981491\n",
      "loss 20.109321814775466\n",
      "Epoch:  148\n",
      "training loss =  2.512565026064369\n",
      "Val Loss: 1.7676\tVal Accuracy: 0.6533\n",
      "loss 2.508956264257431\n",
      "loss 4.986955156326294\n",
      "loss 7.4564568400383\n",
      "loss 9.998209735155106\n",
      "loss 12.504909464120864\n",
      "loss 15.086396217346191\n",
      "loss 17.623987361192704\n",
      "loss 20.02594354867935\n",
      "Epoch:  149\n",
      "training loss =  2.501142673841481\n",
      "Val Loss: 1.7818\tVal Accuracy: 0.6516\n",
      "loss 2.4994116711616514\n",
      "loss 4.937070100307465\n",
      "loss 7.340801837444306\n",
      "loss 9.738547307252883\n",
      "loss 12.136426743268967\n",
      "loss 14.542212618589401\n",
      "loss 17.000114728212356\n",
      "loss 19.480352447032928\n",
      "Epoch:  150\n",
      "training loss =  2.4344954542427444\n",
      "Val Loss: 1.7425\tVal Accuracy: 0.6614\n",
      "loss 2.410622206926346\n",
      "loss 4.860574100017548\n",
      "loss 7.2146111071109775\n",
      "loss 9.544598840475082\n",
      "loss 11.915017840862275\n",
      "loss 14.255772742033004\n",
      "loss 16.69181449174881\n",
      "loss 19.104041521549224\n",
      "Epoch:  151\n",
      "training loss =  2.3879907054285847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 1.7336\tVal Accuracy: 0.6608\n",
      "loss 2.374937846660614\n",
      "loss 4.784274337291717\n",
      "loss 7.177336478233338\n",
      "loss 9.553579051494598\n",
      "loss 11.929336253404617\n",
      "loss 14.307536189556123\n",
      "loss 16.700730129480363\n",
      "loss 18.99548647761345\n",
      "Epoch:  152\n",
      "training loss =  2.372697598880929\n",
      "Val Loss: 1.7364\tVal Accuracy: 0.6618\n",
      "loss 2.3712935602664946\n",
      "loss 4.669722932577133\n",
      "loss 7.03779641032219\n",
      "loss 9.43564319729805\n",
      "loss 11.77578954577446\n",
      "loss 14.213316274881363\n",
      "loss 16.52931386590004\n",
      "loss 18.8707906126976\n",
      "Epoch:  153\n",
      "training loss =  2.3601548991191477\n",
      "Val Loss: 1.7341\tVal Accuracy: 0.6626\n",
      "loss 2.37903804063797\n",
      "loss 4.747319940328598\n",
      "loss 7.0719642674922945\n",
      "loss 9.45047421693802\n",
      "loss 11.75634888291359\n",
      "loss 14.03437001824379\n",
      "loss 16.34028234601021\n",
      "loss 18.735947316884996\n",
      "Epoch:  154\n",
      "training loss =  2.3430602903993196\n",
      "Val Loss: 1.7308\tVal Accuracy: 0.6606\n",
      "loss 2.3182801103591917\n",
      "loss 4.668139681816101\n",
      "loss 6.900047614574432\n",
      "loss 9.23240178823471\n",
      "loss 11.546870628595352\n",
      "loss 13.886225910186768\n",
      "loss 16.21965166568756\n",
      "loss 18.570740075111388\n",
      "Epoch:  155\n",
      "training loss =  2.3215720970044953\n",
      "Val Loss: 1.7311\tVal Accuracy: 0.6619\n",
      "loss 2.32244926571846\n",
      "loss 4.677116552591324\n",
      "loss 7.0224138402938845\n",
      "loss 9.416466153860092\n",
      "loss 11.699605741500854\n",
      "loss 14.000584846735\n",
      "loss 16.359019206762312\n",
      "loss 18.70337829589844\n",
      "Epoch:  156\n",
      "training loss =  2.338983209198225\n",
      "Val Loss: 1.7293\tVal Accuracy: 0.6625\n",
      "loss 2.3854249441623687\n",
      "loss 4.759297569990158\n",
      "loss 7.0449206417799\n",
      "loss 9.350823108553886\n",
      "loss 11.710502937436104\n",
      "loss 14.051913007497788\n",
      "loss 16.39906273126602\n",
      "loss 18.707657293081283\n",
      "Epoch:  157\n",
      "training loss =  2.3391711586166553\n",
      "Val Loss: 1.7288\tVal Accuracy: 0.6620\n",
      "loss 2.3896972227096556\n",
      "loss 4.707779144048691\n",
      "loss 7.083241193294525\n",
      "loss 9.40934933066368\n",
      "loss 11.738062371015548\n",
      "loss 14.084018164873124\n",
      "loss 16.478368129730224\n",
      "loss 18.775362101793288\n",
      "Epoch:  158\n",
      "training loss =  2.3490098896748375\n",
      "Val Loss: 1.7269\tVal Accuracy: 0.6632\n",
      "loss 2.367683995962143\n",
      "loss 4.6885901951789855\n",
      "loss 7.0363434731960295\n",
      "loss 9.339983061552047\n",
      "loss 11.674771877527236\n",
      "loss 13.967411254644395\n",
      "loss 16.26473076224327\n",
      "loss 18.648897256851196\n",
      "Epoch:  159\n",
      "training loss =  2.3315006142514516\n",
      "Val Loss: 1.7284\tVal Accuracy: 0.6633\n",
      "loss 2.413885225057602\n",
      "loss 4.749360526800156\n",
      "loss 7.03384435415268\n",
      "loss 9.360575712919236\n",
      "loss 11.630812439918518\n",
      "loss 13.961126190423965\n",
      "loss 16.253680040836333\n",
      "loss 18.56459356546402\n",
      "Epoch:  160\n",
      "training loss =  2.319303955688666\n",
      "Val Loss: 1.7287\tVal Accuracy: 0.6616\n",
      "loss 2.336247956752777\n",
      "loss 4.733711166381836\n",
      "loss 7.063002117872238\n",
      "loss 9.370158011913299\n",
      "loss 11.69736064195633\n",
      "loss 14.020305061340332\n",
      "loss 16.37866993904114\n",
      "loss 18.69452543735504\n",
      "Epoch:  161\n",
      "training loss =  2.333764874166058\n",
      "Val Loss: 1.7255\tVal Accuracy: 0.6650\n",
      "loss 2.3108100414276125\n",
      "loss 4.633116827011109\n",
      "loss 6.948327184915542\n",
      "loss 9.272553228139877\n",
      "loss 11.59057028055191\n",
      "loss 13.989980787038803\n",
      "loss 16.334118064641952\n",
      "loss 18.672214766740797\n",
      "Epoch:  162\n",
      "training loss =  2.3343549571912874\n",
      "Val Loss: 1.7218\tVal Accuracy: 0.6632\n",
      "loss 2.338087626695633\n",
      "loss 4.642395924329758\n",
      "loss 6.90569473028183\n",
      "loss 9.186902493238449\n",
      "loss 11.555675023794175\n",
      "loss 13.85696046590805\n",
      "loss 16.131936917304994\n",
      "loss 18.47143934607506\n",
      "Epoch:  163\n",
      "training loss =  2.308282354629365\n",
      "Val Loss: 1.7244\tVal Accuracy: 0.6632\n",
      "loss 2.343518546819687\n",
      "loss 4.603398511409759\n",
      "loss 6.9219150125980375\n",
      "loss 9.20504424571991\n",
      "loss 11.5219080388546\n",
      "loss 13.809567638635635\n",
      "loss 16.043107060194014\n",
      "loss 18.433143035173416\n",
      "Epoch:  164\n",
      "training loss =  2.3033083613693863\n",
      "Val Loss: 1.7296\tVal Accuracy: 0.6629\n",
      "loss 2.3078650104999543\n",
      "loss 4.618715932369232\n",
      "loss 6.924685282707214\n",
      "loss 9.203404899835586\n",
      "loss 11.461185367107392\n",
      "loss 13.838178251981736\n",
      "loss 16.182229704856873\n",
      "loss 18.477130048274994\n",
      "Epoch:  165\n",
      "training loss =  2.3110801573130986\n",
      "Val Loss: 1.7224\tVal Accuracy: 0.6644\n",
      "loss 2.3009829461574554\n",
      "loss 4.628838545083999\n",
      "loss 6.94861673951149\n",
      "loss 9.287871366739273\n",
      "loss 11.657218508720398\n",
      "loss 13.935362471342087\n",
      "loss 16.261795152425766\n",
      "loss 18.59192109823227\n",
      "Epoch:  166\n",
      "training loss =  2.3251889331760833\n",
      "Val Loss: 1.7231\tVal Accuracy: 0.6632\n",
      "loss 2.2989854824543\n",
      "loss 4.505861230492592\n",
      "loss 6.80237663090229\n",
      "loss 9.08944082915783\n",
      "loss 11.44688390672207\n",
      "loss 13.819007281661033\n",
      "loss 16.175281456112863\n",
      "loss 18.507676743865012\n",
      "Epoch:  167\n",
      "training loss =  2.313693078146975\n",
      "Val Loss: 1.7230\tVal Accuracy: 0.6644\n",
      "loss 2.2648425626754762\n",
      "loss 4.4741029888391495\n",
      "loss 6.730425152182579\n",
      "loss 9.015284542441368\n",
      "loss 11.317107696533203\n",
      "loss 13.663924968242645\n",
      "loss 15.942219262123109\n",
      "loss 18.266582452058792\n",
      "Epoch:  168\n",
      "training loss =  2.2843077835019114\n",
      "Val Loss: 1.7194\tVal Accuracy: 0.6643\n",
      "loss 2.2984804993867876\n",
      "loss 4.574535722136497\n",
      "loss 6.866252073645592\n",
      "loss 9.146256619095801\n",
      "loss 11.45807709634304\n",
      "loss 13.770563811659812\n",
      "loss 16.08058281838894\n",
      "loss 18.407728196978567\n",
      "Epoch:  169\n",
      "training loss =  2.30096584122175\n",
      "Val Loss: 1.7235\tVal Accuracy: 0.6632\n",
      "loss 2.2672016787528992\n",
      "loss 4.593389837741852\n",
      "loss 6.8635762238502505\n",
      "loss 9.192108297348023\n",
      "loss 11.473045815825463\n",
      "loss 13.751922073960305\n",
      "loss 16.049214500784874\n",
      "loss 18.352118735313415\n",
      "Epoch:  170\n",
      "training loss =  2.2939972179403374\n",
      "Val Loss: 1.7232\tVal Accuracy: 0.6642\n",
      "loss 2.349194482564926\n",
      "loss 4.699379373788833\n",
      "loss 7.061131207942963\n",
      "loss 9.367962956428528\n",
      "loss 11.620046591758728\n",
      "loss 13.855766921043395\n",
      "loss 16.19944912850857\n",
      "loss 18.52093555510044\n",
      "Epoch:  171\n",
      "training loss =  2.311622976443312\n",
      "Val Loss: 1.7231\tVal Accuracy: 0.6650\n",
      "loss 2.290221400260925\n",
      "loss 4.48790084540844\n",
      "loss 6.761146035790444\n",
      "loss 9.096397833228112\n",
      "loss 11.39430027782917\n",
      "loss 13.673198081851005\n",
      "loss 15.89207987844944\n",
      "loss 6.8401298689842225\n",
      "loss 9.14374051451683\n",
      "loss 11.466585279703141\n",
      "loss 13.79616255402565\n",
      "loss 16.07884437799454\n",
      "loss 18.426397982239724\n",
      "Epoch:  173\n",
      "training loss =  2.302628305428673\n",
      "Val Loss: 1.7243\tVal Accuracy: 0.6636\n",
      "loss 2.247180985212326\n",
      "loss 4.519400523900986\n",
      "loss 6.821313496828079\n",
      "loss 9.139290591478348\n",
      "loss 11.429045484066009\n",
      "loss 13.71368864774704\n",
      "loss 16.027971935272216\n",
      "loss 18.300788865089416\n",
      "Epoch:  174\n",
      "training loss =  2.2887445436813696\n",
      "Val Loss: 1.7218\tVal Accuracy: 0.6662\n",
      "loss 2.263119293451309\n",
      "loss 4.532605526447296\n",
      "loss 6.8077116966247555\n",
      "loss 9.01915451169014\n",
      "loss 11.271719183325768\n",
      "loss 13.574810801148415\n",
      "loss 15.82453227698803\n",
      "loss 18.171431993842123\n",
      "Epoch:  175\n",
      "training loss =  2.272958504576837\n",
      "Val Loss: 1.7245\tVal Accuracy: 0.6648\n",
      "loss 2.3083175158500673\n",
      "loss 4.605099276304245\n",
      "loss 6.988842314481735\n",
      "loss 9.26034060239792\n",
      "loss 11.57725589632988\n",
      "loss 13.80186998128891\n",
      "loss 16.085193002223967\n",
      "loss 18.324448885917665\n",
      "Epoch:  176\n",
      "training loss =  2.2919804706762803\n",
      "Val Loss: 1.7233\tVal Accuracy: 0.6648\n",
      "loss 2.3083204662799837\n",
      "loss 4.60627266049385\n",
      "loss 6.890143556594849\n",
      "loss 9.244870669841767\n",
      "loss 11.567186529636382\n",
      "loss 13.895306684970855\n",
      "loss 16.189935982227325\n",
      "loss 18.516321854591368\n",
      "Epoch:  177\n",
      "training loss =  2.3156865282035053\n",
      "Val Loss: 1.7207\tVal Accuracy: 0.6636\n",
      "loss 2.3223738145828245\n",
      "loss 4.598918398618698\n",
      "loss 6.8468790405988695\n",
      "loss 9.140505736470223\n",
      "loss 11.41209094107151\n",
      "loss 13.71881654202938\n",
      "loss 16.078569230437278\n",
      "loss 18.340598481297494\n",
      "Epoch:  178\n",
      "training loss =  2.2942042812963868\n",
      "Val Loss: 1.7226\tVal Accuracy: 0.6647\n",
      "loss 2.306555289030075\n",
      "loss 4.569744775295257\n",
      "loss 6.88432523727417\n",
      "loss 9.190146601200103\n",
      "loss 11.467609938383102\n",
      "loss 13.73912556052208\n",
      "loss 16.03414966702461\n",
      "loss 18.329252116680145\n",
      "Epoch:  179\n",
      "training loss =  2.2912111270516444\n",
      "Val Loss: 1.7185\tVal Accuracy: 0.6649\n",
      "loss 2.2736843621730802\n",
      "loss 4.581108938455582\n",
      "loss 6.806470330953598\n",
      "loss 9.085873734951019\n",
      "loss 11.35974534869194\n",
      "loss 13.546554492712021\n",
      "loss 15.869953058958053\n",
      "loss 18.199647376537325\n",
      "Epoch:  180\n",
      "training loss =  2.2764542117603956\n",
      "Val Loss: 1.7185\tVal Accuracy: 0.6643\n",
      "loss 2.2517590391635895\n",
      "loss 4.553737901449203\n",
      "loss 6.839995148181916\n",
      "loss 9.042641308307648\n",
      "loss 11.33227178812027\n",
      "loss 13.57204850077629\n",
      "loss 15.793208775520325\n",
      "loss 18.078926602602007\n",
      "Epoch:  181\n",
      "training loss =  2.260561889661453\n",
      "Val Loss: 1.7183\tVal Accuracy: 0.6645\n",
      "loss 2.2129055190086366\n",
      "loss 4.524757246971131\n",
      "loss 6.835698273181915\n",
      "loss 9.020974935293198\n",
      "loss 11.292306488752365\n",
      "loss 13.558482327461242\n",
      "loss 15.84526146531105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 18.121494200229645\n",
      "Epoch:  182\n",
      "training loss =  2.2647578427868504\n",
      "Val Loss: 1.7210\tVal Accuracy: 0.6643\n",
      "loss 2.255713794231415\n",
      "loss 4.531441926956177\n",
      "loss 6.860946036577225\n",
      "loss 9.128493280410767\n",
      "loss 11.408196099996566\n",
      "loss 13.623343216180801\n",
      "loss 15.944934611320496\n",
      "loss 18.257628885507582\n",
      "Epoch:  183\n",
      "training loss =  2.2828176218286047\n",
      "Val Loss: 1.7163\tVal Accuracy: 0.6642\n",
      "loss 2.3059267628192903\n",
      "loss 4.530176995992661\n",
      "loss 6.783455077409744\n",
      "loss 8.943127267360687\n",
      "loss 11.231131263971328\n",
      "loss 13.56246573805809\n",
      "loss 15.728466376066208\n",
      "loss 18.013466209173203\n",
      "Epoch:  184\n",
      "training loss =  2.2532899159355733\n",
      "Val Loss: 1.7216\tVal Accuracy: 0.6651\n",
      "loss 2.2817860519886017\n",
      "loss 4.560422768592835\n",
      "loss 6.8100070226192475\n",
      "loss 9.052884463071823\n",
      "loss 11.326839796304704\n",
      "loss 13.65061038017273\n",
      "loss 15.900521461963654\n",
      "loss 18.170349310040475\n",
      "Epoch:  185\n",
      "training loss =  2.2727140777608006\n",
      "Val Loss: 1.7176\tVal Accuracy: 0.6656\n",
      "loss 2.3209534168243406\n",
      "loss 4.541109006404877\n",
      "loss 6.805922333002091\n",
      "loss 9.054888840913772\n",
      "loss 11.27568029165268\n",
      "loss 13.563171855211259\n",
      "loss 15.856110523939133\n",
      "loss 18.146161105632782\n",
      "Epoch:  186\n",
      "training loss =  2.268423697345014\n",
      "Val Loss: 1.7168\tVal Accuracy: 0.6638\n",
      "loss 2.226950466632843\n",
      "loss 4.502363889217377\n",
      "loss 6.778125365376472\n",
      "loss 9.045388028025627\n",
      "loss 11.299382464289666\n",
      "loss 13.569774265885354\n",
      "loss 15.836894889473916\n",
      "loss 18.11629471361637\n",
      "Epoch:  187\n",
      "training loss =  2.263993638990535\n",
      "Val Loss: 1.7153\tVal Accuracy: 0.6644\n",
      "loss 2.308021378517151\n",
      "loss 4.599586664438248\n",
      "loss 6.855472793579102\n",
      "loss 9.07073793888092\n",
      "loss 11.35726474404335\n",
      "loss 13.59817137002945\n",
      "loss 15.931411284208298\n",
      "loss 18.185657604932786\n",
      "Epoch:  188\n",
      "training loss =  2.272433353269071\n",
      "Val Loss: 1.7157\tVal Accuracy: 0.6659\n",
      "loss 2.196274302005768\n",
      "loss 4.431545622348786\n",
      "loss 6.734782650470733\n",
      "loss 8.978643450737\n",
      "loss 11.350353561639785\n",
      "loss 13.583854756355286\n",
      "loss 15.835616083145142\n",
      "loss 18.18171429991722\n",
      "Epoch:  189\n",
      "training loss =  2.271811733322759\n",
      "Val Loss: 1.7184\tVal Accuracy: 0.6644\n",
      "loss 2.2899905860424044\n",
      "loss 4.544407986402511\n",
      "loss 6.809172059297562\n",
      "loss 9.048951250314712\n",
      "loss 11.267000762224198\n",
      "loss 13.563629415035248\n",
      "loss 15.805352392196655\n",
      "loss 18.08668816924095\n",
      "Epoch:  190\n",
      "training loss =  2.2609803728371047\n",
      "Val Loss: 1.7180\tVal Accuracy: 0.6644\n",
      "loss 2.2833677184581758\n",
      "loss 4.568080410957337\n",
      "loss 6.852777364253998\n",
      "loss 9.118838946819306\n",
      "loss 11.354169918298721\n",
      "loss 13.662404482364655\n",
      "loss 15.942250266075135\n",
      "loss 18.202996096611024\n",
      "Epoch:  191\n",
      "training loss =  2.276811881337509\n",
      "Val Loss: 1.7168\tVal Accuracy: 0.6655\n",
      "loss 2.3011241352558134\n",
      "loss 4.619058527946472\n",
      "loss 6.910724116563797\n",
      "loss 9.219569059610366\n",
      "loss 11.466390122175216\n",
      "loss 13.730096819400787\n",
      "loss 15.975583176612854\n",
      "loss 18.179632877111434\n",
      "Epoch:  192\n",
      "training loss =  2.271227326641603\n",
      "Val Loss: 1.7168\tVal Accuracy: 0.6640\n",
      "loss 2.2941243064403536\n",
      "loss 4.537173625230789\n",
      "loss 6.7741687452793125\n",
      "loss 9.01156302690506\n",
      "loss 11.261988719701767\n",
      "loss 13.564345060586929\n",
      "loss 15.849083223342895\n",
      "loss 18.08334048628807\n",
      "Epoch:  193\n",
      "training loss =  2.2616834684873632\n",
      "Val Loss: 1.7177\tVal Accuracy: 0.6650\n",
      "loss 2.280967847108841\n",
      "loss 4.532089456319809\n",
      "loss 6.820912522077561\n",
      "loss 9.08667011976242\n",
      "loss 11.32406350493431\n",
      "loss 13.58381803035736\n",
      "loss 15.882972394227982\n",
      "loss 18.071990901231764\n",
      "Epoch:  194\n",
      "training loss =  2.260204392538473\n",
      "Val Loss: 1.7146\tVal Accuracy: 0.6650\n",
      "loss 2.2174257504940034\n",
      "loss 4.508275572061539\n",
      "loss 6.8439415216445925\n",
      "loss 9.075673081874847\n",
      "loss 11.295792664289474\n",
      "loss 13.641516865491868\n",
      "loss 15.853582538366318\n",
      "loss 18.055770404338837\n",
      "Epoch:  195\n",
      "training loss =  2.259472678080386\n",
      "Val Loss: 1.7165\tVal Accuracy: 0.6654\n",
      "loss 2.2178468012809756\n",
      "loss 4.4599043655395505\n",
      "loss 6.709482606649399\n",
      "loss 8.980828897953034\n",
      "loss 11.214912061691285\n",
      "loss 13.539806056022645\n",
      "loss 15.7658149600029\n",
      "loss 17.931413182020187\n",
      "Epoch:  196\n",
      "training loss =  2.2409842113407317\n",
      "Val Loss: 1.7162\tVal Accuracy: 0.6659\n",
      "loss 2.2595748674869536\n",
      "loss 4.506888945102691\n",
      "loss 6.777762540578842\n",
      "loss 9.018007584810256\n",
      "loss 11.309137006998062\n",
      "loss 13.534809000492096\n",
      "loss 15.797053024768829\n",
      "loss 18.003301329612732\n",
      "Epoch:  197\n",
      "training loss =  2.2513020210171457\n",
      "Val Loss: 1.7180\tVal Accuracy: 0.6661\n",
      "loss 2.257431310415268\n",
      "loss 4.522525501251221\n",
      "loss 6.731817458868027\n",
      "loss 9.043334902524949\n",
      "loss 11.304501436948776\n",
      "loss 13.547364575862884\n",
      "loss 15.7824698638916\n",
      "loss 17.953360635638237\n",
      "Epoch:  198\n",
      "training loss =  2.2439960338193785\n",
      "Val Loss: 1.7193\tVal Accuracy: 0.6652\n",
      "loss 2.208151705265045\n",
      "loss 4.555941919088363\n",
      "loss 6.764892126321793\n",
      "loss 9.0958931183815\n",
      "loss 11.335122392177581\n",
      "loss 13.53705119729042\n",
      "loss 15.87123155593872\n",
      "loss 18.179585032463073\n",
      "Epoch:  199\n",
      "training loss =  2.27133501566965\n",
      "Val Loss: 1.7181\tVal Accuracy: 0.6643\n",
      "loss 2.2896983087062837\n",
      "loss 4.565077986717224\n",
      "loss 6.809971095919609\n",
      "loss 9.102463625073433\n",
      "loss 11.38092728793621\n",
      "loss 13.638573078513145\n",
      "loss 15.85685212790966\n",
      "loss 18.094200232625006\n",
      "Epoch:  200\n",
      "training loss =  2.2608184217667167\n",
      "Val Loss: 1.7143\tVal Accuracy: 0.6652\n",
      "loss 2.277218471765518\n",
      "loss 4.547891912460327\n",
      "loss 6.845939811468124\n",
      "loss 9.080284768342972\n",
      "loss 11.36594406247139\n",
      "loss 13.621606823205948\n",
      "loss 15.816024988889694\n",
      "loss 18.060278030633928\n",
      "Epoch:  201\n",
      "training loss =  2.2566006233911065\n",
      "Val Loss: 1.7174\tVal Accuracy: 0.6647\n",
      "loss 2.2882153940200807\n",
      "loss 4.444819204807281\n",
      "loss 6.690840630531311\n",
      "loss 8.947443902492523\n",
      "loss 11.217034165859223\n",
      "loss 13.443421854376792\n",
      "loss 15.713942192196846\n",
      "loss 17.9673501342535\n",
      "Epoch:  202\n",
      "training loss =  2.246198383735368\n",
      "Val Loss: 1.7201\tVal Accuracy: 0.6649\n",
      "loss 2.2838642811775207\n",
      "loss 4.52950414776802\n",
      "loss 6.787604714632034\n",
      "loss 9.045402253866195\n",
      "loss 11.306122208833694\n",
      "loss 13.53312785744667\n",
      "loss 15.819101538658142\n",
      "loss 18.125226633548735\n",
      "Epoch:  203\n",
      "training loss =  2.2638800848210714\n",
      "Val Loss: 1.7197\tVal Accuracy: 0.6643\n",
      "loss 2.240204713344574\n",
      "loss 4.460207588672638\n",
      "loss 6.777624462842941\n",
      "loss 9.055709705352783\n",
      "loss 11.320174055099487\n",
      "loss 13.598854235410691\n",
      "loss 15.876053016185761\n",
      "loss 18.097868329286577\n",
      "Epoch:  204\n",
      "training loss =  2.2613311726461274\n",
      "Val Loss: 1.7176\tVal Accuracy: 0.6642\n",
      "loss 2.243453717827797\n",
      "loss 4.504517673850059\n",
      "loss 6.7258519810438155\n",
      "loss 9.019106766581535\n",
      "loss 11.273300837874412\n",
      "loss 13.525670041441918\n",
      "loss 15.835088952183723\n",
      "loss 18.101779562830924\n",
      "Epoch:  205\n",
      "training loss =  2.2632978816629934\n",
      "Val Loss: 1.7175\tVal Accuracy: 0.6658\n",
      "loss 2.257755366563797\n",
      "loss 4.5025863778591155\n",
      "loss 6.700456686019898\n",
      "loss 8.94991024851799\n",
      "loss 11.199166641235351\n",
      "loss 13.440357465744018\n",
      "loss 15.720104374885558\n",
      "loss 18.04176263809204\n",
      "Epoch:  206\n",
      "training loss =  2.2567077795270065\n",
      "Val Loss: 1.7157\tVal Accuracy: 0.6648\n",
      "loss 2.2774548161029817\n",
      "loss 4.603755013942719\n",
      "loss 6.8355994737148285\n",
      "loss 9.067824608683587\n",
      "loss 11.273949164748192\n",
      "loss 13.495168154835701\n",
      "loss 15.750598611235619\n",
      "loss 17.962204416394233\n",
      "Epoch:  207\n",
      "training loss =  2.2434949245553453\n",
      "Val Loss: 1.7157\tVal Accuracy: 0.6652\n",
      "loss 2.2114730715751647\n",
      "loss 4.422951861619949\n",
      "loss 6.643650480508804\n",
      "loss 8.906783576011657\n",
      "loss 11.21844712138176\n",
      "loss 13.478614848852157\n",
      "loss 15.697596100568772\n",
      "loss 17.96564798593521\n",
      "Epoch:  208\n",
      "training loss =  2.246375281520872\n",
      "Val Loss: 1.7138\tVal Accuracy: 0.6652\n",
      "loss 2.176993135213852\n",
      "loss 4.440721813440323\n",
      "loss 6.745959672927857\n",
      "loss 9.029111932516098\n",
      "loss 11.294776159524918\n",
      "loss 13.570155209302902\n",
      "loss 15.855102171897888\n",
      "loss 18.12819020986557\n",
      "Epoch:  209\n",
      "training loss =  2.2666883252690506\n",
      "Val Loss: 1.7160\tVal Accuracy: 0.6657\n"
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, validation_dataloader, beta, cutmix_prob, epochs = num_Epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load saved model from checkpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('saved_model_checkpoints/cutmix_check')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "train_loss = checkpoint['Training_Loss_List'] \n",
    "v_loss = checkpoint['Validation_Loss_List']\n",
    "v_acc = checkpoint['Validation_Accuracy_List']\n",
    "epoch = checkpoint['Epoch']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Validation Accuracy v/s Epochs')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "x = np.arange(1,121)\n",
    "plt.plot(x, v_acc)\n",
    "plt.xlabel('Epochs', fontsize =16)\n",
    "plt.ylabel('Validation Accuracy', fontsize =16)\n",
    "plt.title('Validation Accuracy v/s Epochs',fontsize =16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f05f1cdf090>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "x = np.arange(1,121)\n",
    "plt.plot(x, train_loss, label = 'Training Loss')\n",
    "plt.plot(x, v_loss, label = 'Validation Loss')\n",
    "plt.xlabel('Epochs', fontsize =16)\n",
    "plt.ylabel('Loss', fontsize =16)\n",
    "plt.title('Loss v/s Epochs',fontsize =16)\n",
    "plt.legend(fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1175\tTrain Accuracy: 0.7188\n"
     ]
    }
   ],
   "source": [
    "t_loss, t_acc = test_classify(model, train_dataloader)\n",
    "print('Train Loss: {:.4f}\\tTrain Accuracy: {:.4f}'.format(t_loss, t_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
